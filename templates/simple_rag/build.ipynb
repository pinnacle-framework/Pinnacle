{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38c1a328-fd86-4c5f-bd54-b8664f433608",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Simple retrieval augmented generation with OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f8484d-2e35-472a-9b24-1a30ec1d144b",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "## Connect to pinnacle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d66021-ce62-4021-a2c5-158dee92b3bb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    ":::note\n",
    "Note that this is only relevant if you are running pinnacle in development mode.\n",
    "Otherwise refer to \"Configuring your production system\".\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ef70f6d-a189-460a-8864-241a689624e2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "APPLY = True\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['pinnacle_SECRETS_VOLUME'] = '~/data/secrets/snowflake_dev'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb029a5e-fedf-4f07-8a31-d220cfbfbb3d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-Jun-13 12:20:07.17\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mbuild.py\u001b[0m:\u001b[36m87\u001b[0m| Building Datalayer...\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:07.25\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mbuild.py\u001b[0m:\u001b[36m133\u001b[0m| Building Datalayer... DONE\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from pinnacle import pinnacle, CFG\n",
    "import os\n",
    "\n",
    "db = pinnacle('mongomock://', initialize_cluster=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e7902bd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import io\n",
    "from pinnacle import logging\n",
    "\n",
    "\n",
    "def getter():\n",
    "    logging.info('Downloading data...')\n",
    "    response = requests.get('https://pinnacledb-public-demo.s3.amazonaws.com/text.json')\n",
    "    logging.info('Downloading data... (Done)')\n",
    "    data = json.loads(response.content.decode('utf-8'))\n",
    "    return [{'x': r} for r in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ef8dd07-1b47-4dce-84dd-a081d1f5ee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if APPLY:\n",
    "    data = getter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14067b23-7958-4c93-9311-2525b133bfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnacle import Table\n",
    "\n",
    "table = Table('<var:table_name>', fields={'x': 'str'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4885060-450c-4446-b5fb-e58591c0d1ff",
   "metadata": {},
   "source": [
    "Create plugin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f879a4df-6f60-4c80-8fdd-285a1ef92c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnacle import Plugin\n",
    "\n",
    "plugin = Plugin(path='./rag_plugin.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fea927-ee4a-44cd-aaf2-634b574c316d",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "## Apply a chunker for search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d90bda-e8c4-494e-a38c-837fb63689ae",
   "metadata": {},
   "source": [
    ":::note\n",
    "Note that applying a chunker is ***not*** mandatory for search.\n",
    "If your data is already chunked (e.g. short text snippets or audio) or if you\n",
    "are searching through something like images, which can't be chunked, then this\n",
    "won't be necessary.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93d21872-d4dc-40dc-abab-fb07ba102ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnacle import Listener\n",
    "from rag_plugin import Chunker\n",
    "\n",
    "upstream_listener = Listener(\n",
    "    model=Chunker(identifier='chunker'),\n",
    "    select=db['<var:table_name>'],\n",
    "    key='x',\n",
    "    identifier='chunker',\n",
    "    flatten=True,\n",
    "    upstream=[plugin],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a2cd87-723f-4cee-87c7-9b8181c9e54b",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "## Build text embedding model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10753ea4-9893-4056-813d-7d6ddf78ce02",
   "metadata": {},
   "source": [
    "OpenAI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9b1f538-65ca-499e-b6d0-2dd733f81723",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pinnacle_openai import OpenAIEmbedding\n",
    "\n",
    "openai_embedding = OpenAIEmbedding(\n",
    "    identifier='text-embedding',\n",
    "    model='<var:embedding_model>',\n",
    "    datatype='vector[float32:1536]',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31843db-8638-458a-a770-96a79041be88",
   "metadata": {},
   "source": [
    "## Create vector-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4663fa4b-c2ec-427d-bf8b-b8b109cc2ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnacle import VectorIndex, Listener\n",
    "\n",
    "vector_index_name = 'vectorindex'\n",
    "\n",
    "vector_index = VectorIndex(\n",
    "    vector_index_name,\n",
    "    indexing_listener=Listener(\n",
    "        key=upstream_listener.outputs,\n",
    "        select=db[upstream_listener.outputs],\n",
    "        model=openai_embedding,\n",
    "        identifier='embeddinglistener',\n",
    "        upstream=[upstream_listener],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1179a67b-4e40-496b-9851-98f32d42faa0",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "## Build LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75faf501-f0cf-4707-a165-5a05cfb14bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnacle_openai import OpenAIChatCompletion\n",
    "\n",
    "\n",
    "llm_openai = OpenAIChatCompletion(\n",
    "    identifier='llm-model',\n",
    "    model='<var:llm_model>',\n",
    "    datatype='str',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ae6203-dcc4-493c-a8f8-f727f0f75778",
   "metadata": {},
   "source": [
    "## Answer question with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44baeb09-6f35-4cf2-b814-46283a59f7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag_plugin import RAGModel\n",
    "\n",
    "\n",
    "prompt_template = (\n",
    "    \"Use the following context snippets, these snippets are not ordered!, Answer the question based on this context.\\n\"\n",
    "    \"These snippets are samples from our internal data-repositories, and should be used exclusively and as a matter\"\n",
    "    \" of priority to answer the question. Please answer in 20 words or less.\\n\"\n",
    "    \"{context}\\n\"\n",
    "    \"Here is the question: {query}\"\n",
    ")\n",
    "\n",
    "\n",
    "rag = RAGModel(\n",
    "    'simple_rag',\n",
    "    select=db[upstream_listener.outputs].select().like({upstream_listener.outputs: '<var:query>'}, vector_index=vector_index_name, n=5),\n",
    "    prompt_template=prompt_template,\n",
    "    key=upstream_listener.outputs,\n",
    "    llm=llm_openai,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183bf5b6-4644-4e4c-b65b-e6bafdc6b49f",
   "metadata": {},
   "source": [
    "By applying the RAG model to the database, it will subsequently be accessible for use in other services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c974643b-e642-40ea-942f-4d90e0d1bbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnacle import Streamlit, Plugin\n",
    "from rag_plugin import demo_func\n",
    "\n",
    "demo = Streamlit('simple-rag-demo', demo_func=demo_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6787c78-4b14-4a72-818b-450408a74331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnacle import Application\n",
    "\n",
    "app = Application(\n",
    "    'simple-rag-app',\n",
    "    upstream=[table, plugin],\n",
    "    components=[\n",
    "        upstream_listener,\n",
    "        vector_index,\n",
    "        rag,\n",
    "        demo,\n",
    "    ],\n",
    "    variables={\n",
    "        'table_name': 'docs',\n",
    "        'id_field': '_id',\n",
    "        'embedding_model': 'text-embedding-ada-002',\n",
    "        'llm_model': 'gpt-3.5-turbo',\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0770487c-9e26-4bb8-8554-37fc4a8ca24c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Application:simple-rag-app:6c4f73b9d964d6faeb\n",
       "├── upstream\n",
       "│   ├── [0] Table:docs:3b21dc32e8beebd92b\n",
       "│   │   ├── fields: {'x': 'str'}\n",
       "│   │   └── primary_id: id\n",
       "│   └── [1] Plugin:plugin-rag_plugin_py:b14248bd4605534489\n",
       "│       ├── path: /Users/dodo/.pinnacle/plugins/5242564403d481dbe2/rag_plugin.py\n",
       "│       └── cache_path: ~/.pinnacle/plugins\n",
       "├── components\n",
       "│   ├── [0] Listener:chunker:1862a8fc1629f85fe6\n",
       "│   │   ├── upstream\n",
       "│   │   │   └── [0] Plugin:plugin-rag_plugin_py:1dce9f8e8e852d4707\n",
       "│   │   │       ├── path: /Users/dodo/.pinnacle/plugins/d74990b67d73e918c0/rag_plugin.py\n",
       "│   │   │       └── cache_path: ~/.pinnacle/plugins\n",
       "│   │   ├── cdc_table: docs\n",
       "│   │   ├── key: x\n",
       "│   │   ├── model: Chunker:chunker:b12cd565989b72fc4c\n",
       "│   │   │   ├── datatype: str\n",
       "│   │   │   └── chunk_size: 200\n",
       "│   │   ├── select: docs\n",
       "│   │   └── flatten: True\n",
       "│   ├── [1] VectorIndex:vectorindex:851e610e9d2ace0b54\n",
       "│   │   ├── cdc_table: _outputs__embeddinglistener__a67199bb7c0c1ac162\n",
       "│   │   ├── indexing_listener: Listener:embeddinglistener:a67199bb7c0c1ac162\n",
       "│   │   │   ├── upstream\n",
       "│   │   │   │   └── [0] Listener:chunker:1862a8fc1629f85fe6\n",
       "│   │   │   │       ├── upstream\n",
       "│   │   │   │       │   └── [0] Plugin:plugin-rag_plugin_py:b2ce7e28d49fce8307\n",
       "│   │   │   │       │       ├── path: /Users/dodo/.pinnacle/plugins/cad68136b064ea3d19/rag_plugin.py\n",
       "│   │   │   │       │       └── cache_path: ~/.pinnacle/plugins\n",
       "│   │   │   │       ├── cdc_table: docs\n",
       "│   │   │   │       ├── key: x\n",
       "│   │   │   │       ├── model: Chunker:chunker:b12cd565989b72fc4c\n",
       "│   │   │   │       │   ├── datatype: str\n",
       "│   │   │   │       │   └── chunk_size: 200\n",
       "│   │   │   │       ├── select: docs\n",
       "│   │   │   │       └── flatten: True\n",
       "│   │   │   ├── cdc_table: _outputs__chunker__1862a8fc1629f85fe6\n",
       "│   │   │   ├── key: _outputs__chunker__1862a8fc1629f85fe6\n",
       "│   │   │   ├── model: OpenAIEmbedding:text-embedding:2b907268839faa545d\n",
       "│   │   │   │   ├── datatype: vector\n",
       "│   │   │   │   ├── model: text-embedding-ada-002\n",
       "│   │   │   │   ├── max_batch_size: 8\n",
       "│   │   │   │   └── batch_size: 100\n",
       "│   │   │   └── select: _outputs__chunker__1862a8fc1629f85fe6\n",
       "│   │   └── measure: cosine\n",
       "│   ├── [2] RAGModel:simple_rag:233661fe822e51dd90\n",
       "│   │   ├── datatype: str\n",
       "│   │   ├── prompt_template: Use the following context snippets, these snippets are not ordered!, Answer the \n",
       "│   │   │   question based on this context.\n",
       "│   │   │   These snippets are samples from our internal data-repositories, and should be used exclusively and as a\n",
       "│   │   │   matter of priority to answer the question. Please answer in 20 words or less.\n",
       "│   │   │   {context}\n",
       "│   │   │   Here is the question: {query}\n",
       "│   │   ├── select: _outputs__chunker__1862a8fc1629f85fe6.select().like({'_outputs__chunker__1862a8fc1629f85fe6': \n",
       "│   │   │   '&lt;var:query&gt;'}, \"vectorindex\", n=5)\n",
       "│   │   ├── key: _outputs__chunker__1862a8fc1629f85fe6\n",
       "│   │   └── llm: OpenAIChatCompletion:llm-model:ffce2ddfa3a6a5288f\n",
       "│   │       ├── datatype: str\n",
       "│   │       ├── model: gpt-3.5-turbo\n",
       "│   │       ├── max_batch_size: 8\n",
       "│   │       └── batch_size: 1\n",
       "│   └── [3] Streamlit:simple-rag-demo:b33aaf6fa76d173336\n",
       "│       └── demo_func: &lt;function demo_func at 0x13c6de050&gt;\n",
       "└── variables: {'table_name': 'docs', 'id_field': '_id', 'embedding_model': 'text-embedding-ada-002', 'llm_model': \n",
       "    'gpt-3.5-turbo'}\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Application:simple-rag-app:6c4f73b9d964d6faeb\n",
       "├── upstream\n",
       "│   ├── [0] Table:docs:3b21dc32e8beebd92b\n",
       "│   │   ├── fields: {'x': 'str'}\n",
       "│   │   └── primary_id: id\n",
       "│   └── [1] Plugin:plugin-rag_plugin_py:b14248bd4605534489\n",
       "│       ├── path: /Users/dodo/.pinnacle/plugins/5242564403d481dbe2/rag_plugin.py\n",
       "│       └── cache_path: ~/.pinnacle/plugins\n",
       "├── components\n",
       "│   ├── [0] Listener:chunker:1862a8fc1629f85fe6\n",
       "│   │   ├── upstream\n",
       "│   │   │   └── [0] Plugin:plugin-rag_plugin_py:1dce9f8e8e852d4707\n",
       "│   │   │       ├── path: /Users/dodo/.pinnacle/plugins/d74990b67d73e918c0/rag_plugin.py\n",
       "│   │   │       └── cache_path: ~/.pinnacle/plugins\n",
       "│   │   ├── cdc_table: docs\n",
       "│   │   ├── key: x\n",
       "│   │   ├── model: Chunker:chunker:b12cd565989b72fc4c\n",
       "│   │   │   ├── datatype: str\n",
       "│   │   │   └── chunk_size: 200\n",
       "│   │   ├── select: docs\n",
       "│   │   └── flatten: True\n",
       "│   ├── [1] VectorIndex:vectorindex:851e610e9d2ace0b54\n",
       "│   │   ├── cdc_table: _outputs__embeddinglistener__a67199bb7c0c1ac162\n",
       "│   │   ├── indexing_listener: Listener:embeddinglistener:a67199bb7c0c1ac162\n",
       "│   │   │   ├── upstream\n",
       "│   │   │   │   └── [0] Listener:chunker:1862a8fc1629f85fe6\n",
       "│   │   │   │       ├── upstream\n",
       "│   │   │   │       │   └── [0] Plugin:plugin-rag_plugin_py:b2ce7e28d49fce8307\n",
       "│   │   │   │       │       ├── path: /Users/dodo/.pinnacle/plugins/cad68136b064ea3d19/rag_plugin.py\n",
       "│   │   │   │       │       └── cache_path: ~/.pinnacle/plugins\n",
       "│   │   │   │       ├── cdc_table: docs\n",
       "│   │   │   │       ├── key: x\n",
       "│   │   │   │       ├── model: Chunker:chunker:b12cd565989b72fc4c\n",
       "│   │   │   │       │   ├── datatype: str\n",
       "│   │   │   │       │   └── chunk_size: 200\n",
       "│   │   │   │       ├── select: docs\n",
       "│   │   │   │       └── flatten: True\n",
       "│   │   │   ├── cdc_table: _outputs__chunker__1862a8fc1629f85fe6\n",
       "│   │   │   ├── key: _outputs__chunker__1862a8fc1629f85fe6\n",
       "│   │   │   ├── model: OpenAIEmbedding:text-embedding:2b907268839faa545d\n",
       "│   │   │   │   ├── datatype: vector\n",
       "│   │   │   │   ├── model: text-embedding-ada-002\n",
       "│   │   │   │   ├── max_batch_size: 8\n",
       "│   │   │   │   └── batch_size: 100\n",
       "│   │   │   └── select: _outputs__chunker__1862a8fc1629f85fe6\n",
       "│   │   └── measure: cosine\n",
       "│   ├── [2] RAGModel:simple_rag:233661fe822e51dd90\n",
       "│   │   ├── datatype: str\n",
       "│   │   ├── prompt_template: Use the following context snippets, these snippets are not ordered!, Answer the \n",
       "│   │   │   question based on this context.\n",
       "│   │   │   These snippets are samples from our internal data-repositories, and should be used exclusively and as a\n",
       "│   │   │   matter of priority to answer the question. Please answer in 20 words or less.\n",
       "│   │   │   {context}\n",
       "│   │   │   Here is the question: {query}\n",
       "│   │   ├── select: _outputs__chunker__1862a8fc1629f85fe6.select().like({'_outputs__chunker__1862a8fc1629f85fe6': \n",
       "│   │   │   '<var:query>'}, \"vectorindex\", n=5)\n",
       "│   │   ├── key: _outputs__chunker__1862a8fc1629f85fe6\n",
       "│   │   └── llm: OpenAIChatCompletion:llm-model:ffce2ddfa3a6a5288f\n",
       "│   │       ├── datatype: str\n",
       "│   │       ├── model: gpt-3.5-turbo\n",
       "│   │       ├── max_batch_size: 8\n",
       "│   │       └── batch_size: 1\n",
       "│   └── [3] Streamlit:simple-rag-demo:b33aaf6fa76d173336\n",
       "│       └── demo_func: <function demo_func at 0x13c6de050>\n",
       "└── variables: {'table_name': 'docs', 'id_field': '_id', 'embedding_model': 'text-embedding-ada-002', 'llm_model': \n",
       "    'gpt-3.5-turbo'}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "app.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "137448de-eeee-4aa1-9202-bf26aca68aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m77\u001b[0m| Found 14 create events to apply\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m78\u001b[0m| Found 17 jobs to apply\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m93\u001b[0m| Found these changes and/ or additions that need to be made:\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m96\u001b[0m| ----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m97\u001b[0m| TABLE EVENTS:\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m98\u001b[0m| ----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m105\u001b[0m| [0]: docs[x=str]\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m105\u001b[0m| [1]: _outputs__chunker__1862a8fc1629f85fe6[_outputs__chunker__1862a8fc1629f85fe6=str;_source=str]\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m105\u001b[0m| [2]: _outputs__embeddinglistener__a67199bb7c0c1ac162[_outputs__embeddinglistener__a67199bb7c0c1ac162=vector[float32:1536];_source=str]\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m108\u001b[0m| ----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m109\u001b[0m| METADATA EVENTS:\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m110\u001b[0m| ----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m121\u001b[0m| [0]: Table:docs:3b21dc32e8beebd92b: Create\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m121\u001b[0m| [1]: Plugin:plugin-rag_plugin_py:b14248bd4605534489: Create\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m121\u001b[0m| [2]: Plugin:plugin-rag_plugin_py:1dce9f8e8e852d4707: Create\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m121\u001b[0m| [3]: Chunker:chunker:b12cd565989b72fc4c: Create\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m121\u001b[0m| [4]: Table:_outputs__chunker__1862a8fc1629f85fe6:55813a15e4d7f63d2b: Create\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m121\u001b[0m| [5]: Listener:chunker:1862a8fc1629f85fe6: Create\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m121\u001b[0m| [6]: OpenAIEmbedding:text-embedding:2b907268839faa545d: Create\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m121\u001b[0m| [7]: Table:_outputs__embeddinglistener__a67199bb7c0c1ac162:392e97d67fb77a15dd: Create\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m121\u001b[0m| [8]: Listener:embeddinglistener:a67199bb7c0c1ac162: Create\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m121\u001b[0m| [9]: VectorIndex:vectorindex:851e610e9d2ace0b54: Create\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m121\u001b[0m| [10]: OpenAIChatCompletion:llm-model:ffce2ddfa3a6a5288f: Create\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m121\u001b[0m| [11]: RAGModel:simple_rag:233661fe822e51dd90: Create\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m121\u001b[0m| [12]: Streamlit:simple-rag-demo:b33aaf6fa76d173336: Create\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m123\u001b[0m| [13]: Application:simple-rag-app:6c4f73b9d964d6faeb: Create\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m126\u001b[0m| ----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m127\u001b[0m| PUT EVENTS:\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m128\u001b[0m| ----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m133\u001b[0m| [0]: Chunker:chunker:b12cd565989b72fc4c/compute\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m133\u001b[0m| [1]: Listener:chunker:1862a8fc1629f85fe6/scheduler\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m133\u001b[0m| [2]: Listener:chunker:1862a8fc1629f85fe6/cdc\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m133\u001b[0m| [3]: OpenAIEmbedding:text-embedding:2b907268839faa545d/compute\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m133\u001b[0m| [4]: Listener:embeddinglistener:a67199bb7c0c1ac162/scheduler\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m133\u001b[0m| [5]: Listener:embeddinglistener:a67199bb7c0c1ac162/cdc\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m133\u001b[0m| [6]: VectorIndex:vectorindex:851e610e9d2ace0b54/vector_search\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m133\u001b[0m| [7]: OpenAIChatCompletion:llm-model:ffce2ddfa3a6a5288f/compute\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m133\u001b[0m| [8]: RAGModel:simple_rag:233661fe822e51dd90/compute\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m136\u001b[0m| ----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m137\u001b[0m| JOBS EVENTS:\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m138\u001b[0m| ----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m150\u001b[0m| [0]: Table:docs:3b21dc32e8beebd92b.set_status: set_status\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m150\u001b[0m| [1]: Plugin:plugin-rag_plugin_py:b14248bd4605534489.set_status: set_status\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m150\u001b[0m| [2]: Plugin:plugin-rag_plugin_py:1dce9f8e8e852d4707.set_status: set_status\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m150\u001b[0m| [3]: Chunker:chunker:b12cd565989b72fc4c.set_status: set_status\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m150\u001b[0m| [4]: Table:_outputs__chunker__1862a8fc1629f85fe6:55813a15e4d7f63d2b.set_status: set_status\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m145\u001b[0m| [5]: Listener:chunker:1862a8fc1629f85fe6.run: run ~ [3,2,4]\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m145\u001b[0m| [6]: Listener:chunker:1862a8fc1629f85fe6.set_status: set_status ~ [5,2,3,4]\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m150\u001b[0m| [7]: OpenAIEmbedding:text-embedding:2b907268839faa545d.set_status: set_status\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m150\u001b[0m| [8]: Table:_outputs__embeddinglistener__a67199bb7c0c1ac162:392e97d67fb77a15dd.set_status: set_status\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m145\u001b[0m| [9]: Listener:embeddinglistener:a67199bb7c0c1ac162.run: run ~ [5,6,7,8]\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m145\u001b[0m| [10]: Listener:embeddinglistener:a67199bb7c0c1ac162.set_status: set_status ~ [9,5,6,7,8]\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m145\u001b[0m| [11]: VectorIndex:vectorindex:851e610e9d2ace0b54.copy_vectors: copy_vectors ~ [9,10]\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m145\u001b[0m| [12]: VectorIndex:vectorindex:851e610e9d2ace0b54.set_status: set_status ~ [11,9,10]\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m150\u001b[0m| [13]: OpenAIChatCompletion:llm-model:ffce2ddfa3a6a5288f.set_status: set_status\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m145\u001b[0m| [14]: RAGModel:simple_rag:233661fe822e51dd90.set_status: set_status ~ [13]\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m150\u001b[0m| [15]: Streamlit:simple-rag-demo:b33aaf6fa76d173336.set_status: set_status\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m145\u001b[0m| [16]: Application:simple-rag-app:6c4f73b9d964d6faeb.set_status: set_status ~ [0,1,5,6,11,12,14,15]\u001b[0m\n",
      "\u001b[32m2025-Jun-13 12:20:08.59\u001b[0m| USER    \u001b[0m | \u001b[36mDuncans-MBP.fritz.box\u001b[0m| \u001b[36mapply.py\u001b[0m:\u001b[36m152\u001b[0m| ----------------------------------------------------------------------------------------------------\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pinnacle.components.application.Application at 0x17f0fb4f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if APPLY:\n",
    "    db.apply(app, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "573cee13-f0be-4cb0-8f27-7fbebdceeb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:05<00:00,  1.34s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['684bfb58177f8b02aaa513ec',\n",
       " '684bfb58177f8b02aaa513ed',\n",
       " '684bfb58177f8b02aaa513ee',\n",
       " '684bfb58177f8b02aaa513ef',\n",
       " '684bfb58177f8b02aaa513f0',\n",
       " '684bfb58177f8b02aaa513f1',\n",
       " '684bfb58177f8b02aaa513f2',\n",
       " '684bfb58177f8b02aaa513f3',\n",
       " '684bfb58177f8b02aaa513f4',\n",
       " '684bfb58177f8b02aaa513f5',\n",
       " '684bfb58177f8b02aaa513f6',\n",
       " '684bfb58177f8b02aaa513f7',\n",
       " '684bfb58177f8b02aaa513f8',\n",
       " '684bfb58177f8b02aaa513f9',\n",
       " '684bfb58177f8b02aaa513fa',\n",
       " '684bfb58177f8b02aaa513fb',\n",
       " '684bfb58177f8b02aaa513fc',\n",
       " '684bfb58177f8b02aaa513fd',\n",
       " '684bfb58177f8b02aaa513fe',\n",
       " '684bfb58177f8b02aaa513ff',\n",
       " '684bfb58177f8b02aaa51400',\n",
       " '684bfb58177f8b02aaa51401',\n",
       " '684bfb58177f8b02aaa51402',\n",
       " '684bfb58177f8b02aaa51403',\n",
       " '684bfb58177f8b02aaa51404',\n",
       " '684bfb58177f8b02aaa51405',\n",
       " '684bfb58177f8b02aaa51406',\n",
       " '684bfb58177f8b02aaa51407',\n",
       " '684bfb58177f8b02aaa51408',\n",
       " '684bfb58177f8b02aaa51409',\n",
       " '684bfb58177f8b02aaa5140a',\n",
       " '684bfb58177f8b02aaa5140b',\n",
       " '684bfb58177f8b02aaa5140c',\n",
       " '684bfb58177f8b02aaa5140d',\n",
       " '684bfb58177f8b02aaa5140e',\n",
       " '684bfb58177f8b02aaa5140f',\n",
       " '684bfb58177f8b02aaa51410',\n",
       " '684bfb58177f8b02aaa51411',\n",
       " '684bfb58177f8b02aaa51412',\n",
       " '684bfb58177f8b02aaa51413',\n",
       " '684bfb58177f8b02aaa51414',\n",
       " '684bfb58177f8b02aaa51415',\n",
       " '684bfb58177f8b02aaa51416',\n",
       " '684bfb58177f8b02aaa51417',\n",
       " '684bfb58177f8b02aaa51418',\n",
       " '684bfb58177f8b02aaa51419',\n",
       " '684bfb58177f8b02aaa5141a',\n",
       " '684bfb58177f8b02aaa5141b',\n",
       " '684bfb58177f8b02aaa5141c',\n",
       " '684bfb58177f8b02aaa5141d',\n",
       " '684bfb58177f8b02aaa5141e',\n",
       " '684bfb58177f8b02aaa5141f',\n",
       " '684bfb58177f8b02aaa51420',\n",
       " '684bfb58177f8b02aaa51421',\n",
       " '684bfb58177f8b02aaa51422',\n",
       " '684bfb58177f8b02aaa51423',\n",
       " '684bfb58177f8b02aaa51424',\n",
       " '684bfb58177f8b02aaa51425',\n",
       " '684bfb58177f8b02aaa51426',\n",
       " '684bfb58177f8b02aaa51427',\n",
       " '684bfb58177f8b02aaa51428',\n",
       " '684bfb58177f8b02aaa51429',\n",
       " '684bfb58177f8b02aaa5142a',\n",
       " '684bfb58177f8b02aaa5142b',\n",
       " '684bfb58177f8b02aaa5142c',\n",
       " '684bfb58177f8b02aaa5142d',\n",
       " '684bfb58177f8b02aaa5142e',\n",
       " '684bfb58177f8b02aaa5142f',\n",
       " '684bfb58177f8b02aaa51430',\n",
       " '684bfb58177f8b02aaa51431',\n",
       " '684bfb58177f8b02aaa51432',\n",
       " '684bfb58177f8b02aaa51433',\n",
       " '684bfb58177f8b02aaa51434',\n",
       " '684bfb58177f8b02aaa51435',\n",
       " '684bfb58177f8b02aaa51436',\n",
       " '684bfb58177f8b02aaa51437',\n",
       " '684bfb58177f8b02aaa51438',\n",
       " '684bfb58177f8b02aaa51439',\n",
       " '684bfb58177f8b02aaa5143a',\n",
       " '684bfb58177f8b02aaa5143b',\n",
       " '684bfb58177f8b02aaa5143c',\n",
       " '684bfb58177f8b02aaa5143d',\n",
       " '684bfb58177f8b02aaa5143e',\n",
       " '684bfb58177f8b02aaa5143f',\n",
       " '684bfb58177f8b02aaa51440',\n",
       " '684bfb58177f8b02aaa51441',\n",
       " '684bfb58177f8b02aaa51442',\n",
       " '684bfb58177f8b02aaa51443',\n",
       " '684bfb58177f8b02aaa51444',\n",
       " '684bfb58177f8b02aaa51445',\n",
       " '684bfb58177f8b02aaa51446',\n",
       " '684bfb58177f8b02aaa51447',\n",
       " '684bfb58177f8b02aaa51448',\n",
       " '684bfb58177f8b02aaa51449',\n",
       " '684bfb58177f8b02aaa5144a',\n",
       " '684bfb58177f8b02aaa5144b',\n",
       " '684bfb58177f8b02aaa5144c',\n",
       " '684bfb58177f8b02aaa5144d',\n",
       " '684bfb58177f8b02aaa5144e',\n",
       " '684bfb58177f8b02aaa5144f',\n",
       " '684bfb58177f8b02aaa51450',\n",
       " '684bfb58177f8b02aaa51451',\n",
       " '684bfb58177f8b02aaa51452',\n",
       " '684bfb58177f8b02aaa51453',\n",
       " '684bfb58177f8b02aaa51454',\n",
       " '684bfb58177f8b02aaa51455',\n",
       " '684bfb58177f8b02aaa51456',\n",
       " '684bfb58177f8b02aaa51457',\n",
       " '684bfb58177f8b02aaa51458',\n",
       " '684bfb58177f8b02aaa51459',\n",
       " '684bfb58177f8b02aaa5145a',\n",
       " '684bfb58177f8b02aaa5145b',\n",
       " '684bfb58177f8b02aaa5145c',\n",
       " '684bfb58177f8b02aaa5145d',\n",
       " '684bfb58177f8b02aaa5145e',\n",
       " '684bfb58177f8b02aaa5145f',\n",
       " '684bfb58177f8b02aaa51460',\n",
       " '684bfb58177f8b02aaa51461',\n",
       " '684bfb58177f8b02aaa51462',\n",
       " '684bfb58177f8b02aaa51463',\n",
       " '684bfb58177f8b02aaa51464',\n",
       " '684bfb58177f8b02aaa51465',\n",
       " '684bfb58177f8b02aaa51466',\n",
       " '684bfb58177f8b02aaa51467',\n",
       " '684bfb58177f8b02aaa51468',\n",
       " '684bfb58177f8b02aaa51469',\n",
       " '684bfb58177f8b02aaa5146a',\n",
       " '684bfb58177f8b02aaa5146b',\n",
       " '684bfb58177f8b02aaa5146c',\n",
       " '684bfb58177f8b02aaa5146d',\n",
       " '684bfb58177f8b02aaa5146e',\n",
       " '684bfb58177f8b02aaa5146f',\n",
       " '684bfb58177f8b02aaa51470',\n",
       " '684bfb58177f8b02aaa51471',\n",
       " '684bfb58177f8b02aaa51472',\n",
       " '684bfb58177f8b02aaa51473',\n",
       " '684bfb58177f8b02aaa51474',\n",
       " '684bfb58177f8b02aaa51475',\n",
       " '684bfb58177f8b02aaa51476',\n",
       " '684bfb58177f8b02aaa51477',\n",
       " '684bfb58177f8b02aaa51478',\n",
       " '684bfb58177f8b02aaa51479',\n",
       " '684bfb58177f8b02aaa5147a',\n",
       " '684bfb58177f8b02aaa5147b',\n",
       " '684bfb58177f8b02aaa5147c',\n",
       " '684bfb58177f8b02aaa5147d',\n",
       " '684bfb58177f8b02aaa5147e',\n",
       " '684bfb58177f8b02aaa5147f',\n",
       " '684bfb58177f8b02aaa51480',\n",
       " '684bfb58177f8b02aaa51481',\n",
       " '684bfb58177f8b02aaa51482',\n",
       " '684bfb58177f8b02aaa51483',\n",
       " '684bfb58177f8b02aaa51484',\n",
       " '684bfb58177f8b02aaa51485',\n",
       " '684bfb58177f8b02aaa51486',\n",
       " '684bfb58177f8b02aaa51487',\n",
       " '684bfb58177f8b02aaa51488',\n",
       " '684bfb58177f8b02aaa51489',\n",
       " '684bfb58177f8b02aaa5148a',\n",
       " '684bfb58177f8b02aaa5148b',\n",
       " '684bfb58177f8b02aaa5148c',\n",
       " '684bfb58177f8b02aaa5148d',\n",
       " '684bfb58177f8b02aaa5148e',\n",
       " '684bfb58177f8b02aaa5148f',\n",
       " '684bfb58177f8b02aaa51490',\n",
       " '684bfb58177f8b02aaa51491',\n",
       " '684bfb58177f8b02aaa51492',\n",
       " '684bfb58177f8b02aaa51493',\n",
       " '684bfb58177f8b02aaa51494',\n",
       " '684bfb58177f8b02aaa51495',\n",
       " '684bfb58177f8b02aaa51496',\n",
       " '684bfb58177f8b02aaa51497',\n",
       " '684bfb58177f8b02aaa51498',\n",
       " '684bfb58177f8b02aaa51499',\n",
       " '684bfb58177f8b02aaa5149a',\n",
       " '684bfb58177f8b02aaa5149b',\n",
       " '684bfb58177f8b02aaa5149c',\n",
       " '684bfb58177f8b02aaa5149d',\n",
       " '684bfb58177f8b02aaa5149e',\n",
       " '684bfb58177f8b02aaa5149f',\n",
       " '684bfb58177f8b02aaa514a0',\n",
       " '684bfb58177f8b02aaa514a1',\n",
       " '684bfb58177f8b02aaa514a2',\n",
       " '684bfb58177f8b02aaa514a3',\n",
       " '684bfb58177f8b02aaa514a4',\n",
       " '684bfb58177f8b02aaa514a5',\n",
       " '684bfb58177f8b02aaa514a6']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if APPLY:\n",
    "    db['docs'].insert(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "990aa4a3-7674-466f-8efe-43897c06c03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.export('.', format='yaml')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b24af19",
   "metadata": {},
   "source": [
    "# Training and maintaining MNIST predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8905783f",
   "metadata": {},
   "source": [
    "In this notebook we'll be implementing a classic machine learning classification task: MNIST hand written digit\n",
    "recognition, using a convolution neural network, but with a twist: we'll be implementing the task *in database* using SuperDuperDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9897997-dee8-4947-9327-b96fe06a5a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pinnacledb[demo]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3812091",
   "metadata": {},
   "source": [
    "SuperDuperDB supports MongoDB as a databackend. Correspondingly, we'll import the python MongoDB client `pymongo`\n",
    "and \"wrap\" our database to convert it to a SuperDuper `Datalayer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28adbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import os\n",
    "\n",
    "# Uncomment one of the following lines to use a bespoke MongoDB deployment\n",
    "# For testing the default connection is to mongomock\n",
    "\n",
    "mongodb_uri = os.getenv(\"MONGODB_URI\",\"mongomock://test\")\n",
    "# mongodb_uri = \"mongodb://localhost:27017\"\n",
    "# mongodb_uri = \"mongodb://pinnacle:pinnacle@mongodb:27017/documents\"\n",
    "# mongodb_uri = \"mongodb://<user>:<pass>@<mongo_cluster>/<database>\"\n",
    "# mongodb_uri = \"mongodb+srv://<username>:<password>@<atlas_cluster>/<database>\"\n",
    "\n",
    "# Super-Duper your Database!\n",
    "from pinnacledb import pinnacle\n",
    "db = pinnacle(mongodb_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6233e891",
   "metadata": {},
   "source": [
    "Now that we've connected to SuperDuperDB, let's add some data. MNIST is a good show case for one of the \n",
    "key benefits of SuperDuperDB - adding \"difficult\" data types. This can be done using an `Encoder` \n",
    "which is a key wrapper in SuperDuperDB's arsenal. The `Encoder` works closely together with the `Document` \n",
    "wrapper. Together they allow Python dictionaries containing non-JSONable/ `bytes` objects, to be insert into\n",
    "SuperDuperDB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0934cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pinnacledb.ext.pillow import pil_image as i\n",
    "from pinnacledb import Document as D\n",
    "from pinnacledb.backends.mongodb import Collection\n",
    "\n",
    "import random\n",
    "\n",
    "collection = Collection('mnist')\n",
    "\n",
    "mnist_data = list(torchvision.datasets.MNIST(root='./data', download=True))\n",
    "data = [D({'img': i(x[0]), 'class': x[1]}) for x in mnist_data]\n",
    "random.shuffle(data)\n",
    "data = data[:1000]\n",
    "\n",
    "db.execute(\n",
    "    collection.insert_many(data[:-100]),\n",
    "    encoders=(i,)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5341135",
   "metadata": {},
   "source": [
    "Now that we've inserted the images and their classes to the database, let's query some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36f9c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = db.execute(collection.find_one())\n",
    "r.unpack()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1413d4c5",
   "metadata": {},
   "source": [
    "When we query the data, it's in exactly the format we inserted it. In particular, we can use the `PIL.Image` instances\n",
    "to inspect the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fb7c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.unpack()['img']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fde8bb",
   "metadata": {},
   "source": [
    "Now let's create our model. SuperDuperDB supports these frameworks, out-of-the-box:\n",
    "\n",
    "- `torch`\n",
    "- `sklearn`\n",
    "- `transformers`\n",
    "- `sentence_transformers`\n",
    "- `openai`\n",
    "- `langchain`\n",
    "\n",
    "In this case, we're going to use PyTorch, since it's great for computer vision use-cases.\n",
    "We can combine `torch` with `torchvision` in SuperDuperDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb425e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n",
    "            torch.nn.BatchNorm2d(6),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            torch.nn.BatchNorm2d(16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc = torch.nn.Linear(400, 120)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc1 = torch.nn.Linear(120, 84)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "    \n",
    "def postprocess(x):\n",
    "    return int(x.topk(1)[1].item())\n",
    "\n",
    "\n",
    "def preprocess(x):\n",
    "    return torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((32, 32)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(mean=(0.1307,), std=(0.3081,))]\n",
    "    )(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91155314",
   "metadata": {},
   "source": [
    "We've created `postprocess` and `preprocess` functions to handle the communication with the SuperDuperDB\n",
    "`Datalayer`. In order to create a native SuperDuperDB model, we wrap the model, preprocessing and postprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47855b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pinnacle(LeNet5(10), preprocess=preprocess, postprocess=postprocess, preferred_devices=('cpu',))\n",
    "db.add(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fde9224",
   "metadata": {},
   "source": [
    "The model predicts human readable outputs, directly from the `PIL.Image` objects. All \n",
    "models in SuperDuperDB are equipped with a `sklearn`-style `.predict` method. This makes \n",
    "it easy to know how each AI-framework will operate in combination with the `Datalayer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae586949",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([r['img'] for r in data[:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf0457e",
   "metadata": {},
   "source": [
    "Now we're ready to \"train\" or \"fit\" the model. Trainable models in SuperDuperDB are equipped \n",
    "with a `sklearn`-like `.fit` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c610c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "from pinnacledb import Metric\n",
    "from pinnacledb import Dataset\n",
    "from pinnacledb.ext.torch.model import TorchTrainerConfiguration\n",
    "\n",
    "\n",
    "job = model.fit(\n",
    "    X='img',\n",
    "    y='class',\n",
    "    db=db,\n",
    "    select=collection.find(),\n",
    "    configuration=TorchTrainerConfiguration(\n",
    "        identifier='my_configuration',\n",
    "        objective=cross_entropy,\n",
    "        loader_kwargs={'batch_size': 10},\n",
    "        max_iterations=10,\n",
    "        validation_interval=5,\n",
    "    ),\n",
    "    metrics=[Metric(identifier='acc', object=lambda x, y: sum([xx == yy for xx, yy in zip(x, y)]) / len(x))],\n",
    "    validation_sets=[\n",
    "        Dataset(\n",
    "            identifier='my_valid',\n",
    "            select=Collection('mnist').find({'_fold': 'valid'}),\n",
    "        )\n",
    "    ],\n",
    "    distributed=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200d3be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "model = db.load('model', model.identifier)\n",
    "\n",
    "plt.plot(model.metric_values['my_valid/acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0199b952",
   "metadata": {},
   "source": [
    "Now that the model has been trained, we can use it to \"listen\" the data for incoming changes. \n",
    "This is set up with a simple predict \"on\" the database (without loading all the data client-side).\n",
    "\n",
    "The `listen` toggle \"activates\" the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e53249",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X='img', db=db, select=collection.find(), listen=True, max_chunk_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7daae786",
   "metadata": {},
   "source": [
    "We can see that predictions are available in `_outputs.img.lenet5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc71a143",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.execute(collection.find_one({'_fold': 'valid'})).unpack()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c580aba3",
   "metadata": {},
   "source": [
    "The models \"activated\" can be seen here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8912f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.show('listener')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a78a2a1",
   "metadata": {},
   "source": [
    "We can verify that the model is activated, by inserting the rest of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aa56d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in data[-100:]:\n",
    "    r['update'] = True\n",
    "\n",
    "db.execute(collection.insert_many(data[-100:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb48a30",
   "metadata": {},
   "source": [
    "You can see that the inserted data, are now also populated with predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8161983",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.execute(collection.find_one({'update': True}))['_outputs']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

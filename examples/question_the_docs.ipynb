{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c042ddbb-c2c9-46ed-b36c-c965c0d7ff5b",
   "metadata": {},
   "source": [
    "# Building Q&A Assistant Using Mongo and OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6fbce6-fec9-47af-8701-99721eedec50",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook is designed to demonstrate how to implement a document Question-and-Answer (Q&A) task using SuperDuperDB in conjunction with OpenAI and MongoDB. It provides a step-by-step guide and explanation of each component involved in the process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before diving into the implementation, ensure that you have the necessary libraries installed by running the following commands:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f98f1c7ae8e02278"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6858da67-597d-4d98-ae4a-41003bb569f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pinnacledb[demo]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3befb73",
   "metadata": {},
   "source": [
    "Additionally, ensure that you have set your openai API key as an environment variable. You can uncomment the following code and add your API key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bcdade-f988-4464-bfcf-806245031bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#os.environ['OPENAI_API_KEY'] = 'sk-...'\n",
    "\n",
    "if 'OPENAI_API_KEY' not in os.environ:\n",
    "    raise Exception('Environment variable \"OPENAI_API_KEY\" not set')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Connect to datastore \n",
    "\n",
    "First, we need to establish a connection to a MongoDB datastore via SuperDuperDB. You can configure the `MongoDB_URI` based on your specific setup. \n",
    "Here are some examples of MongoDB URIs:\n",
    "\n",
    "* For testing (default connection): `mongomock://test`\n",
    "* Local MongoDB instance: `mongodb://localhost:27017`\n",
    "* MongoDB with authentication: `mongodb://pinnacle:pinnacle@mongodb:27017/documents`\n",
    "* MongoDB Atlas: `mongodb+srv://<username>:<password>@<atlas_cluster>/<database>`"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85c1a0f7572c43ba"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42c42cc-af6a-4712-a993-d9c921693819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnacledb import pinnacle\n",
    "from pinnacledb.backends.mongodb import Collection\n",
    "import os\n",
    "\n",
    "mongodb_uri = os.getenv(\"MONGODB_URI\",\"mongomock://test\")\n",
    "db = pinnacle(mongodb_uri)\n",
    "\n",
    "collection = Collection('questiondocs')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Dataset \n",
    "\n",
    "In this example we use the internal textual data from the `pinnacledb` project's API documentation. The goal is to create a chatbot that can provide information about the project. You can either load the data from your local project or use the provided data. \n",
    "\n",
    "If you have the SuperDuperDB project locally and want to load the latest version of the API, uncomment the following cell:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "737497f7d5032bf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72a2a52-964f-456e-88b6-040965f5ed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "\n",
    "# ROOT = '../docs/content/docs'\n",
    "\n",
    "# STRIDE = 5       # stride in numbers of lines\n",
    "# WINDOW = 10       # length of window in numbers of lines\n",
    "\n",
    "# content = sum([open(file).readlines() \n",
    "#                for file in glob.glob(f'{ROOT}/*/*.md') \n",
    "#                + glob.glob('{ROOT}/*.md')], [])\n",
    "# chunks = ['\\n'.join(content[i: i + WINDOW]) for i in range(0, len(content), STRIDE)]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Otherwise, you can load the data from an external source. The chunks of text contain code snippets and explanations, which will be used to build the document Q&A chatbot. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9803aef243ad58c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e587e284-0876-4464-a977-ac97a9070787",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -O https://pinnacledb-public.s3.eu-west-1.amazonaws.com/pinnacledb_docs.json\n",
    "\n",
    "import json\n",
    "from IPython.display import Markdown\n",
    "\n",
    "with open('pinnacledb_docs.json') as f:\n",
    "    chunks = json.load(f)\n",
    "    \n",
    "Markdown(chunks[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0370732b-0c55-4672-b6be-0830f9a3a755",
   "metadata": {},
   "source": [
    "As usual, we insert the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7208ef2-c035-43b9-a624-ade42a06ed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnacledb import Document\n",
    "\n",
    "db.execute(collection.insert_many([Document({'txt': chunk}) for chunk in chunks]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b299b6f-37ae-46d7-b064-7d368d98d68a",
   "metadata": {},
   "source": [
    "## Create a Vector-Search Index\n",
    "\n",
    "To enable question-answering, a vector-search index is created using SuperDuperDB with the help of `OpenAI`. Alternatively, one can use `torch`, `sentence_transformers`, `transformers`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa132d0-e6a2-46f6-9eb8-13fbce90ff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnacledb import VectorIndex\n",
    "from pinnacledb import Listener\n",
    "from pinnacledb.ext.openai import OpenAIEmbedding\n",
    "\n",
    "db.add(\n",
    "    VectorIndex(\n",
    "        identifier='my-index',\n",
    "        indexing_listener=Listener(\n",
    "            model=OpenAIEmbedding(model='text-embedding-ada-002'),\n",
    "            key='txt',\n",
    "            select=collection.find(),\n",
    "        ),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create a Chat-Completion Component\n",
    "\n",
    "In this step, a chat-completion component is created and added to the system. This component is essential for the Q&A functionality:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0922a0dc623d7bf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfa4df6-73ac-4d46-8047-011648e24958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnacledb.ext.openai import OpenAIChatCompletion\n",
    "\n",
    "chat = OpenAIChatCompletion(\n",
    "    model='gpt-3.5-turbo',\n",
    "    prompt=(\n",
    "        'Use the following description and code-snippets aboout SuperDuperDB to answer this question about SuperDuperDB\\n'\n",
    "        'Do not use any other information you might have learned about other python packages\\n'\n",
    "        'Only base your answer on the code-snippets retrieved\\n'\n",
    "        '{context}\\n\\n'\n",
    "        'Here\\'s the question:\\n'\n",
    "    ),\n",
    ")\n",
    "\n",
    "db.add(chat)\n",
    "\n",
    "print(db.show('model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696ac7bb-eaaf-4bec-9561-603b3c98a736",
   "metadata": {},
   "source": [
    "## Ask Questions to Your Docs\n",
    "\n",
    "Finally, you can ask questions about the documents. You can target specific queries and use the power of MongoDB for vector-search and filtering rules. Here's an example of asking a question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4a0f6c-9e24-47aa-bc73-7cc4507e94ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnacledb import Document\n",
    "from IPython.display import Markdown\n",
    "\n",
    "q = 'Can you give me a code-snippet to set up a `VectorIndex`?'\n",
    "\n",
    "output, context = db.predict(\n",
    "    model_name='gpt-3.5-turbo',\n",
    "    input=q,\n",
    "    context_select=(\n",
    "        collection\n",
    "            .like(Document({'txt': q}), vector_index='my-index', n=5)\n",
    "            .find()\n",
    "    ),\n",
    "    context_key='txt',\n",
    ")\n",
    "\n",
    "Markdown(output.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

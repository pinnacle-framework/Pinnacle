{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c042ddbb-c2c9-46ed-b36c-c965c0d7ff5b",
   "metadata": {},
   "source": [
    "# Building Q&A Assistant Using Mongo and OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6fbce6-fec9-47af-8701-99721eedec50",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook is designed to demonstrate how to implement a document Question-and-Answer (Q&A) task using SuperDuperDB in conjunction with OpenAI and MongoDB. It provides a step-by-step guide and explanation of each component involved in the process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before diving into the implementation, ensure that you have the necessary libraries installed by running the following commands:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f98f1c7ae8e02278"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6858da67-597d-4d98-ae4a-41003bb569f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pinnacledb\n",
    "!pip install ipython openai==0.27.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3befb73",
   "metadata": {},
   "source": [
    "Additionally, ensure that you have set your openai API key as an environment variable. You can uncomment the following code and add your API key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bcdade-f988-4464-bfcf-806245031bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#os.environ['OPENAI_API_KEY'] = 'sk-...'\n",
    "\n",
    "if 'OPENAI_API_KEY' not in os.environ:\n",
    "    raise Exception('Environment variable \"OPENAI_API_KEY\" not set')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Connect to datastore \n",
    "\n",
    "First, we need to establish a connection to a MongoDB datastore via SuperDuperDB. You can configure the `MongoDB_URI` based on your specific setup. \n",
    "Here are some examples of MongoDB URIs:\n",
    "\n",
    "* For testing (default connection): `mongomock://test`\n",
    "* Local MongoDB instance: `mongodb://localhost:27017`\n",
    "* MongoDB with authentication: `mongodb://pinnacle:pinnacle@mongodb:27017/documents`\n",
    "* MongoDB Atlas: `mongodb+srv://<username>:<password>@<atlas_cluster>/<database>`"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85c1a0f7572c43ba"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42c42cc-af6a-4712-a993-d9c921693819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnacledb import pinnacle\n",
    "from pinnacledb.backends.mongodb import Collection\n",
    "import os\n",
    "\n",
    "mongodb_uri = os.getenv(\"MONGODB_URI\",\"mongomock://test\")\n",
    "db = pinnacle(mongodb_uri)\n",
    "\n",
    "collection = Collection('questiondocs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce857b0-738c-4d7f-bee0-f709c6fc5ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Dataset \n",
    "\n",
    "In this example we use the internal textual data from the `pinnacledb` project's API documentation. The goal is to create a chatbot that can provide information about the project. You can either load the data from your local project or use the provided data. \n",
    "\n",
    "If you have the SuperDuperDB project locally and want to load the latest version of the API, uncomment the following cell:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "737497f7d5032bf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72a2a52-964f-456e-88b6-040965f5ed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "\n",
    "# ROOT = '../docs/hr/content/docs/'\n",
    "\n",
    "# STRIDE = 3       # stride in numbers of lines\n",
    "# WINDOW = 25       # length of window in numbers of lines\n",
    "\n",
    "# files = sorted(glob.glob(f'{ROOT}/*.md') + glob.glob(f'{ROOT}/*.mdx'))\n",
    "\n",
    "# content = sum([open(file).read().split('\\n') for file in files], [])\n",
    "# chunks = ['\\n'.join(content[i: i + WINDOW]) for i in range(0, len(content), STRIDE)]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Otherwise, you can load the data from an external source. The chunks of text contain code snippets and explanations, which will be used to build the document Q&A chatbot. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9803aef243ad58c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20bb184-d45b-4647-b3c3-7043db9a3239",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import *\n",
    "\n",
    "Markdown(chunks[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e587e284-0876-4464-a977-ac97a9070787",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -O https://pinnacledb-public.s3.eu-west-1.amazonaws.com/pinnacledb_docs.json\n",
    "\n",
    "import json\n",
    "from IPython.display import Markdown\n",
    "\n",
    "with open('pinnacledb_docs.json') as f:\n",
    "    chunks = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8c4636-88c6-42a4-b471-41be7c20680f",
   "metadata": {},
   "source": [
    "You can see that the chunks of text contain bits of code, and explanations, \n",
    "which can become useful in building a document Q&A chatbot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0370732b-0c55-4672-b6be-0830f9a3a755",
   "metadata": {},
   "source": [
    "As usual we insert the data. The `Document` wrapper allows `pinnacledb` to handle records with special data types such as images,\n",
    "video, and custom data-types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7208ef2-c035-43b9-a624-ade42a06ed09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnacledb import Document\n",
    "\n",
    "db.execute(collection.insert_many([Document({'txt': chunk}) for chunk in chunks]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b299b6f-37ae-46d7-b064-7d368d98d68a",
   "metadata": {},
   "source": [
    "## Create a Vector-Search Index\n",
    "\n",
    "To enable question-answering over your documents, we need to setup a standard `pinnacledb` vector-search index using `openai` (although there are many options\n",
    "here: `torch`, `sentence_transformers`, `transformers`, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7930b9a1-1483-4106-873c-d85a3920c64e",
   "metadata": {},
   "source": [
    "A `Model` is a wrapper around a self-built or ecosystem model, such as `torch`, `transformers`, `openai`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56905f2e-485e-4179-8585-34eac26c0751",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnacledb.ext.openai import OpenAIEmbedding\n",
    "\n",
    "model = OpenAIEmbedding(model='text-embedding-ada-002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb05a78-263e-4e6f-b429-8e51dbb932b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict('This is a test', one=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4331b81b-c257-4353-aab4-8f601bef78de",
   "metadata": {},
   "source": [
    "A `Listener` \"deploys\" a `Model` to \"listen\" to incoming data, and compute outputs, which are saved in the database, via `db`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1625dab-6438-494b-b74d-efb58bfc8610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnacledb import Listener\n",
    "\n",
    "listener = Listener(model=model, key='txt', select=collection.find())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591dad80-3788-441b-96db-a5bf23a16979",
   "metadata": {},
   "source": [
    "A `VectorIndex` wraps a `Listener`, making its outputs searchable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa132d0-e6a2-46f6-9eb8-13fbce90ff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnacledb import VectorIndex\n",
    "\n",
    "db.add(\n",
    "    VectorIndex(identifier='my-index', indexing_listener=listener)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fde5b17-9d71-4535-aaf6-85f4fa9910e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.execute(collection.find_one())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92948823-0d18-4e1b-b103-f226d6b09e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnacledb.backends.mongodb import Collection\n",
    "from pinnacledb import Document as D\n",
    "from IPython.display import *\n",
    "\n",
    "query = 'Code snippet how to create a `VectorIndex` with a torchvision model'\n",
    "\n",
    "result = db.execute(\n",
    "    collection\n",
    "        .like(D({'txt': query}), vector_index='my-index', n=5)\n",
    "        .find()\n",
    ")\n",
    "\n",
    "display(Markdown('---'))\n",
    "\n",
    "for r in result:\n",
    "    display(Markdown(r['txt']))\n",
    "    display(Markdown('---'))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create a Chat-Completion Component\n",
    "\n",
    "In this step, a chat-completion component is created and added to the system. This component is essential for the Q&A functionality:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0922a0dc623d7bf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfa4df6-73ac-4d46-8047-011648e24958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnacledb.ext.openai import OpenAIChatCompletion\n",
    "\n",
    "chat = OpenAIChatCompletion(\n",
    "    model='gpt-3.5-turbo',\n",
    "    prompt=(\n",
    "        'Use the following description and code-snippets aboout SuperDuperDB to answer this question about SuperDuperDB\\n'\n",
    "        'Do not use any other information you might have learned about other python packages\\n'\n",
    "        'Only base your answer on the code-snippets retrieved\\n'\n",
    "        '{context}\\n\\n'\n",
    "        'Here\\'s the question:\\n'\n",
    "    ),\n",
    ")\n",
    "\n",
    "db.add(chat)\n",
    "\n",
    "print(db.show('model'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696ac7bb-eaaf-4bec-9561-603b3c98a736",
   "metadata": {},
   "source": [
    "## Ask Questions to Your Docs\n",
    "\n",
    "Finally, you can ask questions about the documents. You can target specific queries and use the power of MongoDB for vector-search and filtering rules. Here's an example of asking a question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4a0f6c-9e24-47aa-bc73-7cc4507e94ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnacledb import Document\n",
    "from IPython.display import Markdown\n",
    "\n",
    "# Define the search parameters\n",
    "search_term = 'Can you give me a code-snippet to set up a `VectorIndex`?'\n",
    "num_results = 5\n",
    "\n",
    "output, context = db.predict(\n",
    "    model_name='gpt-3.5-turbo',\n",
    "    input=search_term,\n",
    "    context_select=(\n",
    "        collection\n",
    "            .like(Document({'txt': search_term}), vector_index='my-index', n=num_results)\n",
    "            .find()\n",
    "    ),\n",
    "    context_key='txt',\n",
    ")\n",
    "\n",
    "Markdown(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d1fe16-78d7-4c8d-9991-1086cc9e51bb",
   "metadata": {},
   "source": [
    "Reset the demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab688589-5180-4a78-8fc3-8d3ddaf11e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.remove('vector_index', 'my-index', force=True)\n",
    "db.remove('listener', 'text-embedding-ada-002/txt', force=True)\n",
    "db.remove('model', 'text-embedding-ada-002', force=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

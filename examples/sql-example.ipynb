{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0e29fef",
   "metadata": {},
   "source": [
    "# End-to-End Example Using SQL Databases\n",
    "\n",
    "SuperDuperDB offers the flexibility to connect to various SQL databases, including but not limited to:\n",
    "\n",
    "- MongoDB\n",
    "- PostgreSQL\n",
    "- SQLite\n",
    "- DuckDB\n",
    "- BigQuery\n",
    "- ClickHouse\n",
    "- DataFusion\n",
    "- Druid\n",
    "- Impala\n",
    "- MSSQL\n",
    "- MySQL\n",
    "- Oracle\n",
    "- pandas\n",
    "- Polars\n",
    "- PySpark\n",
    "- Snowflake\n",
    "- Trino\n",
    "\n",
    "In this example, we showcase how to implement multimodal vector-search with DuckDB. This is an extension of multimodal vector-search with MongoDB, which is just slightly easier to set up (see [here](https://docs.pinnacledb.com/docs/use_cases/items/multimodal_image_search_clip)). Everything demonstrated here applies equally to any of the supported SQL databases mentioned above, as well as to tabular data formats on disk, such as `pandas`.\n",
    "\n",
    "Real life use cases could be vectorizing diverse things like images, texts and searching it efficiently with SuperDuperDB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1db9c6",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before proceeding with this use-case, ensure that you have installed the necessary software requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d752ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pinnacledb[demo]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfde8264",
   "metadata": {},
   "source": [
    "## Connect to Datastore\n",
    "\n",
    "The initial step in any `pinnacledb` workflow is to connect to your datastore. To connect to a different datastore, simply add a different `URI`, for example, `postgres://...`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e7ef91-9eda-4fbd-b34f-b49b5411fc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pinnacledb import pinnacle\n",
    "\n",
    "os.makedirs('.pinnacledb', exist_ok=True)\n",
    "\n",
    "# Let's super duper your SQL database\n",
    "db = pinnacle('duckdb://.pinnacledb/test.ddb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8794451",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "Now that you're connected, add some data to the datastore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d2b073-38b0-4d29-aa65-e568f19e7852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the coco_sample.zip file\n",
    "!curl -O https://pinnacledb-public.s3.eu-west-1.amazonaws.com/coco_sample.zip\n",
    "\n",
    "# Download the captions_tiny.json file\n",
    "!curl -O https://pinnacledb-public.s3.eu-west-1.amazonaws.com/captions_tiny.json\n",
    "\n",
    "# Unzip the contents of coco_sample.zip\n",
    "!unzip coco_sample.zip\n",
    "\n",
    "# Create a directory named 'data/coco'\n",
    "!mkdir -p data/coco\n",
    "\n",
    "# Move the 'images_small' directory to 'data/coco/images'\n",
    "!mv images_small data/coco/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5d36d3-7e74-4c87-92c2-ed1586330858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "# Open the 'captions_tiny.json' file and load its contents\n",
    "with open('captions_tiny.json') as f:\n",
    "    data = json.load(f)[:500]\n",
    "\n",
    "# Create a DataFrame from a list comprehension with image paths and captions\n",
    "data = pd.DataFrame([\n",
    "    {\n",
    "        'image': r['image']['_content']['path'],\n",
    "        'captions': r['captions']\n",
    "    } for r in data\n",
    "])\n",
    "\n",
    "# Add an 'id' column to the DataFrame\n",
    "data['id'] = pd.Series(data.index).apply(str)\n",
    "\n",
    "# Create a DataFrame with 'id' and 'image' columns\n",
    "images_df = data[['id', 'image']]\n",
    "\n",
    "# Open each image using PIL.Image\n",
    "images_df['image'] = images_df['image'].apply(Image.open)\n",
    "\n",
    "# Create a DataFrame with 'id' and 'captions' columns, exploding the 'captions' column\n",
    "captions_df = data[['id', 'captions']].explode('captions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43cd7d2",
   "metadata": {},
   "source": [
    "## Define Schema\n",
    "\n",
    "For this use-case, you need a table with images and another table with text. SuperDuperDB extends standard SQL functionality, allowing developers to define their own data types through the `Encoder` abstraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9483f3-78c5-47df-9fa2-4cd070282791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnacledb.backends.ibis.query import Table\n",
    "from pinnacledb.backends.ibis.field_types import dtype\n",
    "from pinnacledb.ext.pillow import pil_image\n",
    "from pinnacledb import Schema\n",
    "\n",
    "# Define the 'captions' table\n",
    "captions = Table(\n",
    "    'captions',\n",
    "    primary_id='id',\n",
    "    schema=Schema(\n",
    "        'captions-schema',\n",
    "        fields={'id': dtype(str), 'captions': dtype(str)},\n",
    "    )\n",
    ")\n",
    "\n",
    "# Define the 'images' table\n",
    "images = Table(\n",
    "    'images',\n",
    "    primary_id='id',\n",
    "    schema=Schema(\n",
    "        'images-schema',\n",
    "        fields={'id': dtype(str), 'image': pil_image},\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add the 'captions' and 'images' tables to the SuperDuperDB database\n",
    "db.add(captions)\n",
    "db.add(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115b2c14",
   "metadata": {},
   "source": [
    "## Add data to the datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cce29b-dd04-47d2-bdfc-fe3780e06ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data from the 'images_df' DataFrame into the 'images' table\n",
    "_ = db.execute(images.insert(images_df))\n",
    "\n",
    "# Insert data from the 'captions_df' DataFrame into the 'captions' table\n",
    "_ = db.execute(captions.insert(captions_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def10282",
   "metadata": {},
   "source": [
    "## Build SuperDuperDB `Model` Instances\n",
    "\n",
    "This use-case utilizes the `pinnacledb.ext.torch` extension. Both models used output `torch` tensors, which are encoded with `tensor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87ed43d-6f90-46c1-8851-6050ae21a051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "import torch\n",
    "from pinnacledb.ext.torch import TorchModel, tensor\n",
    "\n",
    "# Load the CLIP model\n",
    "model, preprocess = clip.load(\"RN50\", device='cpu')\n",
    "\n",
    "# Define a tensor type\n",
    "t = tensor(torch.float, shape=(1024,))\n",
    "\n",
    "# Create a TorchModel for text encoding\n",
    "text_model = TorchModel(\n",
    "    identifier='clip_text',\n",
    "    object=model,\n",
    "    preprocess=lambda x: clip.tokenize(x)[0],\n",
    "    encoder=t,\n",
    "    forward_method='encode_text',    \n",
    ")\n",
    "\n",
    "# Create a TorchModel for visual encoding\n",
    "visual_model = TorchModel(\n",
    "    identifier='clip_image',\n",
    "    object=model.visual,    \n",
    "    preprocess=preprocess,\n",
    "    encoder=t,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c5c236",
   "metadata": {},
   "source": [
    "## Create a Vector-Search Index\n",
    "\n",
    "Define a multimodal search index based on the imported models. The `visual_model` is applied to the images, making the `images` table searchable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8aef2c-484f-41a9-9956-d80b9c58eaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnacledb import VectorIndex, Listener\n",
    "\n",
    "# Add a VectorIndex\n",
    "db.add(\n",
    "    VectorIndex(\n",
    "        'my-index',\n",
    "        indexing_listener=Listener(\n",
    "            model=visual_model,\n",
    "            key='image',\n",
    "            select=images,\n",
    "        ),\n",
    "        compatible_listener=Listener(\n",
    "            model=text_model,\n",
    "            key='captions',\n",
    "            active=False,\n",
    "            select=None,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8b9e84",
   "metadata": {},
   "source": [
    "## Search Images Using Text\n",
    "\n",
    "Now, let's demonstrate how to search for images using text queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1731a574-921a-4cba-a65c-26bff9fb9c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnacledb import Document\n",
    "\n",
    "# Execute a query to find images with captions containing 'dog catches frisbee'\n",
    "res = db.execute(\n",
    "    images\n",
    "        .like(Document({'captions': 'dog catches frisbee'}), vector_index='my-index', n=10)\n",
    "        .limit(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72522031-0af8-452a-bbd1-b27dede55154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the image data from the fourth result in the search\n",
    "res[3]['image'].x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

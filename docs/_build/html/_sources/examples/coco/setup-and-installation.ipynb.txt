{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "238f94f6",
   "metadata": {},
   "source": [
    "# Setup and installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b455a1c8",
   "metadata": {},
   "source": [
    "SuperDuperDB uses MongoDB for data storage. If you haven't done so already, install it using the following lines of bash.\n",
    "\n",
    "```bash\n",
    "wget -qO - https://www.mongodb.org/static/pgp/server-6.0.asc | sudo apt-key add -\n",
    "sudo apt-get install gnupg\n",
    "wget -qO - https://www.mongodb.org/static/pgp/server-6.0.asc | sudo apt-key add -\n",
    "echo \"deb [ arch=amd64,arm64 ] https://repo.mongodb.org/apt/ubuntu focal/mongodb-org/6.0 multiverse\" | sudo tee /etc/apt/sources.list.d/mongodb-org-6.0.list\n",
    "sudo apt-get update\n",
    "sudo apt-get install -y mongodb-org\n",
    "```\n",
    "\n",
    "If you haven't downloaded the data already, execute the lines of bash below. We've tried to keep it clean,\n",
    "and for reasons of efficiency have resized the images using imagemagick:\n",
    "\n",
    "```bash\n",
    "curl http://images.cocodataset.org/annotations/annotations_trainval2014.zip -o raw.zip\n",
    "unzip raw.zip\n",
    "curl http://images.cocodataset.org/zips/train2014.zip -o images.zip\n",
    "unzip -q images.zip\n",
    "sudo apt install -y imagemagick\n",
    "mogrify -resize 224x 'train2014/*.jpg'\n",
    "mkdir -p data/coco\n",
    "mv train2014 data/coco/images\n",
    "mv annotations/* data/coco\n",
    "rm raw.zip\n",
    "rm images.zip\n",
    "```\n",
    "\n",
    "In case you haven't done so already, install the dependencies for this tutorial, including SuperDuperDB,\n",
    "which is a simple pip install:\n",
    "\n",
    "```bash\n",
    "pip install pandas\n",
    "pip install pillow\n",
    "pip install torch\n",
    "pip install -r ../../requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e1e6e1",
   "metadata": {},
   "source": [
    "SuperDuperDB can handle data in any format, including images. The documents in the database are MongoDB `bson` documents, which mix `json` with raw bytes and `ObjectId` objects. SuperDuperDB takes advantage of this by \n",
    "serializing more sophisticated objects to bytes, and reinstantiating the objects in memory, when data is queried.\n",
    "\n",
    "\n",
    "In order to tell SuperDuperDB what type an object has, one specifies this with a subdocument of the form:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"_content\": {\n",
    "        \"bytes\": ...,\n",
    "        \"type\": \"<my-type>\",\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "If however, the content is located on the web or the filesystem, one can specify the URLs directly:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"_content\": {\n",
    "        \"url\": \"<url-or-file>\",\n",
    "        \"type\": \"<my-type>\",\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Let's see this now in action. We reformat the CoCo data, so that each image is associated in one document with all of the captions which describe it, and add the location of the images using the `_content` keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbbf38ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"captions\": [\n",
      "      \"A restaurant has modern wooden tables and chairs.\",\n",
      "      \"A long restaurant table with rattan rounded back chairs.\",\n",
      "      \"a long table with a plant on top of it surrounded with wooden chairs \",\n",
      "      \"A long table with a flower arrangement in the middle for meetings\",\n",
      "      \"A table is adorned with wooden chairs with blue accents.\"\n",
      "    ],\n",
      "    \"img\": {\n",
      "      \"_content\": {\n",
      "        \"url\": \"file://data/coco/images/COCO_train2014_000000057870.jpg\",\n",
      "        \"type\": \"image\"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"captions\": [\n",
      "      \"A man preparing desserts in a kitchen covered in frosting.\",\n",
      "      \"A chef is preparing and decorating many small pastries.\",\n",
      "      \"A baker prepares various types of baked goods.\",\n",
      "      \"a close up of a person grabbing a pastry in a container\",\n",
      "      \"Close up of a hand touching various pastries.\"\n",
      "    ],\n",
      "    \"img\": {\n",
      "      \"_content\": {\n",
      "        \"url\": \"file://data/coco/images/COCO_train2014_000000384029.jpg\",\n",
      "        \"type\": \"image\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('data/coco/captions_train2014.json') as f:\n",
    "    raw = json.load(f)\n",
    "    \n",
    "raw['images'] = {x['id']: x for x in raw['images']}\n",
    "\n",
    "for im in raw['images']:\n",
    "    raw['images'][im]['captions'] = []\n",
    "    \n",
    "for a in raw['annotations']:\n",
    "    raw['images'][a['image_id']]['captions'].append(a['caption'])\n",
    "\n",
    "raw = list(raw['images'].values())\n",
    "\n",
    "for i, im in enumerate(raw):\n",
    "    # if image is already in memory, then add 'bytes': b'...' instead of 'url': '...'\n",
    "    # for content located on the web, use 'http://' or 'https://' instead of 'file://'\n",
    "    im['img'] = {\n",
    "        '_content': {'url': f'file://data/coco/images/{im[\"file_name\"]}', 'type': 'image'}\n",
    "    }\n",
    "    raw[i] = {'captions': im['captions'], 'img': im['img']}\n",
    "    \n",
    "print(json.dumps(raw[:2], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5a4733",
   "metadata": {},
   "source": [
    "You can see that we've slightly reformatted the data in preparation for injestion to SuperDuperDB. That's so that SuperDuperDB knows how to handle the content behind the URLs or file paths for the images. We'll learn more about that in the next chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bff7bb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/coco/data.json', 'w') as f:\n",
    "    json.dump(raw, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

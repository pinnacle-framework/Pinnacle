{"metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.7"}}, "nbformat": 4, "nbformat_minor": 5, "cells": [{"cell_type": "markdown", "id": "38c1a328-fd86-4c5f-bd54-b8664f433608", "metadata": {}, "source": ["<!-- TABS -->\n", "# Retrieval augmented generation"]}, {"cell_type": "markdown", "id": "ec24191c-ed06-4264-9cd1-c8c0d7c23f0b", "metadata": {}, "source": ["The first step in any SuperDuperDB application is to connect to your data-backend with SuperDuperDB:"]}, {"cell_type": "markdown", "id": "f7a4aab8-86eb-4e1c-9200-0a16ba75b2e6", "metadata": {}, "source": ["<!-- TABS -->\n", "## Configure your production system"]}, {"cell_type": "markdown", "id": "81e7cd59-67d0-4776-aea1-4864aa768f95", "metadata": {}, "source": [":::note\n", "If you would like to use the production features \n", "of SuperDuperDB, then you should set the relevant \n", "connections and configurations in a configuration \n", "file. Otherwise you are welcome to use \"development\" mode \n", "to get going with SuperDuperDB quickly.\n", ":::"]}, {"cell_type": "code", "execution_count": null, "id": "62014646-ccd4-4d10-ac26-1c470f88f2f2", "metadata": {}, "outputs": [], "source": ["import os\n", "\n", "os.mkdirs('.pinnacledb', exist_ok=True)\n", "os.environ['pinnacleDB_CONFIG_FILE'] = '.pinnacledb/config.yaml'"]}, {"cell_type": "code", "execution_count": null, "id": "8e50edd2-438d-44ab-9da0-0b72197df262", "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB Community>\n", "CFG = '''\n", "artifact_store: filesystem://<path-to-artifact-store>\n", "cluster: \n", "    compute: ray://<ray-host>\n", "    cdc:    \n", "        uri: http://<cdc-host>:<cdc-port>\n", "    vector_search:\n", "        uri: http://<vector-search-host>:<vector-search-port>\n", "        type: lance\n", "databackend: mongodb://<mongo-host>:27017/documents\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "1ad9ee67-6402-45ea-8311-3efb039b5df3", "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB Atlas>\n", "CFG = '''\n", "artifact_store: filesystem://<path-to-artifact-store>\n", "cluster: \n", "    compute: ray://<ray-host>\n", "    cdc:    \n", "        uri: http://<cdc-host>:<cdc-port>\n", "    vector_search:\n", "        uri: http://<vector-search-host>:<vector-search-port>\n", "        type: native\n", "databackend: mongodb+srv://<user>:<password>@<mongo-host>:27017/documents\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "9c9e8351-b17f-4882-bda6-5ad51dbc7e1f", "metadata": {}, "outputs": [], "source": ["# <tab: SQLite>\n", "CFG = '''\n", "artifact_store: filesystem://<path-to-artifact-store>\n", "cluster: \n", "    compute: ray://<ray-host>\n", "    cdc:    \n", "        uri: http://<cdc-host>:<cdc-port>\n", "    vector_search:\n", "        uri: http://<vector-search-host>:<vector-search-port>\n", "databackend: sqlite://<path-to-db>.db\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "d16c66bb-6ff2-4cea-b11c-0a65bf86c7ad", "metadata": {}, "outputs": [], "source": ["# <tab: MySQL>\n", "CFG = '''\n", "artifact_store: filesystem://<path-to-artifact-store>\n", "cluster: \n", "    compute: ray://<ray-host>\n", "    cdc:    \n", "        uri: http://<cdc-host>:<cdc-port>\n", "    vector_search:\n", "        uri: http://<vector-search-host>:<vector-search-port>\n", "databackend: mysql://<user>:<password>@<host>:<port>/database\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "9b7ac715-712c-4ec7-be90-0aaa22518977", "metadata": {}, "outputs": [], "source": ["# <tab: Oracle>\n", "CFG = '''\n", "artifact_store: filesystem://<path-to-artifact-store>\n", "cluster: \n", "    compute: ray://<ray-host>\n", "    cdc:    \n", "        uri: http://<cdc-host>:<cdc-port>\n", "    vector_search:\n", "        uri: http://<vector-search-host>:<vector-search-port>\n", "databackend: mssql://<user>:<password>@<host>:<port>\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "f21fad9c-cc0e-4cf5-83f0-41a3a614c6af", "metadata": {}, "outputs": [], "source": ["# <tab: PostgreSQL>\n", "CFG = '''\n", "artifact_store: filesystem://<path-to-artifact-store>\n", "cluster: \n", "    compute: ray://<ray-host>\n", "    cdc:    \n", "        uri: http://<cdc-host>:<cdc-port>\n", "    vector_search:\n", "        uri: http://<vector-search-host>:<vector-search-port>\n", "databackend: postgres://<user>:<password>@<host>:<port</<database>\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "1badb5a3-823c-4463-ab79-6f4f9239dabe", "metadata": {}, "outputs": [], "source": ["# <tab: Snowflake>\n", "CFG = '''\n", "artifact_store: filesystem://<path-to-artifact-store>\n", "metadata_store: sqlite://<path-to-sqlite-db>.db\n", "cluster: \n", "    compute: ray://<ray-host>\n", "    cdc:    \n", "        uri: http://<cdc-host>:<cdc-port>\n", "    vector_search:\n", "        uri: http://<vector-search-host>:<vector-search-port>\n", "databackend: snowflake://<user>:<password>@<account>/<database>\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "ae7807d9-9fc1-4c18-8027-a512f827783d", "metadata": {}, "outputs": [], "source": ["# <tab: Clickhouse>\n", "CFG = '''\n", "artifact_store: filesystem://<path-to-artifact-store>\n", "metadata_store: sqlite://<path-to-sqlite-db>.db\n", "cluster: \n", "    compute: ray://<ray-host>\n", "    cdc:    \n", "        uri: http://<cdc-host>:<cdc-port>\n", "    vector_search:\n", "        uri: http://<vector-search-host>:<vector-search-port>\n", "databackend: clickhouse://<user>:<password>@<host>:<port>\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "fc40c13b-9bc5-47ac-86d6-ef7a379c45ee", "metadata": {}, "outputs": [], "source": ["with open(os.environ['pinnacleDB_CONFIG_FILE'], 'w') as f:\n", "    f.write(CFG)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- TABS -->\n", "## Start your cluster"]}, {"cell_type": "markdown", "metadata": {}, "source": [":::note\n", "Starting a SuperDuperDB cluster is useful in production and model development\n", "if you want to enable scalable compute, access to the models by multiple users for collaboration, \n", "monitoring.\n", "\n", "If you don't need this, then it is simpler to start in development mode.\n", ":::"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: Experimental Cluster>\n", "!python -m pinnacledb local_cluster"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: Docker-Compose>\n", "!make testenv_image\n", "!make testenv_init"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from pinnacledb import pinnacle\n", "\n", "db = pinnacle()"]}, {"cell_type": "markdown", "id": "32f8484d-2e35-472a-9b24-1a30ec1d144b", "metadata": {}, "source": ["<!-- TABS -->\n", "## Connect to SuperDuperDB"]}, {"cell_type": "markdown", "id": "06d66021-ce62-4021-a2c5-158dee92b3bb", "metadata": {}, "source": [":::note\n", "Note that this is only relevant if you are running SuperDuperDB in development mode.\n", "Otherwise refer to \"Configuring your production system\".\n", ":::"]}, {"cell_type": "code", "execution_count": null, "id": "61976f44-8139-41c0-a73e-569c6d16c4b1", "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB>\n", "from pinnacledb import pinnacle\n", "\n", "db = pinnacle('mongodb://localhost:27017/documents')\n", "db.drop(True)"]}, {"cell_type": "code", "execution_count": null, "id": "e981a457", "metadata": {}, "outputs": [], "source": ["# <tab: SQLite>\n", "from pinnacledb import pinnacle\n", "\n", "db = pinnacle('sqlite://my_db.db')"]}, {"cell_type": "code", "execution_count": null, "id": "19ecf7c0-b730-4503-9b5d-e97697b3bcee", "metadata": {}, "outputs": [], "source": ["# <tab: MySQL>\n", "from pinnacledb import pinnacle\n", "\n", "user = 'pinnacle'\n", "password = 'pinnacle'\n", "port = 3306\n", "host = 'localhost'\n", "database = 'test_db'\n", "\n", "db = pinnacle(f\"mysql://{user}:{password}@{host}:{port}/{database}\")"]}, {"cell_type": "code", "execution_count": null, "id": "df208e8c-4fd0-438f-af29-22a763a2aebd", "metadata": {}, "outputs": [], "source": ["# <tab: Oracle>\n", "from pinnacledb import pinnacle\n", "\n", "user = 'sa'\n", "password = 'pinnacle#1'\n", "port = 1433\n", "host = 'localhost'\n", "\n", "db = pinnacle(f\"mssql://{user}:{password}@{host}:{port}\")"]}, {"cell_type": "code", "execution_count": null, "id": "d2297295", "metadata": {}, "outputs": [], "source": ["# <tab: PostgreSQL>\n", "from pinnacledb import pinnacle\n", "\n", "user = 'pinnacle'\n", "password = 'pinnacle'\n", "port = 5432\n", "host = 'localhost'\n", "database = 'test_db'\n", "\n", "db = pinnacle(f\"postgres://{user}:{password}@{host}:{port}/{database}\")"]}, {"cell_type": "code", "execution_count": null, "id": "cc6c8517", "metadata": {}, "outputs": [], "source": ["# <tab: Snowflake>\n", "from pinnacledb import pinnacle\n", "\n", "user = \"pinnacleuser\"\n", "password = \"pinnaclepassword\"\n", "account = \"XXXX-XXXX\"  # ORGANIZATIONID-USERID\n", "database = \"FREE_COMPANY_DATASET/PUBLIC\"\n", "\n", "snowflake_uri = f\"snowflake://{user}:{password}@{account}/{database}\"\n", "\n", "db = pinnacle(\n", "    snowflake_uri, \n", "    metadata_store='sqlite:///your_database_name.db',\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "05da45e3-d9e4-49ca-b9ee-db1b8bf4eb44", "metadata": {}, "outputs": [], "source": ["# <tab: Clickhouse>\n", "from pinnacledb import pinnacle\n", "\n", "user = 'default'\n", "password = ''\n", "port = 8123\n", "host = 'localhost'\n", "\n", "db = pinnacle(f\"clickhouse://{user}:{password}@{host}:{port}\", metadata_store=f'mongomock://meta')"]}, {"cell_type": "code", "execution_count": null, "id": "0e89c8dd-d845-423a-9acc-97e3360d370c", "metadata": {}, "outputs": [], "source": ["# <tab: DuckDB>\n", "from pinnacledb import pinnacle\n", "\n", "db = pinnacle('duckdb://mydb.duckdb')"]}, {"cell_type": "code", "execution_count": null, "id": "2de71562", "metadata": {}, "outputs": [], "source": ["# <tab: Pandas>\n", "from pinnacledb import pinnacle\n", "\n", "db = pinnacle(['my.csv'], metadata_store=f'mongomock://meta')"]}, {"cell_type": "code", "execution_count": null, "id": "cb029a5e-fedf-4f07-8a31-d220cfbfbb3d", "metadata": {}, "outputs": [], "source": ["# <tab: MongoMock>\n", "from pinnacledb import pinnacle\n", "\n", "db = pinnacle('mongomock:///test_db')"]}, {"cell_type": "markdown", "id": "032c2e7b-3f54-4263-b778-0fef60596efb", "metadata": {}, "source": ["<!-- TABS -->\n", "## Get useful sample data"]}, {"cell_type": "code", "execution_count": null, "id": "4e7902bd", "metadata": {}, "outputs": [], "source": ["# <tab: Text>\n", "!curl -O https://pinnacledb-public-demo.s3.amazonaws.com/text.json\n", "import json\n", "\n", "with open('text.json', 'r') as f:\n", "    data = json.load(f)"]}, {"cell_type": "code", "execution_count": null, "id": "33486ec7-0316-4e0c-a409-c09ab4c16669", "metadata": {}, "outputs": [], "source": ["# <tab: PDF>\n", "!curl -O https://pinnacledb-public-demo.s3.amazonaws.com/pdfs.zip && unzip pdfs.zip\n", "import os\n", "\n", "data = [f'pdfs/{x}' for x in os.listdir('./pdfs')]\n", "data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- TABS -->\n", "## Setup tables or collections"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB>\n", "# Note this is an optional step for MongoDB\n", "# Users can also work directly with `DataType` if they want to add\n", "# custom data\n", "from pinnacledb import Schema, DataType\n", "from pinnacledb.backends.mongodb import Collection\n", "\n", "table_or_collection = Collection('documents')\n", "USE_SCHEMA = False\n", "datatype = None\n", "\n", "if USE_SCHEMA and isinstance(datatype, DataType):\n", "    schema = Schema(fields={'x': datatype})\n", "    db.apply(schema)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: SQL>\n", "from pinnacledb.backends.ibis import Table\n", "from pinnacledb.backends.ibis.field_types import FieldType\n", "\n", "if isinstance(datatype, DataType):\n", "    schema = Schema(fields={'x': datatype})\n", "else:\n", "    schema = Schema(fields={'x': FieldType(datatype)})\n", "\n", "table_or_collection = Table('documents', schema=schema)\n", "\n", "db.apply(table_or_collection)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- TABS -->\n", "## Insert data\n", "\n", "In order to create data, we need to create a `Schema` for encoding our special `Datatype` column(s) in the databackend."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB>\n", "from pinnacledb import Document\n", "\n", "def do_insert(data):\n", "    schema = None\n", "    \n", "    if schema is None and datatype is None:\n", "        data = [Document({'x': x}) for x in data]\n", "        db.execute(table_or_collection.insert_many(data))\n", "    elif schema is None and datatype is not None:\n", "        data = [Document({'x': datatype(x)}) for x in data]\n", "        db.execute(table_or_collection.insert_many(data))\n", "    else:\n", "        data = [Document({'x': x}) for x in data]\n", "        db.execute(table_or_collection.insert_many(data, schema='my_schema'))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: SQL>\n", "from pinnacledb import Document\n", "\n", "def do_insert(data):\n", "    db.execute(table_or_collection.insert([Document({'x': x}) for x in data))"]}, {"cell_type": "code", "execution_count": null, "id": "f1630954-44f4-4949-b7d7-600d60431c25", "metadata": {}, "outputs": [], "source": ["do_insert(data[:-len(data) // 4])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- TABS -->\n", "## Build simple select queries"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB>\n", "\n", "select = table_or_collection.find({})"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: SQL>\n", "\n", "select = table_or_collection"]}, {"cell_type": "markdown", "id": "54fea927-ee4a-44cd-aaf2-634b574c316d", "metadata": {}, "source": ["<!-- TABS -->\n", "## Apply a chunker for search"]}, {"cell_type": "markdown", "id": "06d90bda-e8c4-494e-a38c-837fb63689ae", "metadata": {}, "source": [":::note\n", "Note that applying a chunker is ***not*** mandatory for search.\n", "If your data is already chunked (e.g. short text snippets or audio) or if you\n", "are searching through something like images, which can't be chunked, then this\n", "won't be necessary.\n", ":::"]}, {"cell_type": "code", "execution_count": null, "id": "2d20eaa0-a416-4483-938e-23f79845739a", "metadata": {}, "outputs": [], "source": ["# <tab: Text>\n", "from pinnacledb import objectmodel\n", "\n", "CHUNK_SIZE = 200\n", "\n", "@objectmodel(flatten=True, model_update_kwargs={'document_embedded': False})\n", "def chunker(text):\n", "    text = text.split()\n", "    chunks = [' '.join(text[i:i + CHUNK_SIZE]) for i in range(0, len(text), CHUNK_SIZE)]\n", "    return chunks"]}, {"cell_type": "code", "execution_count": null, "id": "facd7dc0-fffa-40d8-af72-2b9e4852ad79", "metadata": {}, "outputs": [], "source": ["# <tab: PDF>\n", "!pip install PyPDF2\n", "from pinnacledb import objectmodel\n", "\n", "CHUNK_SIZE = 500\n", "\n", "@objectmodel(flatten=True, model_update_kwargs={'document_embedded': False})\n", "def chunker(pdf_file):\n", "    reader = PyPDF2.PdfReader(pdf_file)\n", "    num_pages = len(reader.pages)\n", "    print(f'Number of pages {num_pages}')\n", "    text = []    \n", "    for i in range(num_pages):\n", "        page = reader.pages[i]        \n", "        page_text = page.extract_text()\n", "        text.append(page_text)\n", "    text = '\\n\\n'.join(text)\n", "    chunks = [text[i:i + CHUNK_SIZE] for i in range(0, len(text), CHUNK_SIZE)]\n", "    return chunks"]}, {"cell_type": "markdown", "id": "b33a16f9-3bac-45bb-80ac-3ccf265dce5f", "metadata": {}, "source": ["Now we apply this chunker to the data by wrapping the chunker in `Listener`:"]}, {"cell_type": "code", "execution_count": null, "id": "93d21872-d4dc-40dc-abab-fb07ba102ea3", "metadata": {}, "outputs": [], "source": ["from pinnacledb import Listener\n", "\n", "upstream_listener = Listener(\n", "    model=chunker,\n", "    select=select,\n", "    key='x',\n", ")\n", "\n", "db.add(upstream_listener)\n", "indexing_key = upstream_listener.outputs"]}, {"cell_type": "markdown", "id": "7c5377c0-4c9b-4ba9-8f08-5e866b9220b5", "metadata": {}, "source": ["## Select outputs of upstream listener"]}, {"cell_type": "markdown", "id": "809f5f62-95c3-483b-ae74-a5cdb5c1c83d", "metadata": {}, "source": [":::note\n", "This is useful if you have performed a first step, such as pre-computing \n", "features, or chunking your data. You can use this query to \n", "operate on those outputs.\n", ":::"]}, {"cell_type": "code", "execution_count": null, "id": "e49b116d-34f5-438a-995e-a8bd59e1dd80", "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB>\n", "from pinnacledb.backends.mongodb import Collection\n", "\n", "select = Collection(upstream_listener.outputs).find()"]}, {"cell_type": "code", "execution_count": null, "id": "a9f1d1aa-701d-4cd6-827e-2356556767cf", "metadata": {}, "outputs": [], "source": ["# <tab: SQL>\n", "select = db.load('table', upstream_listener.outputs)"]}, {"cell_type": "markdown", "id": "c9a2cd87-723f-4cee-87c7-9b8181c9e54b", "metadata": {}, "source": ["<!-- TABS -->\n", "## Build text embedding model"]}, {"cell_type": "code", "execution_count": null, "id": "a9b1f538-65ca-499e-b6d0-2dd733f81723", "metadata": {}, "outputs": [], "source": ["# <tab: OpenAI>\n", "!pip install openai\n", "from pinnacledb.ext.openai import OpenAIEmbedding\n", "model = OpenAIEmbedding(identifier='text-embedding-ada-002')"]}, {"cell_type": "code", "execution_count": null, "id": "e83facd8-8823-492f-a2c6-659f38d8e6ec", "metadata": {}, "outputs": [], "source": ["# <tab: JinaAI>\n", "from pinnacledb.ext.jina import JinaEmbedding\n", " \n", "# define the model\n", "model = JinaEmbedding(identifier='jina-embeddings-v2-base-en')"]}, {"cell_type": "code", "execution_count": null, "id": "3b4a9a60-41df-461d-b165-1d136ee25694", "metadata": {}, "outputs": [], "source": ["# <tab: Sentence-Transformers>\n", "from pinnacledb import vector\n", "import sentence_transformers\n", "from pinnacledb.ext.sentence_transformers import SentenceTransformer\n", "\n", "model = SentenceTransformer(\n", "    identifier=\"embedding\",\n", "    object=sentence_transformers.SentenceTransformer(\"BAAI/bge-small-en\"),\n", "    datatype=vector(shape=(1024,)),\n", "    postprocess=lambda x: x.tolist(),\n", "    predict_kwargs={\"show_progress_bar\": True},\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "b1219380-13ce-4301-90e6-6ede2eee1497", "metadata": {}, "outputs": [], "source": ["# <tab: Transformers>\n", "import dataclasses as dc\n", "from pinnacledb.components.model import _Predictor, ensure_initialized\n", "from transformers import AutoTokenizer, AutoModel\n", "import torch\n", "\n", "@dc.dataclass(kw_only=True)\n", "class TransformerEmbedding(_Predictor):\n", "    pretrained_model_name_or_path : str\n", "\n", "    def init(self):\n", "        self.tokenizer = AutoTokenizer.from_pretrained(self.pretrained_model_name_or_path)\n", "        self.model = AutoModel.from_pretrained(self.pretrained_model_name_or_path)\n", "        self.model.eval()\n", "\n", "    @ensure_initialized\n", "    def predict_one(self, x):\n", "        return self.predict([x])[0]\n", "        \n", "    @ensure_initialized\n", "    def predict(self, dataset):\n", "        encoded_input = self.tokenizer(dataset, padding=True, truncation=True, return_tensors='pt')\n", "        # Compute token embeddings\n", "        with torch.no_grad():\n", "            model_output = self.model(**encoded_input)\n", "            # Perform pooling. In this case, cls pooling.\n", "            sentence_embeddings = model_output[0][:, 0]\n", "        # normalize embeddings\n", "        sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)\n", "        return sentence_embeddings.tolist()\n", "\n", "\n", "model = TransformerEmbedding(identifier=\"embedding\", pretrained_model_name_or_path=\"BAAI/bge-small-en\")"]}, {"cell_type": "code", "execution_count": null, "id": "b9b238cf-56d5-44b4-87b0-9d8d55bdf36f", "metadata": {}, "outputs": [], "source": ["model.predict_one(\"What is SuperDuperDB\")"]}, {"cell_type": "markdown", "id": "41b8b40d-3750-4d7b-aa60-62e07b734b04", "metadata": {}, "source": ["## Create vector-index"]}, {"cell_type": "code", "execution_count": null, "id": "66ee3ff4-880e-477b-bbdf-5b8d89c56de2", "metadata": {}, "outputs": [], "source": ["vector_index_name = 'my-vector-index'"]}, {"cell_type": "code", "execution_count": null, "id": "ffba61c1-2ec8-4411-870a-228439ce4ba5", "metadata": {}, "outputs": [], "source": ["# <tab: 1-Modality>\n", "from pinnacledb import VectorIndex, Listener\n", "\n", "jobs, _ = db.add(\n", "    VectorIndex(\n", "        vector_index_name,\n", "        indexing_listener=Listener(\n", "            key=indexing_key,      # the `Document` key `model` should ingest to create embedding\n", "            select=select,       # a `Select` query telling which data to search over\n", "            model=model,         # a `_Predictor` how to convert data to embeddings\n", "        )\n", "    )\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "4cede653", "metadata": {}, "outputs": [], "source": ["# <tab: 2-Modalities>\n", "from pinnacledb import VectorIndex, Listener\n", "\n", "jobs, _ = db.add(\n", "    VectorIndex(\n", "        vector_index_name,\n", "        indexing_listener=Listener(\n", "            key=indexing_key,      # the `Document` key `model` should ingest to create embedding\n", "            select=select,       # a `Select` query telling which data to search over\n", "            model=model,         # a `_Predictor` how to convert data to embeddings\n", "        ),\n", "        compatible_listener=Listener(\n", "            key=compatible_key,      # the `Document` key `model` should ingest to create embedding\n", "            model=compatible_model,         # a `_Predictor` how to convert data to embeddings\n", "            active=False,\n", "            select=None,\n", "        )\n", "    )\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "067a1203-8dbc-4d0a-aa4a-705d99902d52", "metadata": {}, "outputs": [], "source": ["query_table_or_collection = select.table_or_collection"]}, {"cell_type": "code", "execution_count": null, "id": "23d9fc2c-74d7-458e-959a-a7289739b54e", "metadata": {}, "outputs": [], "source": ["sample_datapoint = data[0]\n", "query = \"Tell me about the SuperDuperDb\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- TABS -->\n", "## Perform a vector search"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from pinnacledb import Document\n", "\n", "if datatype is None:\n", "    item = Document({indexing_key: sample_datapoint})\n", "else:\n", "    item = Document({indexing_key: datatype(sample_datapoint)})"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Once we have this search target, we can execute a search as follows:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB>\n", "select = query_table_or_collection.like(item, vector_index=vector_index_name, n=10).find()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: SQL>\n", "select = query_table_or_collection.like(item)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["results = db.execute(select)"]}, {"cell_type": "markdown", "id": "91142c55-b256-4025-94c2-6c4d215c6975", "metadata": {}, "source": ["<!-- TABS -->\n", "## Create Vector Search Model"]}, {"cell_type": "code", "execution_count": null, "id": "b5b99541-fd10-41c1-b6a7-1da6c1d4dbd7", "metadata": {}, "outputs": [], "source": ["from pinnacledb.base.serializable import Variable\n", "item = {indexing_key: Variable('query')}"]}, {"cell_type": "code", "execution_count": null, "id": "d47799ab-b688-4eb8-82d4-6c0aa1204801", "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB>\n", "from pinnacledb.components.model import QueryModel\n", "\n", "vector_search_model = QueryModel(\n", "    identifier=\"VectorSearch\",\n", "    select=query_table_or_collection.like(item, vector_index=vector_index_name, n=10).find(),\n", "    postprocess=lambda docs: [{\"_id\": doc[\"_id\"], \"text\": doc[indexing_key], \"_source\": doc[\"_source\"]} for doc in docs]\n", ")\n", "vector_search_model.db = db"]}, {"cell_type": "markdown", "id": "1179a67b-4e40-496b-9851-98f32d42faa0", "metadata": {}, "source": ["<!-- TABS -->\n", "## Build LLM"]}, {"cell_type": "code", "execution_count": null, "id": "f98e5ff4", "metadata": {}, "outputs": [], "source": ["# <tab: OpenAI>\n", "from pinnacledb.ext.openai import OpenAIChatCompletion\n", "\n", "llm = OpenAIChatCompletion(identifier='llm', model='gpt-3.5-turbo')"]}, {"cell_type": "code", "execution_count": null, "id": "9bf39c47", "metadata": {}, "outputs": [], "source": ["# <tab: Anthropic>\n", "\n", "from pinnacledb.ext.anthropic import AnthropicCompletions\n", "llm = AnthropicCompletions(identifier='llm', model='claude-2')"]}, {"cell_type": "code", "execution_count": null, "id": "95e48deb", "metadata": {}, "outputs": [], "source": ["# <tab: vLLM>\n", "from pinnacledb.ext.vllm import VllmModel\n", "\n", "predict_kwargs = {\n", "    \"max_tokens\": 1024,\n", "    \"temperature\": 0.8,\n", "}\n", "\n", "\n", "llm = VllmModel(\n", "    identifier=\"llm\",\n", "    model_name=\"TheBloke/Mistral-7B-Instruct-v0.2-AWQ\",\n", "    vllm_kwargs={\n", "        \"gpu_memory_utilization\": 0.7,\n", "        \"max_model_len\": 10240,\n", "        \"quantization\": \"awq\",\n", "    },\n", "    predict_kwargs=predict_kwargs,\n", ")\n"]}, {"cell_type": "code", "execution_count": null, "id": "fe4ac344", "metadata": {}, "outputs": [], "source": ["# <tab: Transformers>\n", "\n", "from pinnacledb.ext.transformers import LLM\n", "\n", "llm = LLM.from_pretrained(\"facebook/opt-125m\", identifier=\"llm\")"]}, {"cell_type": "code", "execution_count": null, "id": "1fdbfae2-af7d-4845-bce5-0cb230e3614e", "metadata": {}, "outputs": [], "source": ["# <tab: Llama.cpp>\n", "!huggingface-cli download Qwen/Qwen1.5-0.5B-Chat-GGUF qwen1_5-0_5b-chat-q8_0.gguf --local-dir . --local-dir-use-symlinks False\n", "\n", "from pinnacledb.ext.llamacpp.model import LlamaCpp\n", "llm = LlamaCpp(identifier=\"llm\", model_name_or_path=\"./qwen1_5-0_5b-chat-q8_0.gguf\")"]}, {"cell_type": "markdown", "id": "eac27684-15cf-4439-bb34-2afc7d330614", "metadata": {}, "source": ["<!-- TABS -->\n", "## Answer question with LLM"]}, {"cell_type": "code", "execution_count": null, "id": "c975509e-843e-47ff-b2c1-8b3a04dbd4e9", "metadata": {}, "outputs": [], "source": ["# <tab: No-context>\n", "\n", "llm.predict_one(query)"]}, {"cell_type": "code", "execution_count": null, "id": "afa081c4-78d3-4431-9f2f-540568d36536", "metadata": {}, "outputs": [], "source": ["# <tab: Prompt>\n", "from pinnacledb import objectmodel\n", "from pinnacledb.components.graph import Graph, input_node\n", "\n", "@objectmodel\n", "def build_prompt(query):\n", "    return f\"Translate the sentence into German: {query}\"\n", "\n", "in_ = input_node('query')\n", "prompt = build_prompt(query=in_)\n", "answer = llm(X=prompt)\n", "prompt_llm = answer.to_graph(\"prompt_llm\")\n", "prompt_llm.predict_one(query)[0]"]}, {"cell_type": "code", "execution_count": null, "id": "618c737d-7936-4f0e-bb60-66327edb120e", "metadata": {}, "outputs": [], "source": ["# <tab: Context>\n", "from pinnacledb import objectmodel\n", "from pinnacledb.components.graph import Graph, input_node\n", "\n", "prompt_template = (\n", "    \"Use the following context snippets, these snippets are not ordered!, Answer the question based on this context.\\n\"\n", "    \"{context}\\n\\n\"\n", "    \"Here's the question: {query}\"\n", ")\n", "\n", "\n", "@objectmodel\n", "def build_prompt(query, docs):\n", "    chunks = [doc[\"text\"] for doc in docs]\n", "    context = \"\\n\\n\".join(chunks)\n", "    prompt = prompt_template.format(context=context, query=query)\n", "    return prompt\n", "    \n", "\n", "in_ = input_node('query')\n", "vector_search_results = vector_search_model(query=in_)\n", "prompt = build_prompt(query=in_, docs=vector_search_results)\n", "answer = llm(X=prompt)\n", "context_llm = answer.to_graph(\"context_llm\")\n", "context_llm.predict_one(query)"]}]}
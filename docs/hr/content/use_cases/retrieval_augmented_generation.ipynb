{"metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.7"}}, "nbformat": 4, "nbformat_minor": 5, "cells": [{"cell_type": "markdown", "id": "38c1a328-fd86-4c5f-bd54-b8664f433608", "metadata": {}, "source": ["<!-- TABS -->\n", "# Retrieval augmented generation"]}, {"cell_type": "markdown", "id": "ec24191c-ed06-4264-9cd1-c8c0d7c23f0b", "metadata": {}, "source": ["The first step in any SuperDuperDB application is to connect to your data-backend with SuperDuperDB:"]}, {"cell_type": "markdown", "id": "32f8484d-2e35-472a-9b24-1a30ec1d144b", "metadata": {}, "source": ["<!-- TABS -->\n", "## Connect to SuperDuperDB"]}, {"cell_type": "code", "execution_count": null, "id": "61976f44-8139-41c0-a73e-569c6d16c4b1", "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB>\n", "from pinnacledb import pinnacle\n", "\n", "db = pinnacle('mongodb://localhost:27017/documents')"]}, {"cell_type": "code", "execution_count": null, "id": "e981a457", "metadata": {}, "outputs": [], "source": ["# <tab: SQLite>\n", "from pinnacledb import pinnacle\n", "\n", "db = pinnacle('sqlite://my_db.db')"]}, {"cell_type": "markdown", "id": "e40544ac-0d97-46df-8bb5-4151baa72406", "metadata": {}, "source": ["Once you have done that you are ready to define your datatype(s) which you would like to \"search\"."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- TABS -->\n", "## Insert data\n", "\n", "In order to create data, we need create a `Schema` for encoding our special `Datatype` column(s) in the databackend."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Here's some sample data to work with:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: Text>\n", "!curl -O https://jupyter-sessions.s3.us-east-2.amazonaws.com/text.json\n", "\n", "import json\n", "with open('text.json') as f:\n", "    data = json.load(f)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: Images>\n", "!curl -O https://jupyter-sessions.s3.us-east-2.amazonaws.com/images.zip\n", "!unzip images.zip\n", "\n", "import os\n", "data = [{'image': f'file://image/{file}'} for file in os.listdir('./images')]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: Audio>\n", "!curl -O https://jupyter-sessions.s3.us-east-2.amazonaws.com/audio.zip\n", "!unzip audio.zip\n", "\n", "import os\n", "data = [{'audio': f'file://audio/{file}'} for file in os.listdir('./audio')]"]}, {"cell_type": "markdown", "metadata": {}, "source": ["The next code-block is only necessary if you're working with a custom `DataType`:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from pinnacledb import Schema, Document\n", "\n", "schema = Schema(\n", "    'my_schema',\n", "    fields={\n", "        'my_key': dt\n", "    }\n", ")\n", "\n", "data = [\n", "    Document({'my_key': item}) for item in data\n", "]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB>\n", "from pinnacledb.backends.mongodb import Collection\n", "\n", "collection = Collection('documents')\n", "\n", "db.execute(collection.insert_many(data))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: SQL>\n", "from pinnacledb.backends.ibis import Table\n", "\n", "table = Table(\n", "    'my_table',\n", "    schema=schema,\n", ")\n", "\n", "db.add(table)\n", "db.execute(table.insert(data))"]}, {"cell_type": "markdown", "id": "c9a2cd87-723f-4cee-87c7-9b8181c9e54b", "metadata": {}, "source": ["<!-- TABS -->\n", "## Build text embedding model"]}, {"cell_type": "code", "execution_count": null, "id": "a9b1f538-65ca-499e-b6d0-2dd733f81723", "metadata": {}, "outputs": [], "source": ["# <tab: OpenAI>\n", "..."]}, {"cell_type": "code", "execution_count": null, "id": "e83facd8-8823-492f-a2c6-659f38d8e6ec", "metadata": {}, "outputs": [], "source": ["# <tab: JinaAI>\n", "..."]}, {"cell_type": "code", "execution_count": null, "id": "3b4a9a60-41df-461d-b165-1d136ee25694", "metadata": {}, "outputs": [], "source": ["# <tab: Sentence-Transformers>\n", "..."]}, {"cell_type": "code", "execution_count": null, "id": "b1219380-13ce-4301-90e6-6ede2eee1497", "metadata": {}, "outputs": [], "source": ["# <tab: Transformers>\n", "..."]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- TABS -->\n", "## Perform a vector search"]}, {"cell_type": "markdown", "metadata": {}, "source": ["- `item` is the item which is to be encoded\n", "- `dt` is the `DataType` instance to apply"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from pinnacledb import Document\n", "\n", "item = Document({'my_key': dt(item)})"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Once we have this search target, we can execute a search as follows:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB>\n", "from pinnacledb.backends.mongodb import Collection\n", "\n", "collection = Collection('documents')\n", "\n", "select = collection.find().like(item)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: SQL>\n", "\n", "# Table was created earlier, before preparing vector-search\n", "table = db.load('table', 'documents')\n", "\n", "select = table.like(item)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["results = db.execute(select)"]}, {"cell_type": "markdown", "id": "1179a67b-4e40-496b-9851-98f32d42faa0", "metadata": {}, "source": ["<!-- TABS -->\n", "## Build LLM"]}, {"cell_type": "code", "execution_count": null, "id": "f98e5ff4", "metadata": {}, "outputs": [], "source": ["# <tab: OpenAI>\n", "\n", "..."]}, {"cell_type": "code", "execution_count": null, "id": "9bf39c47", "metadata": {}, "outputs": [], "source": ["# <tab: Anthropic>\n", "\n", "..."]}, {"cell_type": "code", "execution_count": null, "id": "95e48deb", "metadata": {}, "outputs": [], "source": ["# <tab: vLLM>\n", "\n", "..."]}, {"cell_type": "code", "execution_count": null, "id": "fe4ac344", "metadata": {}, "outputs": [], "source": ["# <tab: Transformers>\n", "\n", "..."]}, {"cell_type": "code", "execution_count": null, "id": "29f98dca", "metadata": {}, "outputs": [], "source": ["# <tab: Llama.cpp>\n", "\n", "..."]}, {"cell_type": "code", "execution_count": null, "id": "3778ab16", "metadata": {}, "outputs": [], "source": ["llm.predict_one(X='Tell me about SuperDuperDB')"]}, {"cell_type": "code", "execution_count": null, "id": "f9c9689c", "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB>\n", "from pinnacledb.components.model import QueryModel\n", "from pinnacledb import Variable, Document\n", "\n", "query_model = QueryModel(\n", "    select=collection.find().like(Document({'my_key': Variable('item')}))\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "c28fdaf6", "metadata": {}, "outputs": [], "source": ["from pinnacledb.components.graph import Graph, Input\n", "from pinnacledb import pinnacle\n", "\n", "\n", "@pinnacle\n", "class PromptBuilder:\n", "    def __init__(self, initial_prompt, post_prompt, key):\n", "        self.inital_prompt = initial_prompt\n", "        self.post_prompt = post_prompt\n", "        self.key = key\n", "\n", "    def __call__(self, X, context):\n", "        return (\n", "            self.initial_prompt + '\\n\\n'\n", "            + [r[self.key] for r in context]\n", "            + self.post_prompt + '\\n\\n'\n", "            + X\n", "        )\n", "\n", "\n", "prompt_builder = PromptBuilder(\n", "    initial_prompt='Answer the following question based on the following facts:',\n", "    post_prompt='Here\\'s the question:',\n", "    key='my_key',\n", ")\n", "\n", "with Graph() as G:\n", "    input = Input('X')\n", "    query_results = query_model(item=input)\n", "    prompt = prompt_builder(X=input, context=query_results)\n", "    output = llm(X=prompt)"]}]}
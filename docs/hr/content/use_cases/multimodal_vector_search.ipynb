{"metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.7"}}, "nbformat": 4, "nbformat_minor": 5, "cells": [{"cell_type": "markdown", "id": "38c1a328-fd86-4c5f-bd54-b8664f433608", "metadata": {}, "source": ["<!-- TABS -->\n", "# Multimodal vector search"]}, {"cell_type": "markdown", "id": "f7a4aab8-86eb-4e1c-9200-0a16ba75b2e6", "metadata": {}, "source": ["<!-- TABS -->\n", "## Configure your production system"]}, {"cell_type": "markdown", "id": "81e7cd59-67d0-4776-aea1-4864aa768f95", "metadata": {}, "source": [":::note\n", "If you would like to use the production features \n", "of SuperDuperDB, then you should set the relevant \n", "connections and configurations in a configuration \n", "file. Otherwise you are welcome to use \"development\" mode \n", "to get going with SuperDuperDB quickly.\n", ":::"]}, {"cell_type": "code", "execution_count": null, "id": "62014646-ccd4-4d10-ac26-1c470f88f2f2", "metadata": {}, "outputs": [], "source": ["import os\n", "\n", "os.makedirs('.pinnacledb', exist_ok=True)\n", "os.environ['pinnacleDB_CONFIG'] = '.pinnacledb/config.yaml'"]}, {"cell_type": "code", "execution_count": null, "id": "8e50edd2-438d-44ab-9da0-0b72197df262", "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB Community>\n", "CFG = '''\n", "data_backend: mongodb://127.0.0.1:27017/documents\n", "artifact_store: filesystem://./artifact_store\n", "cluster:\n", "  cdc:\n", "    strategy: null\n", "    uri: ray://127.0.0.1:20000\n", "  compute:\n", "    uri: ray://127.0.0.1:10001\n", "  vector_search:\n", "    backfill_batch_size: 100\n", "    type: in_memory\n", "    uri: http://127.0.0.1:21000\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "1ad9ee67-6402-45ea-8311-3efb039b5df3", "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB Atlas>\n", "CFG = '''\n", "artifact_store: filesystem://<path-to-artifact-store>\n", "cluster: \n", "    compute: ray://<ray-host>\n", "    cdc:    \n", "        uri: http://<cdc-host>:<cdc-port>\n", "    vector_search:\n", "        uri: http://<vector-search-host>:<vector-search-port>\n", "        type: native\n", "databackend: mongodb+srv://<user>:<password>@<mongo-host>:27017/documents\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "9c9e8351-b17f-4882-bda6-5ad51dbc7e1f", "metadata": {}, "outputs": [], "source": ["# <tab: SQLite>\n", "CFG = '''\n", "artifact_store: filesystem://<path-to-artifact-store>\n", "cluster: \n", "    compute: ray://<ray-host>\n", "    cdc:    \n", "        uri: http://<cdc-host>:<cdc-port>\n", "    vector_search:\n", "        uri: http://<vector-search-host>:<vector-search-port>\n", "databackend: sqlite://<path-to-db>.db\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "d16c66bb-6ff2-4cea-b11c-0a65bf86c7ad", "metadata": {}, "outputs": [], "source": ["# <tab: MySQL>\n", "CFG = '''\n", "artifact_store: filesystem://<path-to-artifact-store>\n", "cluster: \n", "    compute: ray://<ray-host>\n", "    cdc:    \n", "        uri: http://<cdc-host>:<cdc-port>\n", "    vector_search:\n", "        uri: http://<vector-search-host>:<vector-search-port>\n", "databackend: mysql://<user>:<password>@<host>:<port>/database\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "9b7ac715-712c-4ec7-be90-0aaa22518977", "metadata": {}, "outputs": [], "source": ["# <tab: Oracle>\n", "CFG = '''\n", "artifact_store: filesystem://<path-to-artifact-store>\n", "cluster: \n", "    compute: ray://<ray-host>\n", "    cdc:    \n", "        uri: http://<cdc-host>:<cdc-port>\n", "    vector_search:\n", "        uri: http://<vector-search-host>:<vector-search-port>\n", "databackend: mssql://<user>:<password>@<host>:<port>\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "f21fad9c-cc0e-4cf5-83f0-41a3a614c6af", "metadata": {}, "outputs": [], "source": ["# <tab: PostgreSQL>\n", "CFG = '''\n", "artifact_store: filesystem://<path-to-artifact-store>\n", "cluster: \n", "    compute: ray://<ray-host>\n", "    cdc:    \n", "        uri: http://<cdc-host>:<cdc-port>\n", "    vector_search:\n", "        uri: http://<vector-search-host>:<vector-search-port>\n", "databackend: postgres://<user>:<password>@<host>:<port</<database>\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "1badb5a3-823c-4463-ab79-6f4f9239dabe", "metadata": {}, "outputs": [], "source": ["# <tab: Snowflake>\n", "CFG = '''\n", "artifact_store: filesystem://<path-to-artifact-store>\n", "metadata_store: sqlite://<path-to-sqlite-db>.db\n", "cluster: \n", "    compute: ray://<ray-host>\n", "    cdc:    \n", "        uri: http://<cdc-host>:<cdc-port>\n", "    vector_search:\n", "        uri: http://<vector-search-host>:<vector-search-port>\n", "databackend: snowflake://<user>:<password>@<account>/<database>\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "ae7807d9-9fc1-4c18-8027-a512f827783d", "metadata": {}, "outputs": [], "source": ["# <tab: Clickhouse>\n", "CFG = '''\n", "artifact_store: filesystem://<path-to-artifact-store>\n", "metadata_store: sqlite://<path-to-sqlite-db>.db\n", "cluster: \n", "    compute: ray://<ray-host>\n", "    cdc:    \n", "        uri: http://<cdc-host>:<cdc-port>\n", "    vector_search:\n", "        uri: http://<vector-search-host>:<vector-search-port>\n", "databackend: clickhouse://<user>:<password>@<host>:<port>\n", "'''"]}, {"cell_type": "code", "execution_count": null, "id": "fc40c13b-9bc5-47ac-86d6-ef7a379c45ee", "metadata": {}, "outputs": [], "source": ["with open(os.environ['pinnacleDB_CONFIG'], 'w') as f:\n", "    f.write(CFG)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- TABS -->\n", "## Start your cluster"]}, {"cell_type": "markdown", "metadata": {}, "source": [":::note\n", "Starting a SuperDuperDB cluster is useful in production and model development\n", "if you want to enable scalable compute, access to the models by multiple users for collaboration, \n", "monitoring.\n", "\n", "If you don't need this, then it is simpler to start in development mode.\n", ":::"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: Experimental Cluster>\n", "!python -m pinnacledb local-cluster up"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: Docker-Compose>\n", "!make testenv_image\n", "!make testenv_init"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from pinnacledb import pinnacle\n", "\n", "db = pinnacle()"]}, {"cell_type": "markdown", "id": "32f8484d-2e35-472a-9b24-1a30ec1d144b", "metadata": {}, "source": ["<!-- TABS -->\n", "## Connect to SuperDuperDB"]}, {"cell_type": "markdown", "id": "06d66021-ce62-4021-a2c5-158dee92b3bb", "metadata": {}, "source": [":::note\n", "Note that this is only relevant if you are running SuperDuperDB in development mode.\n", "Otherwise refer to \"Configuring your production system\".\n", ":::"]}, {"cell_type": "code", "execution_count": null, "id": "61976f44-8139-41c0-a73e-569c6d16c4b1", "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB>\n", "from pinnacledb import pinnacle\n", "\n", "db = pinnacle('mongodb://localhost:27017/documents')"]}, {"cell_type": "code", "execution_count": null, "id": "e981a457", "metadata": {}, "outputs": [], "source": ["# <tab: SQLite>\n", "from pinnacledb import pinnacle\n", "db = pinnacle('sqlite://my_db.db')"]}, {"cell_type": "code", "execution_count": null, "id": "19ecf7c0-b730-4503-9b5d-e97697b3bcee", "metadata": {}, "outputs": [], "source": ["# <tab: MySQL>\n", "from pinnacledb import pinnacle\n", "\n", "user = 'pinnacle'\n", "password = 'pinnacle'\n", "port = 3306\n", "host = 'localhost'\n", "database = 'test_db'\n", "\n", "db = pinnacle(f\"mysql://{user}:{password}@{host}:{port}/{database}\")"]}, {"cell_type": "code", "execution_count": null, "id": "df208e8c-4fd0-438f-af29-22a763a2aebd", "metadata": {}, "outputs": [], "source": ["# <tab: Oracle>\n", "from pinnacledb import pinnacle\n", "\n", "user = 'sa'\n", "password = 'pinnacle#1'\n", "port = 1433\n", "host = 'localhost'\n", "\n", "db = pinnacle(f\"mssql://{user}:{password}@{host}:{port}\")"]}, {"cell_type": "code", "execution_count": null, "id": "d2297295", "metadata": {}, "outputs": [], "source": ["# <tab: PostgreSQL>\n", "!pip install psycopg2\n", "from pinnacledb import pinnacle\n", "\n", "user = 'postgres'\n", "password = 'postgres'\n", "port = 5432\n", "host = 'localhost'\n", "database = 'test_db'\n", "db_uri = f\"postgres://{user}:{password}@{host}:{port}/{database}\"\n", "\n", "db = pinnacle(db_uri, metadata_store=db_uri.replace('postgres://', 'postgresql://'))"]}, {"cell_type": "code", "execution_count": null, "id": "cc6c8517", "metadata": {}, "outputs": [], "source": ["# <tab: Snowflake>\n", "from pinnacledb import pinnacle\n", "\n", "user = \"pinnacleuser\"\n", "password = \"pinnaclepassword\"\n", "account = \"XXXX-XXXX\"  # ORGANIZATIONID-USERID\n", "database = \"FREE_COMPANY_DATASET/PUBLIC\"\n", "\n", "snowflake_uri = f\"snowflake://{user}:{password}@{account}/{database}\"\n", "\n", "db = pinnacle(\n", "    snowflake_uri, \n", "    metadata_store='sqlite:///your_database_name.db',\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "05da45e3-d9e4-49ca-b9ee-db1b8bf4eb44", "metadata": {}, "outputs": [], "source": ["# <tab: Clickhouse>\n", "from pinnacledb import pinnacle\n", "\n", "user = 'default'\n", "password = ''\n", "port = 8123\n", "host = 'localhost'\n", "\n", "db = pinnacle(f\"clickhouse://{user}:{password}@{host}:{port}\", metadata_store=f'mongomock://meta')"]}, {"cell_type": "code", "execution_count": null, "id": "0e89c8dd-d845-423a-9acc-97e3360d370c", "metadata": {}, "outputs": [], "source": ["# <tab: DuckDB>\n", "from pinnacledb import pinnacle\n", "\n", "db = pinnacle('duckdb://mydb.duckdb')"]}, {"cell_type": "code", "execution_count": null, "id": "2de71562", "metadata": {}, "outputs": [], "source": ["# <tab: Pandas>\n", "from pinnacledb import pinnacle\n", "\n", "db = pinnacle(['my.csv'], metadata_store=f'mongomock://meta')"]}, {"cell_type": "code", "execution_count": null, "id": "cb029a5e-fedf-4f07-8a31-d220cfbfbb3d", "metadata": {}, "outputs": [], "source": ["# <tab: MongoMock>\n", "from pinnacledb import pinnacle\n", "\n", "db = pinnacle('mongomock:///test_db')"]}, {"cell_type": "markdown", "id": "032c2e7b-3f54-4263-b778-0fef60596efb", "metadata": {}, "source": ["<!-- TABS -->\n", "## Get useful sample data"]}, {"cell_type": "code", "execution_count": null, "id": "4e7902bd", "metadata": {}, "outputs": [], "source": ["# <tab: Text>\n", "!curl -O https://pinnacledb-public-demo.s3.amazonaws.com/text.json\n", "import json\n", "\n", "with open('text.json', 'r') as f:\n", "    data = json.load(f)"]}, {"cell_type": "code", "execution_count": null, "id": "33486ec7-0316-4e0c-a409-c09ab4c16669", "metadata": {}, "outputs": [], "source": ["# <tab: PDF>\n", "!curl -O https://pinnacledb-public-demo.s3.amazonaws.com/pdfs.zip && unzip -o pdfs.zip\n", "import os\n", "\n", "data = [f'pdfs/{x}' for x in os.listdir('./pdfs')]\n", "data"]}, {"cell_type": "code", "execution_count": null, "id": "0828031a", "metadata": {}, "outputs": [], "source": ["# <tab: Image>\n", "!curl -O s3://pinnacledb-public-demo/images.zip && unzip images.zip\n", "import os\n", "\n", "data = [f'images/{x}' for x in os.listdir('./images')]"]}, {"cell_type": "code", "execution_count": null, "id": "1b6f7ccb", "metadata": {}, "outputs": [], "source": ["# <tab: Video>\n", "!curl -O s3://pinnacledb-public-demo/videos.zip && unzip videos.zip\n", "import os\n", "\n", "data = [f'videos/{x}' for x in os.listdir('./videos')]"]}, {"cell_type": "code", "execution_count": null, "id": "8abcadac", "metadata": {}, "outputs": [], "source": ["# <tab: Audio>\n", "!curl -O s3://pinnacledb-public-demo/audio.zip && unzip audio.zip\n", "import os\n", "\n", "data = [f'audios/{x}' for x in os.listdir('./audios')]"]}, {"cell_type": "markdown", "id": "b31257e4-06fa-4cc7-9626-bb4d03fdc029", "metadata": {}, "source": ["<!-- TABS -->\n", "## Create datatype"]}, {"cell_type": "markdown", "id": "43284218", "metadata": {}, "source": ["Data types such as \"text\" or \"integer\" which are natively support by your `db.databackend` don't need a datatype."]}, {"cell_type": "code", "execution_count": null, "id": "f7a8d08d", "metadata": {}, "outputs": [], "source": ["datatype = None"]}, {"cell_type": "markdown", "id": "993bb111", "metadata": {}, "source": ["Otherwise do one of the following:"]}, {"cell_type": "code", "execution_count": null, "id": "c486d4fe", "metadata": {}, "outputs": [], "source": ["# <tab: PDF>\n", "!pip install PyPDF2\n", "from pinnacledb import DataType\n", "from pinnacledb.components.datatype import File\n", "\n", "datatype = DataType('pdf', encodable='file')"]}, {"cell_type": "code", "execution_count": null, "id": "5bba2555-da0b-46f2-9a1a-00c5fa107ecc", "metadata": {}, "outputs": [], "source": ["# <tab: Image>\n", "from pinnacledb.ext.pillow import pil_image\n", "import PIL.Image\n", "\n", "datatype = pil_image"]}, {"cell_type": "code", "execution_count": null, "id": "876cfb3b-8d2f-4950-86fb-4bf65accfb98", "metadata": {}, "outputs": [], "source": ["# <tab: Audio>\n", "from pinnacledb.ext.numpy import array\n", "from pinnacledb import DataType\n", "import scipy.io.wavfile\n", "import io\n", "\n", "\n", "def encoder(data):\n", "    buffer = io.BytesIO()\n", "    fs = data[0]\n", "    content = data[1]\n", "    scipy.io.wavfile.write(buffer, fs, content)\n", "    return buffer.getvalue()\n", "\n", "\n", "def decoder(data):\n", "    buffer = io.BytesIO(data)\n", "    content = scipy.io.wavfile.read(buffer)\n", "    return content\n", "\n", "\n", "datatype = DataType(\n", "    'wav',\n", "    encoder=encoder,\n", "    decoder=decoder,\n", "    encodable='artifact',\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "e844c762-3391-401d-9047-ed8617a9c946", "metadata": {}, "outputs": [], "source": ["# <tab: Video>\n", "from pinnacledb import DataType\n", "\n", "# Create an instance of the Encoder with the identifier 'video_on_file' and load_hybrid set to False\n", "datatype = DataType(\n", "    identifier='video_on_file',\n", "    encodable='artifact',\n", ")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- TABS -->\n", "## Setup tables or collections"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB>\n", "# Note this is an optional step for MongoDB\n", "# Users can also work directly with `DataType` if they want to add\n", "# custom data\n", "from pinnacledb import Schema, DataType\n", "from pinnacledb.backends.mongodb import Collection\n", "\n", "table_or_collection = Collection('documents')\n", "USE_SCHEMA = False\n", "datatype = None\n", "\n", "if USE_SCHEMA and isinstance(datatype, DataType):\n", "    schema = Schema(fields={'x': datatype})\n", "    db.apply(schema)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: SQL>\n", "from pinnacledb.backends.ibis import Table\n", "from pinnacledb import Schema, DataType\n", "from pinnacledb.backends.ibis.field_types import dtype\n", "\n", "datatype = \"str\"\n", "\n", "if isinstance(datatype, DataType):\n", "    schema = Schema(identifier=\"schema\", fields={\"id\": dtype(\"str\"), \"x\": datatype})\n", "else:\n", "    schema = Schema(\n", "        identifier=\"schema\", fields={\"id\": dtype(\"str\"), \"x\": dtype(datatype)}\n", "    )\n", "\n", "table_or_collection = Table('documents', schema=schema)\n", "\n", "db.apply(table_or_collection)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- TABS -->\n", "## Insert data\n", "\n", "In order to create data, we need to create a `Schema` for encoding our special `Datatype` column(s) in the databackend."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB>\n", "from pinnacledb import Document\n", "\n", "def do_insert(data):\n", "    schema = None\n", "    \n", "    if schema is None and datatype is None:\n", "        data = [Document({'x': x}) for x in data]\n", "        db.execute(table_or_collection.insert_many(data))\n", "    elif schema is None and datatype is not None:\n", "        data = [Document({'x': datatype(x)}) for x in data]\n", "        db.execute(table_or_collection.insert_many(data))\n", "    else:\n", "        data = [Document({'x': x}) for x in data]\n", "        db.execute(table_or_collection.insert_many(data, schema='my_schema'))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: SQL>\n", "from pinnacledb import Document\n", "\n", "def do_insert(data):\n", "    db.execute(table_or_collection.insert([Document({'id': str(idx), 'x': x}) for idx, x in enumerate(data)]))"]}, {"cell_type": "code", "execution_count": null, "id": "0f9d0da5-2cc1-42bf-868a-1c77f7b1d9c7", "metadata": {}, "outputs": [], "source": ["do_insert(data[:-len(data) // 4])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- TABS -->\n", "## Build simple select queries"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB>\n", "\n", "select = table_or_collection.find({})"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: SQL>\n", "\n", "select = table_or_collection.to_query()"]}, {"cell_type": "markdown", "id": "54fea927-ee4a-44cd-aaf2-634b574c316d", "metadata": {}, "source": ["<!-- TABS -->\n", "## Apply a chunker for search"]}, {"cell_type": "markdown", "id": "06d90bda-e8c4-494e-a38c-837fb63689ae", "metadata": {}, "source": [":::note\n", "Note that applying a chunker is ***not*** mandatory for search.\n", "If your data is already chunked (e.g. short text snippets or audio) or if you\n", "are searching through something like images, which can't be chunked, then this\n", "won't be necessary.\n", ":::"]}, {"cell_type": "code", "execution_count": null, "id": "2d20eaa0-a416-4483-938e-23f79845739a", "metadata": {}, "outputs": [], "source": ["# <tab: Text>\n", "from pinnacledb import objectmodel\n", "\n", "CHUNK_SIZE = 200\n", "\n", "@objectmodel(flatten=True, model_update_kwargs={'document_embedded': False}, datatype=model_output_dtype)\n", "def chunker(text):\n", "    text = text.split()\n", "    chunks = [' '.join(text[i:i + CHUNK_SIZE]) for i in range(0, len(text), CHUNK_SIZE)]\n", "    return chunks"]}, {"cell_type": "code", "execution_count": null, "id": "facd7dc0-fffa-40d8-af72-2b9e4852ad79", "metadata": {}, "outputs": [], "source": ["# <tab: PDF>\n", "!pip install -q \"unstructured[pdf]\"\n", "from pinnacledb import objectmodel\n", "from unstructured.partition.pdf import partition_pdf\n", "\n", "CHUNK_SIZE = 500\n", "\n", "@objectmodel(flatten=True, model_update_kwargs={'document_embedded': False}, datatype=model_output_dtype)\n", "def chunker(pdf_file):\n", "    elements = partition_pdf(pdf_file)\n", "    text = '\\n'.join([e.text for e in elements])\n", "    chunks = [text[i:i + CHUNK_SIZE] for i in range(0, len(text), CHUNK_SIZE)]\n", "    return chunks"]}, {"cell_type": "code", "execution_count": null, "id": "f093a6d0-9d2f-4ecf-b1bd-0027302c62de", "metadata": {}, "outputs": [], "source": ["# <tab: Video>\n", "!pip install opencv-python\n", "import cv2\n", "import tqdm\n", "from PIL import Image\n", "from pinnacledb.ext.pillow import pil_image\n", "from pinnacledb import ObjectModel, Schema\n", "\n", "\n", "@objectmodel(\n", "    flatten=True,\n", "    model_update_kwargs={'document_embedded': False},\n", "    output_schema=Schema(identifier='output-schema', fields={'image': pil_image}),\n", ")\n", "def chunker(video_file):\n", "    # Set the sampling frequency for frames\n", "    sample_freq = 10\n", "    \n", "    # Open the video file using OpenCV\n", "    cap = cv2.VideoCapture(video_file)\n", "    \n", "    # Initialize variables\n", "    frame_count = 0\n", "    fps = cap.get(cv2.CAP_PROP_FPS)\n", "    extracted_frames = []\n", "    progress = tqdm.tqdm()\n", "\n", "    # Iterate through video frames\n", "    while True:\n", "        ret, frame = cap.read()\n", "        if not ret:\n", "            break\n", "        \n", "        # Get the current timestamp based on frame count and FPS\n", "        current_timestamp = frame_count // fps\n", "        \n", "        # Sample frames based on the specified frequency\n", "        if frame_count % sample_freq == 0:\n", "            extracted_frames.append({\n", "                'image': Image.fromarray(frame[:,:,::-1]),  # Convert BGR to RGB\n", "                'current_timestamp': current_timestamp,\n", "            })\n", "        frame_count += 1\n", "        progress.update(1)\n", "    \n", "    # Release resources\n", "    cap.release()\n", "    cv2.destroyAllWindows()\n", "    \n", "    # Return the list of extracted frames\n", "    return extracted_frames"]}, {"cell_type": "code", "execution_count": null, "id": "20f4db9f-bea2-4156-bd78-11eb3bbcf637", "metadata": {}, "outputs": [], "source": ["# <tab: Audio>\n", "from pinnacledb import objectmodel, Schema\n", "\n", "CHUNK_SIZE = 10  # in seconds\n", "\n", "@objectmodel(\n", "    flatten=True,\n", "    model_update_kwargs={'document_embedded': False},\n", "    output_schema=Schema(identifier='output-schema', fields={'audio': datatype}),\n", ")\n", "def chunker(audio):\n", "    chunks = []\n", "    for i in range(0, len(audio), CHUNK_SIZE):\n", "        chunks.append(audio[1][i: i + CHUNK_SIZE])\n", "    return [(audio[0], chunk) for chunk in chunks]"]}, {"cell_type": "markdown", "id": "b33a16f9-3bac-45bb-80ac-3ccf265dce5f", "metadata": {}, "source": ["Now we apply this chunker to the data by wrapping the chunker in `Listener`:"]}, {"cell_type": "code", "execution_count": null, "id": "93d21872-d4dc-40dc-abab-fb07ba102ea3", "metadata": {}, "outputs": [], "source": ["from pinnacledb import Listener\n", "\n", "upstream_listener = Listener(\n", "    model=chunker,\n", "    select=select,\n", "    key='x',\n", ")\n", "\n", "db.apply(upstream_listener)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- TABS -->\n", "## Build multimodal embedding models"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Some embedding models such as [CLIP](https://github.com/openai/CLIP) come in pairs of `model` and `compatible_model`.\n", "Otherwise:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["compatible_model = None"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: Text>\n", "from pinnacledb.ext.sentence_transformers import SentenceTransformer\n", "from pinnacledb import vector\n", "\n", "# Load the pre-trained sentence transformer model\n", "model = SentenceTransformer(\n", "    identifier='all-MiniLM-L6-v2',\n", "    postprocess=lambda x: x.tolist(),\n", "    datatype=vector(shape=(784,)),\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: Image>\n", "from torchvision import transforms\n", "import torch\n", "import torch.nn as nn\n", "import torchvision.models as models\n", "\n", "import warnings\n", "\n", "# Import custom modules\n", "from pinnacledb.ext.torch import TorchModel, tensor\n", "\n", "# Define a series of image transformations using torchvision.transforms.Compose\n", "t = transforms.Compose([\n", "    transforms.Resize((224, 224)),   # Resize the input image to 224x224 pixels (must same as here)\n", "    transforms.CenterCrop((224, 224)),  # Perform a center crop on the resized image\n", "    transforms.ToTensor(),  # Convert the image to a PyTorch tensor\n", "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalize the tensor with specified mean and standard deviation\n", "])\n", "\n", "# Define a preprocess function that applies the defined transformations to an input image\n", "def preprocess(x):\n", "    try:\n", "        return t(x)\n", "    except Exception as e:\n", "        # If an exception occurs during preprocessing, issue a warning and return a tensor of zeros\n", "        warnings.warn(str(e))\n", "        return torch.zeros(3, 224, 224)\n", "\n", "# Load the pre-trained ResNet-50 model from torchvision\n", "resnet50 = models.resnet50(pretrained=True)\n", "\n", "# Extract all layers of the ResNet-50 model except the last one\n", "modules = list(resnet50.children())[:-1]\n", "resnet50 = nn.Sequential(*modules)\n", "\n", "# Create a TorchModel instance with the ResNet-50 model, preprocessing function, and postprocessing lambda\n", "model = TorchModel(\n", "    identifier='resnet50',\n", "    preprocess=preprocess,\n", "    object=resnet50,\n", "    postprocess=lambda x: x[:, 0, 0],  # Postprocess by extracting the top-left element of the output tensor\n", "    encoder=tensor(torch.float, shape=(2048,))  # Specify the encoder configuration\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: Text+Image>\n", "import clip\n", "from pinnacledb import vector\n", "from pinnacledb.ext.torch import TorchModel\n", "\n", "# Load the CLIP model and obtain the preprocessing function\n", "model, preprocess = clip.load(\"RN50\", device='cpu')\n", "\n", "# Define a vector with shape (1024,)\n", "e = vector(shape=(1024,))\n", "\n", "# Create a TorchModel for text encoding\n", "compatible_model = TorchModel(\n", "    identifier='clip_text', # Unique identifier for the model\n", "    object=model, # CLIP model\n", "    preprocess=lambda x: clip.tokenize(x)[0],  # Model input preprocessing using CLIP \n", "    postprocess=lambda x: x.tolist(), # Convert the model output to a list\n", "    encoder=e,  # Vector encoder with shape (1024,)\n", "    forward_method='encode_text', # Use the 'encode_text' method for forward pass \n", ")\n", "\n", "# Create a TorchModel for visual encoding\n", "model = TorchModel(\n", "    identifier='clip_image',  # Unique identifier for the model\n", "    object=model.visual,  # Visual part of the CLIP model    \n", "    preprocess=preprocess, # Visual preprocessing using CLIP\n", "    postprocess=lambda x: x.tolist(), # Convert the output to a list \n", "    encoder=e, # Vector encoder with shape (1024,)\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: Audio>\n", "!pip install librosa\n", "import librosa\n", "import numpy as np\n", "from pinnacledb import Model\n", "\n", "def audio_embedding(audio_file):\n", "    # Load the audio file\n", "    y, sr = librosa.load(audio_file)\n", "    mfccs = librosa.feature.mfcc(y=y, sr=sr)\n", "    return mfccs\n", "\n", "model= Model(identifier='my-model-audio', object=audio_embedding, datatype=vector(shape=(1000,)))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": []}, {"cell_type": "markdown", "id": "7c5377c0-4c9b-4ba9-8f08-5e866b9220b5", "metadata": {}, "source": ["## Select outputs of upstream listener"]}, {"cell_type": "markdown", "id": "809f5f62-95c3-483b-ae74-a5cdb5c1c83d", "metadata": {}, "source": [":::note\n", "This is useful if you have performed a first step, such as pre-computing \n", "features, or chunking your data. You can use this query to \n", "operate on those outputs.\n", ":::"]}, {"cell_type": "code", "execution_count": null, "id": "e49b116d-34f5-438a-995e-a8bd59e1dd80", "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB>\n", "from pinnacledb.backends.mongodb import Collection\n", "\n", "indexing_key = upstream_listener.outputs_key\n", "select = Collection(upstream_listener.outputs).find()"]}, {"cell_type": "code", "execution_count": null, "id": "a9f1d1aa-701d-4cd6-827e-2356556767cf", "metadata": {}, "outputs": [], "source": ["# <tab: SQL>\n", "indexing_key = upstream_listener.outputs_key\n", "select = db.load(\"table\", upstream_listener.outputs).to_query()"]}, {"cell_type": "markdown", "id": "52991f9a-780c-429b-855f-578f2e629be6", "metadata": {}, "source": ["Depending on whether we have chunked the data, \n", "the indexing key will be different:"]}, {"cell_type": "code", "execution_count": null, "id": "9152339b-71e3-4d13-a279-3c9823a95de9", "metadata": {}, "outputs": [], "source": ["# <tab: Chunked Search>\n", "indexing_key = upstream_listener.outputs\n", "compatible_key = 'y'"]}, {"cell_type": "code", "execution_count": null, "id": "12e75fab-8504-4d17-a7d9-f98667a5d6aa", "metadata": {}, "outputs": [], "source": ["# <tab: Un-chunked Search>\n", "indexing_key = 'x'\n", "compatible_key = 'y'"]}, {"cell_type": "markdown", "id": "41b8b40d-3750-4d7b-aa60-62e07b734b04", "metadata": {}, "source": ["## Create vector-index"]}, {"cell_type": "code", "execution_count": null, "id": "66ee3ff4-880e-477b-bbdf-5b8d89c56de2", "metadata": {}, "outputs": [], "source": ["vector_index_name = 'my-vector-index'"]}, {"cell_type": "code", "execution_count": null, "id": "ffba61c1-2ec8-4411-870a-228439ce4ba5", "metadata": {}, "outputs": [], "source": ["# <tab: 1-Modality>\n", "from pinnacledb import VectorIndex, Listener\n", "\n", "jobs, _ = db.add(\n", "    VectorIndex(\n", "        vector_index_name,\n", "        indexing_listener=Listener(\n", "            key=indexing_key,      # the `Document` key `model` should ingest to create embedding\n", "            select=select,       # a `Select` query telling which data to search over\n", "            model=model,         # a `_Predictor` how to convert data to embeddings\n", "        )\n", "    )\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "4cede653", "metadata": {}, "outputs": [], "source": ["# <tab: 2-Modalities>\n", "from pinnacledb import VectorIndex, Listener\n", "\n", "jobs, _ = db.add(\n", "    VectorIndex(\n", "        vector_index_name,\n", "        indexing_listener=Listener(\n", "            key=indexing_key,      # the `Document` key `model` should ingest to create embedding\n", "            select=select,       # a `Select` query telling which data to search over\n", "            model=model,         # a `_Predictor` how to convert data to embeddings\n", "        ),\n", "        compatible_listener=Listener(\n", "            key=compatible_key,      # the `Document` key `model` should ingest to create embedding\n", "            model=compatible_model,         # a `_Predictor` how to convert data to embeddings\n", "            active=False,\n", "            select=None,\n", "        )\n", "    )\n", ")"]}, {"cell_type": "code", "execution_count": null, "id": "067a1203-8dbc-4d0a-aa4a-705d99902d52", "metadata": {}, "outputs": [], "source": ["query_table_or_collection = select.table_or_collection"]}, {"cell_type": "markdown", "metadata": {}, "source": ["<!-- TABS -->\n", "## Perform a vector search"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from pinnacledb import Document\n", "\n", "item = Document({indexing_key: sample_datapoint})"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Once we have this search target, we can execute a search as follows:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB>\n", "select = query_table_or_collection.like(item, vector_index=vector_index_name, n=10).find()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# <tab: SQL>\n", "select = query_table_or_collection.like(item)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["results = db.execute(select)"]}, {"cell_type": "markdown", "id": "52e7c5cb-1519-412d-b09b-1a1fd82ee2ba", "metadata": {}, "source": ["<!-- TABS -->\n", "## Visualize Results"]}, {"cell_type": "code", "execution_count": null, "id": "1afd4e9d-6752-49a9-85ed-625e69f0b54d", "metadata": {}, "outputs": [], "source": ["# <tab: Text>\n", "from IPython.display import Markdown, display\n", "\n", "def visualize(item, source):\n", "    display(Markdown(item))"]}, {"cell_type": "code", "execution_count": null, "id": "8191fe20-d030-4c70-bb3a-1d905370a18b", "metadata": {}, "outputs": [], "source": ["# <tab: Image>\n", "from IPython.display import display\n", "\n", "def visualize(item, source):\n", "    display(item)        # item is a PIL.Image"]}, {"cell_type": "code", "execution_count": null, "id": "1e604bc7-6e83-40c5-98c3-d45ee421e12f", "metadata": {}, "outputs": [], "source": ["# <tab: Audio>\n", "from IPython.display import Audio, display\n", "\n", "def visualize(item, source):\n", "    display(Audio(item[1], fs=item[0]))"]}, {"cell_type": "code", "execution_count": 1, "id": "6d83da69-5963-4eb9-8b63-34b6b094f431", "metadata": {}, "outputs": [], "source": ["# <tab: PDF>\n", "from IPython.display import IFrame, display\n", "\n", "def visualize(item, source):\n", "    display(IFrame(item))"]}, {"cell_type": "code", "execution_count": null, "id": "819855ef-aafa-45fd-9869-5b859375b730", "metadata": {}, "outputs": [], "source": ["# <tab: Video>\n", "from IPython.display import display, HTML\n", "\n", "timestamp = 0     # increment to the frame you want to start at\n", "\n", "# Create HTML code for the video player with a specified source and controls\n", "video_html = f\"\"\"\n", "<video width=\"640\" height=\"480\" controls>\n", "    <source src=\"{video['video'].uri}\" type=\"video/mp4\">\n", "</video>\n", "<script>\n", "    // Get the video element\n", "    var video = document.querySelector('video');\n", "    \n", "    // Set the current time of the video to the specified timestamp\n", "    video.currentTime = {timestamp};\n", "    \n", "    // Play the video automatically\n", "    video.play();\n", "</script>\n", "\"\"\"\n", "\n", "display(HTML(video_html))"]}, {"cell_type": "markdown", "id": "e74a6059-1572-44d5-86af-8f6566b44cbf", "metadata": {}, "source": ["If your use-case involved chunking, you will want to be able to recover original rows/ documents, \n", "after getting the result of a vector-search:"]}, {"cell_type": "code", "execution_count": null, "id": "28969f2c-b405-42a5-9e61-c38d322ccbc7", "metadata": {}, "outputs": [], "source": ["# <tab: MongoDB>\n", "def get_original(_source):\n", "    return db.execute(table_or_collection.find_one({'_id': source}))"]}, {"cell_type": "code", "execution_count": null, "id": "ab870c0c-ce31-4fa3-bdcc-04a88ac4335c", "metadata": {}, "outputs": [], "source": ["# <tab: SQL>\n", "def get_original(_source):\n", "    return next(db.execute(table_or_collection.filter(table_or_collection.id == source).limit(1)))"]}, {"cell_type": "code", "execution_count": null, "id": "fc514a24-4950-4b7c-9d54-5e4c3c7b59d4", "metadata": {}, "outputs": [], "source": ["for result in results:\n", "    source = None\n", "    if '_source' in result:\n", "        source = result['_source']\n", "        result = get_original(source)\n", "    visualize(result['x'], source=source)"]}, {"cell_type": "markdown", "id": "693b4878-39a2-444d-8e17-72a00e6c246d", "metadata": {}, "source": ["## Check the system stays updated"]}, {"cell_type": "code", "execution_count": null, "id": "5ef97f5a-bb41-46ca-a85e-489824741216", "metadata": {}, "outputs": [], "source": ["# <tab: Development>\n", "\n", "do_insert(data[-len(data) // 4:])"]}, {"cell_type": "code", "execution_count": null, "id": "181d3905-d986-4384-857e-ec1e196c56a6", "metadata": {}, "outputs": [], "source": ["# <tab: Cluster>\n", "\n", "# As an example with MongoDB, we show that inserting to/ updating the DB with a different client (potentially from different source)\n", "# still means that the system stays up-to-date. This should work with any Cluster mode compatible DB (see \"Configuring your production system\")\n", "\n", "collection = pymongo.MongoClient('mongodb://<mongo-host>:/27017/<database>')['<database>'].documents\n", "collection.insert_many([{'x': x} for x in data[-len(data) // 4:])"]}]}
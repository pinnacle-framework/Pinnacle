{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1179a67b-4e40-496b-9851-98f32d42faa0",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "# Build LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98e5ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: OpenAI>\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf39c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: Anthropic>\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e48deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: vLLM>\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4ac344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: Transformers>\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f98dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: Llama.cpp>\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3778ab16",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.predict_one(X='Tell me about SuperDuperDB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c9689c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: MongoDB>\n",
    "from pinnacledb.components.model import QueryModel\n",
    "from pinnacledb import Variable, Document\n",
    "\n",
    "query_model = QueryModel(\n",
    "    select=collection.find().like(Document({'my_key': Variable('item')}))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f44f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: SQL>\n",
    "from pinnacledb.components.model import QueryModel\n",
    "from pinnacledb import Variable, Document\n",
    "\n",
    "query_model = QueryModel(\n",
    "    select=table.like(Document({'my_key': Variable('item')}))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4420a7",
   "metadata": {},
   "source": [
    "In order to combine this vector-search component with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28fdaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnacledb.components.graph import Graph\n",
    "from pinnacledb.components.model import Input\n",
    "from pinnacledb import pinnacle\n",
    "\n",
    "\n",
    "@pinnacle\n",
    "class PromptBuilder:\n",
    "    def __init__(self, initial_prompt, post_prompt, key):\n",
    "        self.inital_prompt = initial_prompt\n",
    "        self.post_prompt = post_prompt\n",
    "        self.key = key\n",
    "\n",
    "    def __call__(self, X, context):\n",
    "        return (\n",
    "            self.initial_prompt + '\\n\\n'\n",
    "            + [r[self.key] for r in context]\n",
    "            + self.post_prompt + '\\n\\n'\n",
    "            + X\n",
    "        )\n",
    "\n",
    "\n",
    "prompt_builder = PromptBuilder(\n",
    "    initial_prompt='Answer the following question based on the following facts:',\n",
    "    post_prompt='Here\\'s the question:',\n",
    "    key='my_key',\n",
    ")\n",
    "\n",
    "input = Input('X')\n",
    "query_results = query_model(item=input)\n",
    "prompt = prompt_builder(X=input, context=query_results)\n",
    "output = llm(X=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963c5856",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(output) == AbstractGraph\n",
    "True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04788fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = output.to_listeners(identifier='', select=collection.find(), key='txt')\n",
    "\n",
    "db.add(stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3219a838",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_model = output.to_graph_model()\n",
    "\n",
    "graph_model.predict_one(...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e703b58-a46d-4b1f-98fd-f50d46b168fe",
   "metadata": {},
   "source": [
    "<!-- TABS -->\n",
    "# Compute features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4a022e-0d40-47ac-bf76-dd42b9a27ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <testing: >\n",
    "from pinnacledb import pinnacle, Document\n",
    "from pinnacledb.backends.mongodb import Collection\n",
    "from pinnacledb.ext.numpy import array\n",
    "import numpy as np\n",
    "\n",
    "db = pinnacle('mongomock://temp')\n",
    "select = Collection(\"data\").find()\n",
    "\n",
    "image_array = array(\"float64\", shape=(256, 256, 3))\n",
    "db.add(image_array)\n",
    "\n",
    "datas = []\n",
    "for i in range(10):\n",
    "    data = {\n",
    "        \"text\": str(i),\n",
    "        \"image\": image_array(np.random.random((256,256,3))),\n",
    "        \"input_data\": i\n",
    "    }\n",
    "    datas.append(data)\n",
    "\n",
    "db.execute(Collection(\"data\").insert_many([Document(data) for data in datas]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2e1588-fec8-45a6-b678-fef05fc7b57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: Text>\n",
    "\n",
    "key = 'txt'\n",
    "\n",
    "import sentence_transformers\n",
    "from pinnacledb import vector, Listener\n",
    "from pinnacledb.ext.sentence_transformers import SentenceTransformer\n",
    "\n",
    "pinnaclemodel = SentenceTransformer(\n",
    "    identifier=\"embedding\",\n",
    "    object=sentence_transformers.SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\"),\n",
    "    datatype=vector(shape=(384,)),\n",
    "    postprocess=lambda x: x.tolist(),\n",
    ")\n",
    "\n",
    "jobs, listener = db.apply(\n",
    "    Listener(\n",
    "        model=pinnaclemodel,\n",
    "        select=select,\n",
    "        key=key,\n",
    "        identifier=\"features\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17de589c-4d75-4483-b2ca-77d5c25c2fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: Image>\n",
    "\n",
    "key = 'image'\n",
    "\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from pinnacledb.ext.torch import TorchModel\n",
    "from pinnacledb import Listener\n",
    "from PIL import Image\n",
    "\n",
    "class TorchVisionEmbedding:\n",
    "    def __init__(self):\n",
    "        # Load the pre-trained ResNet-18 model\n",
    "        self.resnet = models.resnet18(pretrained=True)\n",
    "        \n",
    "        # Set the model to evaluation mode\n",
    "        self.resnet.eval()\n",
    "        \n",
    "    def preprocess(self, image_array):\n",
    "        # Preprocess the image\n",
    "        image = Image.fromarray(image_array.astype(np.uint8))\n",
    "        preprocess = preprocess = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        tensor_image = preprocess(image)\n",
    "        return tensor_image\n",
    "        \n",
    "model = TorchVisionEmbedding()\n",
    "pinnaclemodel = TorchModel(identifier='my-vision-model-torch', object=model.resnet, preprocess=model.preprocess, postprocess=lambda x: x.numpy().tolist())\n",
    "\n",
    "jobs, listener = db.apply(\n",
    "    Listener(\n",
    "        model=pinnaclemodel,\n",
    "        select=select,\n",
    "        key=key,\n",
    "        identifier=\"features\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a32bd1-c2c0-4789-aba9-0fc5d1fbfe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: Text-And-Image>\n",
    "import torch\n",
    "import clip\n",
    "from torchvision import transforms\n",
    "from pinnacledb import ObjectModel\n",
    "from pinnacledb import Listener\n",
    "\n",
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "\n",
    "key={'txt': 'txt', 'image': 'image'}\n",
    "\n",
    "class CLIPModel:\n",
    "    def __init__(self):\n",
    "        # Load the CLIP model\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.model, self.preprocess = clip.load(\"RN50\", device=self.device)\n",
    "\n",
    "    def __call__(self, text, image):\n",
    "        with torch.no_grad():\n",
    "            text = clip.tokenize([text]).to(self.device)\n",
    "            image = self.preprocess(Image.fromarray(image.astype(np.uint8))).unsqueeze(0).to(self.device)\n",
    "            image_features = self.model.encode_image(image)[0].numpy().tolist()\n",
    "            text_features = self.model.encode_text(text)[0].numpy().tolist()\n",
    "        return [image_features, text_features]\n",
    "        \n",
    "model = CLIPModel()\n",
    "\n",
    "pinnaclemodel = ObjectModel(identifier=\"clip\", object=model, signature=\"**kwargs\", flatten=True, model_update_kwargs={\"document_embedded\": False})\n",
    "\n",
    "jobs, listener = db.apply(\n",
    "    Listener(\n",
    "        model=pinnaclemodel,\n",
    "        select=select,\n",
    "        key=key\n",
    "        identifier=\"features\"\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ef07dd-9b0c-4040-85c9-a2bdfda0825d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <testing: >\n",
    "datas = list(db.execute(Collection(\"_outputs.features::0\").find()))\n",
    "for data in datas:\n",
    "    print(len(data[\"_outputs.features::0\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49af16d-782d-47ce-bdc5-15cd9b6e61be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: Random>\n",
    "\n",
    "key = 'random'\n",
    "\n",
    "import numpy as np\n",
    "from pinnacledb import pinnacle, ObjectModel, Listener\n",
    "\n",
    "def random(*args, **kwargs):\n",
    "    return np.random.random(1024).tolist()\n",
    "\n",
    "pinnaclemodel = ObjectModel(identifier=\"random\", object=random)\n",
    "\n",
    "jobs, listener = db.apply(\n",
    "    Listener(\n",
    "        model=pinnaclemodel,\n",
    "        select=select,\n",
    "        key=key,\n",
    "        identifier=\"features\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5a5f79-4b80-4534-a322-03260dc9caf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tab: Custom>\n",
    "import numpy as np\n",
    "from pinnacledb import pinnacle, ObjectModel, Listener\n",
    "\n",
    "key = 'custom'\n",
    "\n",
    "# Define any feature calculation function\n",
    "def calc_fake_feature(input_data):\n",
    "    fake_feature = list(range(10))\n",
    "    return fake_feature\n",
    "\n",
    "pinnaclemodel = ObjectModel(identifier=\"fake_feature\", object=calc_fake_feature)\n",
    "\n",
    "jobs, listener = db.apply(\n",
    "    Listener(\n",
    "        model=pinnaclemodel,\n",
    "        select=select,\n",
    "        # key of input_data\n",
    "        key=key,\n",
    "        identifier=\"features\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b730d13d-585a-43ee-b847-87553ef3f428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <testing: >\n",
    "datas = list(db.execute(select.outputs(\"features::0\")))\n",
    "for data in datas:\n",
    "    print(len(data[\"_outputs.features::0\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

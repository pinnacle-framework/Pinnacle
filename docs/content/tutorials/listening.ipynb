{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aff62002-f228-4b86-8889-c8ee1bb7fa02",
   "metadata": {},
   "source": [
    "# Listening for new data\n",
    "\n",
    "In SuperDuperDB, AI models may be configured to listen for newly inserted data.\n",
    "Outputs will be computed over that data and saved back to the data-backend.\n",
    "\n",
    "In this example we show how to configure 3 models to interact when new data is added.\n",
    "\n",
    "1. A featurizing computer vision model (images `->` vectors).\n",
    "1. 2 models evaluating image-2-text similarity to a set of key-words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e546ab-3433-44a3-8de0-7ee7a8960541",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -O https://pinnacledb-public-demo.s3.amazonaws.com/images.zip && unzip images.zip\n",
    "from PIL import Image\n",
    "\n",
    "data = [f'images/{x}' for x in os.listdir('./images')]\n",
    "data = [Image.open(path) for path in data]\n",
    "sample_datapoint = data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065924be-8d12-40e6-a930-2f1bf6b2e28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnacledb import pinnacle\n",
    "\n",
    "db = pinnacle('mongomock://')\n",
    "\n",
    "db['images'].insert_many(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef3d07b-b396-479f-bce1-568232dcfd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "from torchvision import transforms\n",
    "from pinnacledb import ObjectModel\n",
    "from pinnacledb import Listener\n",
    "\n",
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class CLIPModel:\n",
    "    def __init__(self):\n",
    "        # Load the CLIP model\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.model, self.preprocess = clip.load(\"RN50\", device=self.device)\n",
    "\n",
    "    def __call__(self, text, image):\n",
    "        with torch.no_grad():\n",
    "            text = clip.tokenize([text]).to(self.device)\n",
    "            image = self.preprocess(Image.fromarray(image.astype(np.uint8))).unsqueeze(0).to(self.device)\n",
    "            image_features = self.model.encode_image(image)[0].numpy().tolist()\n",
    "            text_features = self.model.encode_text(text)[0].numpy().tolist()\n",
    "        return [image_features, text_features]\n",
    "        \n",
    "\n",
    "model = ObjectModel(\n",
    "    identifier=\"clip\",\n",
    "    object=CLIPModel(),\n",
    "    signature=\"**kwargs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56e896a-5c4f-4943-bc6b-9a36ef8c52b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "listener = model.to_listener(\n",
    "    select=db['images'].find(),\n",
    "    key='image',\n",
    "    identifier='image_predictions',\n",
    ")\n",
    "\n",
    "db.apply(listener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a553db-47ba-4bdf-9644-e63cc21c405c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['hat', 'cat', 'mat']\n",
    "\n",
    "targets = {word: model.predict_one(word) for word in words}\n",
    "\n",
    "class Comparer:\n",
    "    def __init__(self, targets):\n",
    "        self.targets = targets\n",
    "        self.lookup = list(self.targets.keys())\n",
    "        self.matrix = torch.stack(list(self.targets.values()))\n",
    "\n",
    "    def __call__(self, vector):\n",
    "        best = (self.matrix @ vector).topk(1)[1].item()\n",
    "        return self.lookup[best]\n",
    "\n",
    "comparer = ObjectModel(\n",
    "    'comparer',\n",
    "    object=Comparer(targets)).to_listener(\n",
    "        select=db['images'].find(), \n",
    "        key=f'_outputs.{listener.uuid}'\n",
    "    ),\n",
    ")\n",
    "\n",
    "db.apply(comparer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ca02914-dac0-42ac-ac90-d1ebe87e6774",
   "metadata": {},
   "source": [
    "# Basic RAG tutorial with export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ace1e3-1b4f-4c73-9a95-ae6116373a57",
   "metadata": {},
   "source": [
    ":::info\n",
    "In this tutorial we show you how to do retrieval augmented generation (RAG) with `pinnacledb`.\n",
    "Note that this is just an example of the flexibility and power which `pinnacledb` gives \n",
    "to developers. `pinnacledb` is about much more than RAG and LLMs. \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed5486d-133d-468f-befa-014f81ffbc94",
   "metadata": {},
   "source": [
    "As in the vector-search tutorial we'll use `pinnacledb` documentation for the tutorial.\n",
    "We'll add this to a testing database by downloading the data snapshot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "296ae5f2-32a9-4f80-aeb7-44e82baf749b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  720k  100  720k    0     0   681k      0  0:00:01  0:00:01 --:--:--  683k\n",
      "2024-Jun-06 10:03:48.13| INFO     | Duncans-MBP.fritz.box| pinnacledb.base.build:69   | Data Client is ready. mongomock.MongoClient('localhost', 27017)\n",
      "2024-Jun-06 10:03:48.14| INFO     | Duncans-MBP.fritz.box| pinnacledb.base.build:42   | Connecting to Metadata Client with engine:  mongomock.MongoClient('localhost', 27017)\n",
      "2024-Jun-06 10:03:48.14| INFO     | Duncans-MBP.fritz.box| pinnacledb.base.build:155  | Connecting to compute client: None\n",
      "2024-Jun-06 10:03:48.14| INFO     | Duncans-MBP.fritz.box| pinnacledb.base.datalayer:85   | Building Data Layer\n",
      "2024-Jun-06 10:03:48.14| INFO     | Duncans-MBP.fritz.box| pinnacledb.base.build:220  | Configuration: \n",
      " +---------------+------------------+\n",
      "| Configuration |      Value       |\n",
      "+---------------+------------------+\n",
      "|  Data Backend | mongomock://test |\n",
      "+---------------+------------------+\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from pinnacledb import pinnacle, Document\n",
    "\n",
    "db = pinnacle('mongomock://test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58925a6-b8d1-49a8-9b80-c16d215b05c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -O https://pinnacledb-public-demo.s3.amazonaws.com/text.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06a38ff0-7a0d-42de-8d01-9f533740d075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-Jun-06 10:03:55.68| INFO     | Duncans-MBP.fritz.box| pinnacledb.backends.mongodb.data_backend:183  | Table docu does not exist, auto creating...\n",
      "2024-Jun-06 10:03:55.69| INFO     | Duncans-MBP.fritz.box| pinnacledb.backends.local.compute:37   | Submitting job. function:<function callable_job at 0x10d2d4400>\n",
      "2024-Jun-06 10:03:55.70| SUCCESS  | Duncans-MBP.fritz.box| pinnacledb.backends.local.compute:43   | Job submitted on <pinnacledb.backends.local.compute.LocalComputeBackend object at 0x29e05cc50>.  function:<function callable_job at 0x10d2d4400> future:eaf3b4e1-b4c9-4739-b5e9-e4967df3f2fa\n"
     ]
    }
   ],
   "source": [
    "with open('text.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "_ = db['docu'].insert_many([{'txt': r} for r in data]).execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe6ccbe-e12d-4d89-8559-6875d047b593",
   "metadata": {},
   "source": [
    "Let's verify the data in the `db` by querying one datapoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c97c8eb-5ffe-4fe6-87fd-26c9853b3a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document({'txt': \"---\\nsidebar_position: 5\\n---\\n\\n# Encoding data\\n\\nIn AI, typical types of data are:\\n\\n- **Numbers** (integers, floats, etc.)\\n- **Text**\\n- **Images**\\n- **Audio**\\n- **Videos**\\n- **...bespoke in house data**\\n\\nMost databases don't support any data other than numbers and text.\\nSuperDuperDB enables the use of these more interesting data-types using the `Document` wrapper.\\n\\n### `Document`\\n\\nThe `Document` wrapper, wraps dictionaries, and is the container which is used whenever \\ndata is exchanged with your database. That means inputs, and queries, wrap dictionaries \\nused with `Document` and also results are returned wrapped with `Document`.\\n\\nWhenever the `Document` contains data which is in need of specialized serialization,\\nthen the `Document` instance contains calls to `DataType` instances.\\n\\n### `DataType`\\n\\nThe [`DataType` class](../apply_api/datatype), allows users to create and encoder custom datatypes, by providing \\ntheir own encoder/decoder pairs.\\n\\nHere is an example of applying an `DataType` to add an image to a `Document`:\\n\\n```python\\nimport pickle\\nimport PIL.Image\\nfrom pinnacledb import DataType, Document\\n\\nimage = PIL.Image.open('my_image.jpg')\\n\\nmy_image_encoder = DataType(\\n    identifier='my-pil',\\n    encoder=lambda x: pickle.dumps(x),\\n    decoder=lambda x: pickle.loads(x),\\n)\\n\\ndocument = Document({'img': my_image_encoder(image)})\\n```\\n\\nThe bare-bones dictionary may be exposed with `.unpack()`:\\n\\n```python\\n>>> document.unpack()\\n{'img': <PIL.PngImagePlugin.PngImageFile image mode=P size=400x300>}\\n```\\n\\nBy default, data encoded with `DataType` is saved in the database, but developers \\nmay alternatively save data in the `db.artifact_store` instead. \\n\\nThis may be achiever by specifying the `encodable=...` parameter:\\n\\n```python\\nmy_image_encoder = DataType(\\n    identifier='my-pil',\\n    encoder=lambda x: pickle.dumps(x),\\n    decoder=lambda x: pickle.loads(x),\\n    encodable='artifact',    # saves to disk/ db.artifact_store\\n    # encodable='lazy_artifact', # Just in time loading\\n)\\n```\\n\\nThe `encodable` specifies the type of the output of the `__call__` method, \\nwhich will be a subclass of `pinnacledb.components.datatype._BaseEncodable`.\\nThese encodables become leaves in the tree defines by a `Document`.\\n\\n### `Schema`\\n\\nA `Schema` allows developers to connect named fields of dictionaries \\nor columns of `pandas.DataFrame` objects with `DataType` instances.\\n\\nA `Schema` is used, in particular, for SQL databases/ tables, and for \\nmodels that return multiple outputs.\\n\\nHere is an example `Schema`, which is used together with text and image \\nfields:\\n\\n```python\\ns = Schema('my-schema', fields={'my-text': 'str', 'my-image': my_image_encoder})\\n```\\n\", '_fold': 'train', '_id': ObjectId('66616d6b244ce2210d2daa30')})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db['docu'].find_one().execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad947dd-e848-42f3-93b3-7697a8816ed2",
   "metadata": {},
   "source": [
    "The first step in a RAG application is to create a `VectorIndex`. The results of searching \n",
    "with this index will be used as input to the LLM for answering questions.\n",
    "\n",
    "Read about `VectorIndex` [here](../apply_api/vector_index.md) and follow along the tutorial on \n",
    "vector-search [here](./vector_search.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f443ee6-3ff4-4b24-9767-4d295ea1bc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from pinnacledb import code\n",
      "\n",
      "@code\n",
      "def postprocess(x):\n",
      "    return x.tolist()\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dodo/.pyenv/versions/3.11.7/envs/pinnacledb-3.11/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/Users/dodo/.pyenv/versions/3.11.7/envs/pinnacledb-3.11/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-Jun-06 10:04:06.99| INFO     | Duncans-MBP.fritz.box| pinnacledb.backends.local.compute:37   | Submitting job. function:<function method_job at 0x10d2d44a0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "210it [00:00, 152203.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-Jun-06 10:04:08.08| INFO     | Duncans-MBP.fritz.box| pinnacledb.components.model:730  | Computing chunk 0/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4e24a3ecb2743b8ad358b1dcec585a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-Jun-06 10:04:08.97| INFO     | Duncans-MBP.fritz.box| pinnacledb.components.model:754  | Adding 50 model outputs to `db`\n",
      "2024-Jun-06 10:04:08.99| WARNING  | Duncans-MBP.fritz.box| pinnacledb.backends.mongodb.query:313  | Some delete ids are not executed , hence halting execution Please note the partially executed operations wont trigger any `model/listeners` unless CDC is active.\n",
      "2024-Jun-06 10:04:08.99| INFO     | Duncans-MBP.fritz.box| pinnacledb.components.model:730  | Computing chunk 1/4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdaeb307167b4934b24cc69409dc92a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-Jun-06 10:04:09.94| INFO     | Duncans-MBP.fritz.box| pinnacledb.components.model:754  | Adding 50 model outputs to `db`\n",
      "2024-Jun-06 10:04:09.96| WARNING  | Duncans-MBP.fritz.box| pinnacledb.backends.mongodb.query:313  | Some delete ids are not executed , hence halting execution Please note the partially executed operations wont trigger any `model/listeners` unless CDC is active.\n",
      "2024-Jun-06 10:04:09.96| INFO     | Duncans-MBP.fritz.box| pinnacledb.components.model:730  | Computing chunk 2/4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb7a4fa5f4194b76aeadf5f3134f9822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-Jun-06 10:04:10.83| INFO     | Duncans-MBP.fritz.box| pinnacledb.components.model:754  | Adding 50 model outputs to `db`\n",
      "2024-Jun-06 10:04:10.85| WARNING  | Duncans-MBP.fritz.box| pinnacledb.backends.mongodb.query:313  | Some delete ids are not executed , hence halting execution Please note the partially executed operations wont trigger any `model/listeners` unless CDC is active.\n",
      "2024-Jun-06 10:04:10.85| INFO     | Duncans-MBP.fritz.box| pinnacledb.components.model:730  | Computing chunk 3/4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3eac2cdf4ef41d4b5543b90b24b7a11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-Jun-06 10:04:11.75| INFO     | Duncans-MBP.fritz.box| pinnacledb.components.model:754  | Adding 50 model outputs to `db`\n",
      "2024-Jun-06 10:04:11.78| WARNING  | Duncans-MBP.fritz.box| pinnacledb.backends.mongodb.query:313  | Some delete ids are not executed , hence halting execution Please note the partially executed operations wont trigger any `model/listeners` unless CDC is active.\n",
      "2024-Jun-06 10:04:11.78| INFO     | Duncans-MBP.fritz.box| pinnacledb.components.model:730  | Computing chunk 4/4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0775d52f127f4f0eb47b331d0f598131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-Jun-06 10:04:11.99| INFO     | Duncans-MBP.fritz.box| pinnacledb.components.model:754  | Adding 10 model outputs to `db`\n",
      "2024-Jun-06 10:04:11.99| WARNING  | Duncans-MBP.fritz.box| pinnacledb.backends.mongodb.query:313  | Some delete ids are not executed , hence halting execution Please note the partially executed operations wont trigger any `model/listeners` unless CDC is active.\n",
      "2024-Jun-06 10:04:11.99| SUCCESS  | Duncans-MBP.fritz.box| pinnacledb.backends.local.compute:43   | Job submitted on <pinnacledb.backends.local.compute.LocalComputeBackend object at 0x29e05cc50>.  function:<function method_job at 0x10d2d44a0> future:c4c04d78-4592-4572-a818-d1e16f29452b\n",
      "2024-Jun-06 10:04:11.99| INFO     | Duncans-MBP.fritz.box| pinnacledb.backends.local.compute:37   | Submitting job. function:<function callable_job at 0x10d2d4400>\n",
      "2024-Jun-06 10:04:13.23| INFO     | Duncans-MBP.fritz.box| pinnacledb.base.datalayer:169  | Loading vectors of vector-index: 'my-index'\n",
      "2024-Jun-06 10:04:13.24| INFO     | Duncans-MBP.fritz.box| pinnacledb.base.datalayer:179  | docu.find(documents[0], documents[1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading vectors into vector-table...: 210it [00:00, 5069.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-Jun-06 10:04:13.28| SUCCESS  | Duncans-MBP.fritz.box| pinnacledb.backends.local.compute:43   | Job submitted on <pinnacledb.backends.local.compute.LocalComputeBackend object at 0x29e05cc50>.  function:<function callable_job at 0x10d2d4400> future:f7573bec-9da0-41c3-8af7-f0521e2a2887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([<pinnacledb.jobs.job.ComponentJob at 0x2e7acb710>,\n",
       "  <pinnacledb.jobs.job.FunctionJob at 0x2e75a8990>],\n",
       " VectorIndex(identifier='my-index', uuid='f9449dc2-2b75-40bc-8b36-b2e3f0cef0d0', indexing_listener=Listener(identifier='my-listener', uuid='6906d4a7-7dc1-4475-ab2c-a2b07a1ecf72', key='txt', model=SentenceTransformer(preferred_devices=('cuda', 'mps', 'cpu'), device='cpu', identifier='my-embedding', uuid='61960cf2-15b2-45cf-8131-d5d32469f41a', signature='*args,**kwargs', datatype=DataType(identifier='my-vec', uuid='0c29d107-5884-4815-a359-d1fa3a2e1ad5', encoder=None, decoder=None, info=None, shape=(384,), directory=None, encodable='native', bytes_encoding=<BytesEncoding.BYTES: 'Bytes'>, intermediate_type='bytes', media_type=None), output_schema=None, flatten=False, model_update_kwargs={}, predict_kwargs={'show_progress_bar': True}, compute_kwargs={}, validation=None, metric_values={}, num_workers=0, object=SentenceTransformer(\n",
       "   (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "   (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "   (2): Normalize()\n",
       " ), model='all-MiniLM-L6-v2', preprocess=None, postprocess=Code(identifier='', uuid='dedfcaa8-9970-48e4-a97a-4c2c02716c3b', code='from pinnacledb import code\\n\\n@code\\ndef postprocess(x):\\n    return x.tolist()\\n')), select=docu.find(), active=True, predict_kwargs={'max_chunk_size': 50}), compatible_listener=None, measure='cosine', metric_values={}))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinnacledb import Stack, Document, VectorIndex, Listener, vector\n",
    "from pinnacledb.ext.sentence_transformers.model import SentenceTransformer\n",
    "from pinnacledb.base.code import Code\n",
    "\n",
    "def postprocess(x):\n",
    "    return x.tolist()\n",
    "\n",
    "datatype = vector(shape=384, identifier=\"my-vec\")\n",
    "    \n",
    "model = SentenceTransformer(\n",
    "    identifier=\"my-embedding\",\n",
    "    datatype=datatype,\n",
    "    predict_kwargs={\"show_progress_bar\": True},\n",
    "    signature=\"*args,**kwargs\",\n",
    "    model=\"all-MiniLM-L6-v2\",      \n",
    "    device=\"cpu\",\n",
    "    postprocess=Code.from_object(postprocess),\n",
    ")\n",
    "\n",
    "listener = Listener(\n",
    "    identifier=\"my-listener\",\n",
    "    model=model,\n",
    "    key='txt',\n",
    "    select=db['docu'].find(),\n",
    "    predict_kwargs={'max_chunk_size': 50},\n",
    ")\n",
    "\n",
    "vector_index = VectorIndex(\n",
    "    identifier=\"my-index\",\n",
    "    indexing_listener=listener,\n",
    "    measure=\"cosine\"\n",
    ")\n",
    "\n",
    "db.apply(vector_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82d6525-7216-416f-88a5-8e48beb39045",
   "metadata": {},
   "source": [
    "Now that we've set up a `VectorIndex`, we can connect this index with an LLM in a number of ways.\n",
    "A simple way to do that is with the `SequentialModel`. The first part of the `SequentialModel`\n",
    "executes a query and provides the results to the LLM in the second part. \n",
    "\n",
    "The `RetrievalPrompt` component takes a query with a \"free\" `Variable` as input. \n",
    "This gives users great flexibility with regard to how they fetch the context\n",
    "for their downstream models.\n",
    "\n",
    "We're using OpenAI, but you can use any type of LLm with `pinnacledb`. We have several \n",
    "native integrations (see [here](../ai_integraitons/)) but you can also [bring your own model](../models/bring_your_own_model.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19b5b77b-cdb3-4c76-a5c4-bbc57519badb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from pinnacledb import code\n",
      "\n",
      "@code\n",
      "def get_output(c):\n",
      "    return [r['txt'] for r in c]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([],\n",
       " SequentialModel(identifier='rag', uuid='e7c5b77d-824e-422c-9d9a-3e8460fb5469', signature='**kwargs', datatype=None, output_schema=None, flatten=False, model_update_kwargs={}, predict_kwargs={}, compute_kwargs={}, validation=None, metric_values={}, num_workers=0, models=[RetrievalPrompt(identifier='my-prompt', uuid='82c3c897-4a77-4a11-8092-9916d39a2150', signature='**kwargs', datatype=None, output_schema=None, flatten=False, model_update_kwargs={}, predict_kwargs={}, compute_kwargs={}, validation=None, metric_values={}, num_workers=0, preprocess=None, postprocess=Code(identifier='', uuid='34ae5703-7708-4d78-801d-aa4459c373ec', code=\"from pinnacledb import code\\n\\n@code\\ndef get_output(c):\\n    return [r['txt'] for r in c]\\n\"), select=docu.like(documents[0], vector_index=\"my-index\", n=5).find().limit(10), prompt_explanation=\"HERE ARE SOME FACTS SEPARATED BY '---' IN OUR DATA REPOSITORY WHICH WILL HELP YOU ANSWER THE QUESTION.\", prompt_introduction='HERE IS THE QUESTION WHICH YOU SHOULD ANSWER BASED ONLY ON THE PREVIOUS FACTS:', join='\\n---\\n'), OpenAIChatCompletion(identifier='gpt-3.5-turbo', uuid='5060d4b7-3f51-4a0d-b492-3ede7b638e22', signature='singleton', datatype=None, output_schema=None, flatten=False, model_update_kwargs={}, predict_kwargs={}, compute_kwargs={}, validation=None, metric_values={}, num_workers=0, model='gpt-3.5-turbo', max_batch_size=8, openai_api_key=None, openai_api_base=None, client_kwargs={'api_key': '<OPENAI_API_KEY>'}, batch_size=1, prompt='')]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinnacledb.ext.llm.prompter import *\n",
    "from pinnacledb.base.variables import Variable\n",
    "from pinnacledb import Document\n",
    "from pinnacledb.components.model import SequentialModel\n",
    "from pinnacledb.ext.openai import OpenAIChatCompletion\n",
    "\n",
    "q = db['docu'].like(Document({'txt': Variable('prompt')}), vector_index='my-index', n=5).find().limit(10)\n",
    "\n",
    "def get_output(c):\n",
    "    return [r['txt'] for r in c]\n",
    "\n",
    "prompt_template = RetrievalPrompt('my-prompt', select=q, postprocess=Code.from_object(get_output))\n",
    "\n",
    "llm = OpenAIChatCompletion(\n",
    "    'gpt-3.5-turbo',\n",
    "    client_kwargs={'api_key': os.environ['OPENAI_API_KEY']},\n",
    ")\n",
    "seq = SequentialModel('rag', models=[prompt_template, llm])\n",
    "\n",
    "db.apply(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75784c5-bfbc-4892-8788-e0f9e576c072",
   "metadata": {},
   "source": [
    "Now we can test the `SequentialModel` with a sample question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "428caeee-5e82-4268-9bd5-1499fc21667b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-Jun-06 10:04:27.90| INFO     | Duncans-MBP.fritz.box| pinnacledb.base.datalayer:1052 | {}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22e09689c5254b6c961540705f153703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Vector-indexes in SuperDuperDB are components that are applied to the datalayer in order to enable vector-search functionality. They allow developers to perform vector-search queries by using the `.like` operator along with a specified vector index. This index is responsible for converting the input operand into a vector using registered models, comparing it to stored vectors, and retrieving the most similar IDs. \\n\\nVector-search queries in SuperDuperDB combine standard database queries with vector-search capabilities, allowing developers to seamlessly integrate vector-search into their existing database operations. Additionally, SuperDuperDB offers sidecar integrations for databases that do not have built-in vector-search implementations, such as in-memory vector-search and Lance vector-search. The LanceVectorSearcher class in the `pinnacledb.vector_search.lance` module provides an implementation of a vector index using the Lance library, allowing for efficient similarity and sorting computations of vectors.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq.predict('Tell be about vector-indexes?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda45127-5cfc-42e9-90cb-3ea987e9281f",
   "metadata": {},
   "source": [
    ":::tip\n",
    "Did you know you can use any tools from the Python ecosystem with `pinnacledb`.\n",
    "That includes `langchain` and `llamaindex` which can be very useful for RAG applications.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdde6df4-283b-46ba-aef1-9248bfccbdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnacledb import Stack\n",
    "\n",
    "stack = Stack('rag', components=[vector_index, seq])\n",
    "\n",
    "stack.export('docs/content/tutorials/rag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb73908e-4a32-4a97-8625-b9b24b9eaab7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m{\n",
      "  \u001b[0m\u001b[1;34m\"_base\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"?:component:stack/rag/5809368e-4d83-4f67-83ac-1eb540017cfb\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[1;34m\"_leaves\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "    \u001b[0m\u001b[1;34m\"pinnacledb/components/vector_index/vector/232a2649119b9619411948dc32785b5addb1549a\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "      \u001b[0m\u001b[1;34m\"_path\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"pinnacledb/components/vector_index/vector\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"shape\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m384\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"identifier\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"my-vec\"\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[1;34m\":component:model/my-embedding/61960cf2-15b2-45cf-8131-d5d32469f41a\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "      \u001b[0m\u001b[1;34m\"_path\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"pinnacledb/ext/sentence_transformers/model/SentenceTransformer\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"preferred_devices\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
      "        \u001b[0;32m\"cuda\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0;32m\"mps\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0;32m\"cpu\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"device\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"cpu\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"identifier\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"my-embedding\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"uuid\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"61960cf2-15b2-45cf-8131-d5d32469f41a\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"signature\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"*args,**kwargs\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"datatype\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"?pinnacledb/components/vector_index/vector/232a2649119b9619411948dc32785b5addb1549a\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"output_schema\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;90mnull\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"flatten\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mfalse\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"model_update_kwargs\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"predict_kwargs\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[1;34m\"show_progress_bar\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mtrue\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"compute_kwargs\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"validation\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;90mnull\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"metric_values\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"num_workers\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m0\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"all-MiniLM-L6-v2\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"preprocess\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;90mnull\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"postprocess\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[1;34m\"_path\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"pinnacledb/base/code/Code\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[1;34m\"identifier\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[1;34m\"uuid\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"dedfcaa8-9970-48e4-a97a-4c2c02716c3b\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[1;34m\"code\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"from pinnacledb import code\\n\\n@code\\ndef postprocess(x):\\n    return x.tolist()\\n\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"type_id\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"model\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"version\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m0\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"hidden\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mfalse\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[1;34m\"query/89c6bbe09d45e024c89b0eb0caaf620a04d608885796fe739fdafadd9ed87ce4\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "      \u001b[0m\u001b[1;34m\"_path\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"pinnacledb/backends/mongodb/query/parse_query\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"documents\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[]\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"query\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"docu.find()\"\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[1;34m\":component:listener/my-listener/6906d4a7-7dc1-4475-ab2c-a2b07a1ecf72\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "      \u001b[0m\u001b[1;34m\"_path\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"pinnacledb/components/listener/Listener\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"identifier\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"my-listener\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"uuid\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"6906d4a7-7dc1-4475-ab2c-a2b07a1ecf72\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"key\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"txt\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"?:component:model/my-embedding/61960cf2-15b2-45cf-8131-d5d32469f41a\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"select\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"?query/89c6bbe09d45e024c89b0eb0caaf620a04d608885796fe739fdafadd9ed87ce4\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"active\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mtrue\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"predict_kwargs\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[1;34m\"max_chunk_size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m50\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"type_id\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"listener\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"version\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m0\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"hidden\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mfalse\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[1;34m\":component:vector_index/my-index/f9449dc2-2b75-40bc-8b36-b2e3f0cef0d0\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "      \u001b[0m\u001b[1;34m\"_path\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"pinnacledb/components/vector_index/VectorIndex\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"identifier\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"my-index\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"uuid\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"f9449dc2-2b75-40bc-8b36-b2e3f0cef0d0\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"indexing_listener\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"?:component:listener/my-listener/6906d4a7-7dc1-4475-ab2c-a2b07a1ecf72\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"compatible_listener\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;90mnull\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"measure\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"cosine\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"metric_values\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"type_id\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"vector_index\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"version\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m0\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"hidden\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mfalse\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[1;34m\"variable/prompt\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "      \u001b[0m\u001b[1;34m\"_path\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"pinnacledb/base/variables/Variable\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"identifier\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"prompt\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"uuid\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"af8d02fa-3379-4817-adf7-5e674adf6f22\"\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[1;34m\"query/d2e7bca73884aee93102dba7d578275fbc35d241a8cbbf4b2aad82fd57b7c805\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "      \u001b[0m\u001b[1;34m\"_path\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"pinnacledb/backends/mongodb/query/parse_query\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"documents\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
      "        \u001b[1;39m{\n",
      "          \u001b[0m\u001b[1;34m\"txt\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"?variable/prompt\"\u001b[0m\u001b[1;39m\n",
      "        \u001b[1;39m}\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"query\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"docu.like(documents[0], vector_index=\\\"my-index\\\", n=5).find().limit(10)\"\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[1;34m\":component:model/my-prompt/82c3c897-4a77-4a11-8092-9916d39a2150\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "      \u001b[0m\u001b[1;34m\"_path\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"pinnacledb/ext/llm/prompter/RetrievalPrompt\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"identifier\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"my-prompt\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"uuid\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"82c3c897-4a77-4a11-8092-9916d39a2150\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"signature\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"**kwargs\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"datatype\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;90mnull\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"output_schema\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;90mnull\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"flatten\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mfalse\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"model_update_kwargs\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"predict_kwargs\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"compute_kwargs\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"validation\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;90mnull\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"metric_values\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"num_workers\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m0\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"preprocess\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;90mnull\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"postprocess\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[1;34m\"_path\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"pinnacledb/base/code/Code\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[1;34m\"identifier\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[1;34m\"uuid\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"34ae5703-7708-4d78-801d-aa4459c373ec\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[1;34m\"code\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"from pinnacledb import code\\n\\n@code\\ndef get_output(c):\\n    return [r['txt'] for r in c]\\n\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"select\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"?query/d2e7bca73884aee93102dba7d578275fbc35d241a8cbbf4b2aad82fd57b7c805\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"prompt_explanation\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"HERE ARE SOME FACTS SEPARATED BY '---' IN OUR DATA REPOSITORY WHICH WILL HELP YOU ANSWER THE QUESTION.\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"prompt_introduction\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"HERE IS THE QUESTION WHICH YOU SHOULD ANSWER BASED ONLY ON THE PREVIOUS FACTS:\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"join\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"\\n---\\n\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"type_id\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"model\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"version\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m0\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"hidden\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mfalse\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[1;34m\":component:model/gpt-3-5-turbo/5060d4b7-3f51-4a0d-b492-3ede7b638e22\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "      \u001b[0m\u001b[1;34m\"_path\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"pinnacledb/ext/openai/model/OpenAIChatCompletion\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"identifier\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"gpt-3.5-turbo\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"uuid\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"5060d4b7-3f51-4a0d-b492-3ede7b638e22\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"signature\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"singleton\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"datatype\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;90mnull\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"output_schema\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;90mnull\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"flatten\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mfalse\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"model_update_kwargs\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"predict_kwargs\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"compute_kwargs\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"validation\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;90mnull\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"metric_values\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"num_workers\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m0\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"gpt-3.5-turbo\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"max_batch_size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m8\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"openai_api_key\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;90mnull\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"openai_api_base\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;90mnull\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"client_kwargs\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[1;34m\"api_key\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\""\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"batch_size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"prompt\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"type_id\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"model\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"version\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m0\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"hidden\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mfalse\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[1;34m\":component:model/rag/e7c5b77d-824e-422c-9d9a-3e8460fb5469\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "      \u001b[0m\u001b[1;34m\"_path\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"pinnacledb/components/model/SequentialModel\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"identifier\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"rag\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"uuid\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"e7c5b77d-824e-422c-9d9a-3e8460fb5469\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"signature\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"**kwargs\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"datatype\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;90mnull\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"output_schema\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;90mnull\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"flatten\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mfalse\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"model_update_kwargs\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"predict_kwargs\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"compute_kwargs\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"validation\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;90mnull\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"metric_values\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"num_workers\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m0\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"models\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
      "        \u001b[0;32m\"?:component:model/my-prompt/82c3c897-4a77-4a11-8092-9916d39a2150\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0;32m\"?:component:model/gpt-3-5-turbo/5060d4b7-3f51-4a0d-b492-3ede7b638e22\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"type_id\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"model\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"version\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m0\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"hidden\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mfalse\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[1;34m\":component:stack/rag/5809368e-4d83-4f67-83ac-1eb540017cfb\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "      \u001b[0m\u001b[1;34m\"_path\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"pinnacledb/components/stack/Stack\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"identifier\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"rag\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"uuid\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"5809368e-4d83-4f67-83ac-1eb540017cfb\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"components\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
      "        \u001b[0;32m\"?:component:vector_index/my-index/f9449dc2-2b75-40bc-8b36-b2e3f0cef0d0\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0;32m\"?:component:model/rag/e7c5b77d-824e-422c-9d9a-3e8460fb5469\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"type_id\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"stack\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"version\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;90mnull\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"hidden\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mfalse\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m\n",
      "  \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[1;34m\"_files\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m\n",
      "\u001b[1;39m}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "cat docs/content/tutorials/rag/component.json | jq ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ca02914-dac0-42ac-ac90-d1ebe87e6774",
   "metadata": {},
   "source": [
    "# Basic RAG tutorial with templates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ace1e3-1b4f-4c73-9a95-ae6116373a57",
   "metadata": {},
   "source": [
    ":::info\n",
    "In this tutorial we show you how to do retrieval augmented generation (RAG) with `pinnacledb`.\n",
    "Note that this is just an example of the flexibility and power which `pinnacledb` gives \n",
    "to developers. `pinnacledb` is about much more than RAG and LLMs. \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed5486d-133d-468f-befa-014f81ffbc94",
   "metadata": {},
   "source": [
    "As in the vector-search tutorial we'll use `pinnacledb` documentation for the tutorial.\n",
    "We'll add this to a testing database by downloading the data snapshot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "693f2a31-e443-499a-88a5-55f4d26de446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  720k  100  720k    0     0   656k      0  0:00:01  0:00:01 --:--:--  661k\n"
     ]
    }
   ],
   "source": [
    "!curl -O https://pinnacledb-public-demo.s3.amazonaws.com/text.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "296ae5f2-32a9-4f80-aeb7-44e82baf749b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-Jun-06 14:03:14.74| INFO     | Duncans-MBP.fritz.box| pinnacledb.base.build:69   | Data Client is ready. mongomock.MongoClient('localhost', 27017)\n",
      "2024-Jun-06 14:03:14.74| INFO     | Duncans-MBP.fritz.box| pinnacledb.base.build:42   | Connecting to Metadata Client with engine:  mongomock.MongoClient('localhost', 27017)\n",
      "2024-Jun-06 14:03:14.74| INFO     | Duncans-MBP.fritz.box| pinnacledb.base.build:155  | Connecting to compute client: None\n",
      "2024-Jun-06 14:03:14.74| INFO     | Duncans-MBP.fritz.box| pinnacledb.base.datalayer:86   | Building Data Layer\n",
      "2024-Jun-06 14:03:14.74| INFO     | Duncans-MBP.fritz.box| pinnacledb.base.build:220  | Configuration: \n",
      " +---------------+------------------+\n",
      "| Configuration |      Value       |\n",
      "+---------------+------------------+\n",
      "|  Data Backend | mongomock://test |\n",
      "+---------------+------------------+\n",
      "2024-Jun-06 14:03:14.75| INFO     | Duncans-MBP.fritz.box| pinnacledb.backends.mongodb.data_backend:191  | Table docu does not exist, auto creating...\n",
      "2024-Jun-06 14:03:14.76| INFO     | Duncans-MBP.fritz.box| pinnacledb.backends.local.compute:37   | Submitting job. function:<function callable_job at 0x1142f5580>\n",
      "2024-Jun-06 14:03:14.77| SUCCESS  | Duncans-MBP.fritz.box| pinnacledb.backends.local.compute:43   | Job submitted on <pinnacledb.backends.local.compute.LocalComputeBackend object at 0x16fad6fd0>.  function:<function callable_job at 0x1142f5580> future:b1d0a71b-81f2-467d-b60f-9e9f351a86a3\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from pinnacledb import pinnacle, Document\n",
    "\n",
    "db = pinnacle('mongomock://test')\n",
    "\n",
    "with open('text.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "_ = db['docu'].insert_many([{'txt': r} for r in data]).execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe6ccbe-e12d-4d89-8559-6875d047b593",
   "metadata": {},
   "source": [
    "Let's verify the data in the `db` by querying one datapoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c97c8eb-5ffe-4fe6-87fd-26c9853b3a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document({'txt': \"---\\nsidebar_position: 5\\n---\\n\\n# Encoding data\\n\\nIn AI, typical types of data are:\\n\\n- **Numbers** (integers, floats, etc.)\\n- **Text**\\n- **Images**\\n- **Audio**\\n- **Videos**\\n- **...bespoke in house data**\\n\\nMost databases don't support any data other than numbers and text.\\nSuperDuperDB enables the use of these more interesting data-types using the `Document` wrapper.\\n\\n### `Document`\\n\\nThe `Document` wrapper, wraps dictionaries, and is the container which is used whenever \\ndata is exchanged with your database. That means inputs, and queries, wrap dictionaries \\nused with `Document` and also results are returned wrapped with `Document`.\\n\\nWhenever the `Document` contains data which is in need of specialized serialization,\\nthen the `Document` instance contains calls to `DataType` instances.\\n\\n### `DataType`\\n\\nThe [`DataType` class](../apply_api/datatype), allows users to create and encoder custom datatypes, by providing \\ntheir own encoder/decoder pairs.\\n\\nHere is an example of applying an `DataType` to add an image to a `Document`:\\n\\n```python\\nimport pickle\\nimport PIL.Image\\nfrom pinnacledb import DataType, Document\\n\\nimage = PIL.Image.open('my_image.jpg')\\n\\nmy_image_encoder = DataType(\\n    identifier='my-pil',\\n    encoder=lambda x: pickle.dumps(x),\\n    decoder=lambda x: pickle.loads(x),\\n)\\n\\ndocument = Document({'img': my_image_encoder(image)})\\n```\\n\\nThe bare-bones dictionary may be exposed with `.unpack()`:\\n\\n```python\\n>>> document.unpack()\\n{'img': <PIL.PngImagePlugin.PngImageFile image mode=P size=400x300>}\\n```\\n\\nBy default, data encoded with `DataType` is saved in the database, but developers \\nmay alternatively save data in the `db.artifact_store` instead. \\n\\nThis may be achiever by specifying the `encodable=...` parameter:\\n\\n```python\\nmy_image_encoder = DataType(\\n    identifier='my-pil',\\n    encoder=lambda x: pickle.dumps(x),\\n    decoder=lambda x: pickle.loads(x),\\n    encodable='artifact',    # saves to disk/ db.artifact_store\\n    # encodable='lazy_artifact', # Just in time loading\\n)\\n```\\n\\nThe `encodable` specifies the type of the output of the `__call__` method, \\nwhich will be a subclass of `pinnacledb.components.datatype._BaseEncodable`.\\nThese encodables become leaves in the tree defines by a `Document`.\\n\\n### `Schema`\\n\\nA `Schema` allows developers to connect named fields of dictionaries \\nor columns of `pandas.DataFrame` objects with `DataType` instances.\\n\\nA `Schema` is used, in particular, for SQL databases/ tables, and for \\nmodels that return multiple outputs.\\n\\nHere is an example `Schema`, which is used together with text and image \\nfields:\\n\\n```python\\ns = Schema('my-schema', fields={'my-text': 'str', 'my-image': my_image_encoder})\\n```\\n\", '_fold': 'train', '_id': ObjectId('6661a582a0e5364ed7fc181c')})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db['docu'].find_one().execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad947dd-e848-42f3-93b3-7697a8816ed2",
   "metadata": {},
   "source": [
    "The first step in a RAG application is to create a `VectorIndex`. The results of searching \n",
    "with this index will be used as input to the LLM for answering questions.\n",
    "\n",
    "Read about `VectorIndex` [here](../apply_api/vector_index.md) and follow along the tutorial on \n",
    "vector-search [here](./vector_search.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f443ee6-3ff4-4b24-9767-4d295ea1bc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from pinnacledb import code\n",
      "\n",
      "@code\n",
      "def postprocess(x):\n",
      "    return x.tolist()\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dodo/.pyenv/versions/3.11.7/envs/pinnacledb-3.11/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/Users/dodo/.pyenv/versions/3.11.7/envs/pinnacledb-3.11/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-Jun-06 14:03:36.07| INFO     | Duncans-MBP.fritz.box| pinnacledb.backends.local.compute:37   | Submitting job. function:<function method_job at 0x1142f5620>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "210it [00:00, 80277.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-Jun-06 14:03:37.27| INFO     | Duncans-MBP.fritz.box| pinnacledb.components.model:730  | Computing chunk 0/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "698d8cd291434109ad487c485bc62739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-Jun-06 14:03:37.91| INFO     | Duncans-MBP.fritz.box| pinnacledb.components.model:754  | Adding 50 model outputs to `db`\n",
      "2024-Jun-06 14:03:37.93| WARNING  | Duncans-MBP.fritz.box| pinnacledb.backends.mongodb.query:313  | Some delete ids are not executed , hence halting execution Please note the partially executed operations wont trigger any `model/listeners` unless CDC is active.\n",
      "2024-Jun-06 14:03:37.93| INFO     | Duncans-MBP.fritz.box| pinnacledb.components.model:730  | Computing chunk 1/4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d7fe36eac5d42029e2ab6859d7d1e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-Jun-06 14:03:38.49| INFO     | Duncans-MBP.fritz.box| pinnacledb.components.model:754  | Adding 50 model outputs to `db`\n",
      "2024-Jun-06 14:03:38.51| WARNING  | Duncans-MBP.fritz.box| pinnacledb.backends.mongodb.query:313  | Some delete ids are not executed , hence halting execution Please note the partially executed operations wont trigger any `model/listeners` unless CDC is active.\n",
      "2024-Jun-06 14:03:38.51| INFO     | Duncans-MBP.fritz.box| pinnacledb.components.model:730  | Computing chunk 2/4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd4498d359f84a638810c0e429cf3824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-Jun-06 14:03:39.07| INFO     | Duncans-MBP.fritz.box| pinnacledb.components.model:754  | Adding 50 model outputs to `db`\n",
      "2024-Jun-06 14:03:39.09| WARNING  | Duncans-MBP.fritz.box| pinnacledb.backends.mongodb.query:313  | Some delete ids are not executed , hence halting execution Please note the partially executed operations wont trigger any `model/listeners` unless CDC is active.\n",
      "2024-Jun-06 14:03:39.09| INFO     | Duncans-MBP.fritz.box| pinnacledb.components.model:730  | Computing chunk 3/4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff2b1357bece4c61966f6f6a58f5a09d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-Jun-06 14:03:39.68| INFO     | Duncans-MBP.fritz.box| pinnacledb.components.model:754  | Adding 50 model outputs to `db`\n",
      "2024-Jun-06 14:03:39.71| WARNING  | Duncans-MBP.fritz.box| pinnacledb.backends.mongodb.query:313  | Some delete ids are not executed , hence halting execution Please note the partially executed operations wont trigger any `model/listeners` unless CDC is active.\n",
      "2024-Jun-06 14:03:39.71| INFO     | Duncans-MBP.fritz.box| pinnacledb.components.model:730  | Computing chunk 4/4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e9ae20f4e04e01bdfa4fdd8fb9e550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-Jun-06 14:03:39.84| INFO     | Duncans-MBP.fritz.box| pinnacledb.components.model:754  | Adding 10 model outputs to `db`\n",
      "2024-Jun-06 14:03:39.84| WARNING  | Duncans-MBP.fritz.box| pinnacledb.backends.mongodb.query:313  | Some delete ids are not executed , hence halting execution Please note the partially executed operations wont trigger any `model/listeners` unless CDC is active.\n",
      "2024-Jun-06 14:03:39.84| SUCCESS  | Duncans-MBP.fritz.box| pinnacledb.backends.local.compute:43   | Job submitted on <pinnacledb.backends.local.compute.LocalComputeBackend object at 0x16fad6fd0>.  function:<function method_job at 0x1142f5620> future:ea790267-73ea-4b5c-a9e9-e3bef259fe6f\n",
      "2024-Jun-06 14:03:39.84| INFO     | Duncans-MBP.fritz.box| pinnacledb.backends.local.compute:37   | Submitting job. function:<function callable_job at 0x1142f5580>\n",
      "2024-Jun-06 14:03:41.00| INFO     | Duncans-MBP.fritz.box| pinnacledb.base.datalayer:170  | Loading vectors of vector-index: 'my-index'\n",
      "2024-Jun-06 14:03:41.00| INFO     | Duncans-MBP.fritz.box| pinnacledb.base.datalayer:180  | docu.find(documents[0], documents[1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading vectors into vector-table...: 210it [00:00, 5126.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-Jun-06 14:03:41.04| SUCCESS  | Duncans-MBP.fritz.box| pinnacledb.backends.local.compute:43   | Job submitted on <pinnacledb.backends.local.compute.LocalComputeBackend object at 0x16fad6fd0>.  function:<function callable_job at 0x1142f5580> future:8dc44a22-f2b5-43bc-a410-0328b8bf6fc1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([<pinnacledb.jobs.job.ComponentJob at 0x2eb37a7d0>,\n",
       "  <pinnacledb.jobs.job.FunctionJob at 0x2e8bc2990>],\n",
       " VectorIndex(identifier='my-index', uuid='a32aae9a-465c-4041-aa82-ecbebbb4e0fb', indexing_listener=Listener(identifier='my-listener', uuid='f2a5cc60-9308-4146-8370-4c0b787292e3', key='txt', model=SentenceTransformer(preferred_devices=('cuda', 'mps', 'cpu'), device='cpu', identifier='my-embedding', uuid='a34389e8-12bf-4bf3-bca7-bbe5c027d859', signature='*args,**kwargs', datatype=DataType(identifier='my-vec', uuid='61eb1d6c-aa94-4f12-8823-55732675b6ce', encoder=None, decoder=None, info=None, shape=(384,), directory=None, encodable='native', bytes_encoding=<BytesEncoding.BYTES: 'Bytes'>, intermediate_type='bytes', media_type=None), output_schema=None, flatten=False, model_update_kwargs={}, predict_kwargs={'show_progress_bar': True}, compute_kwargs={}, validation=None, metric_values={}, num_workers=0, object=SentenceTransformer(\n",
       "   (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "   (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "   (2): Normalize()\n",
       " ), model='all-MiniLM-L6-v2', preprocess=None, postprocess=Code(identifier='', uuid='2c9da7eb-8fdf-4fe6-9c0d-d1f1dd056f6f', code='from pinnacledb import code\\n\\n@code\\ndef postprocess(x):\\n    return x.tolist()\\n')), select=docu.find(), active=True, predict_kwargs={'max_chunk_size': 50}), compatible_listener=None, measure='cosine', metric_values={}))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests \n",
    "\n",
    "from pinnacledb import Stack, Document, VectorIndex, Listener, vector\n",
    "from pinnacledb.ext.sentence_transformers.model import SentenceTransformer\n",
    "from pinnacledb.base.code import Code\n",
    "\n",
    "def postprocess(x):\n",
    "    return x.tolist()\n",
    "\n",
    "datatype = vector(shape=384, identifier=\"my-vec\")\n",
    "    \n",
    "model = SentenceTransformer(\n",
    "    identifier=\"my-embedding\",\n",
    "    datatype=datatype,\n",
    "    predict_kwargs={\"show_progress_bar\": True},\n",
    "    signature=\"*args,**kwargs\",\n",
    "    model=\"all-MiniLM-L6-v2\",      \n",
    "    device=\"cpu\",\n",
    "    postprocess=Code.from_object(postprocess),\n",
    ")\n",
    "\n",
    "listener = Listener(\n",
    "    identifier=\"my-listener\",\n",
    "    model=model,\n",
    "    key='txt',\n",
    "    select=db['docu'].find(),\n",
    "    predict_kwargs={'max_chunk_size': 50},\n",
    ")\n",
    "\n",
    "vector_index = VectorIndex(\n",
    "    identifier=\"my-index\",\n",
    "    indexing_listener=listener,\n",
    "    measure=\"cosine\"\n",
    ")\n",
    "\n",
    "db.apply(vector_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82d6525-7216-416f-88a5-8e48beb39045",
   "metadata": {},
   "source": [
    "Now that we've set up a `VectorIndex`, we can connect this index with an LLM in a number of ways.\n",
    "A simple way to do that is with the `SequentialModel`. The first part of the `SequentialModel`\n",
    "executes a query and provides the results to the LLM in the second part. \n",
    "\n",
    "The `RetrievalPrompt` component takes a query with a \"free\" `Variable` as input. \n",
    "This gives users great flexibility with regard to how they fetch the context\n",
    "for their downstream models.\n",
    "\n",
    "We're using OpenAI, but you can use any type of LLm with `pinnacledb`. We have several \n",
    "native integrations (see [here](../ai_integraitons/)) but you can also [bring your own model](../models/bring_your_own_model.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19b5b77b-cdb3-4c76-a5c4-bbc57519badb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from pinnacledb import code\n",
      "\n",
      "@code\n",
      "def get_output(c):\n",
      "    return [r['txt'] for r in c]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([],\n",
       " SequentialModel(identifier='rag', uuid='c95f5400-c9d4-4cf7-99e3-ec86b685e7f1', signature='**kwargs', datatype=None, output_schema=None, flatten=False, model_update_kwargs={}, predict_kwargs={}, compute_kwargs={}, validation=None, metric_values={}, num_workers=0, models=[RetrievalPrompt(identifier='my-prompt', uuid='5e165724-d78f-47b9-b4e0-f782f21eecf7', signature='**kwargs', datatype=None, output_schema=None, flatten=False, model_update_kwargs={}, predict_kwargs={}, compute_kwargs={}, validation=None, metric_values={}, num_workers=0, preprocess=None, postprocess=Code(identifier='', uuid='9d1e182d-42bc-4ec2-857f-06fb4008dee2', code=\"from pinnacledb import code\\n\\n@code\\ndef get_output(c):\\n    return [r['txt'] for r in c]\\n\"), select=docu.like(documents[0], vector_index=\"my-index\", n=5).find().limit(10), prompt_explanation=\"HERE ARE SOME FACTS SEPARATED BY '---' IN OUR DATA REPOSITORY WHICH WILL HELP YOU ANSWER THE QUESTION.\", prompt_introduction='HERE IS THE QUESTION WHICH YOU SHOULD ANSWER BASED ONLY ON THE PREVIOUS FACTS:', join='\\n---\\n'), OpenAIChatCompletion(identifier='gpt-3.5-turbo', uuid='eb850e54-e5b3-49a2-806c-77808f520a05', signature='singleton', datatype=None, output_schema=None, flatten=False, model_update_kwargs={}, predict_kwargs={}, compute_kwargs={}, validation=None, metric_values={}, num_workers=0, model='gpt-3.5-turbo', max_batch_size=8, openai_api_key=None, openai_api_base=None, client_kwargs={}, batch_size=1, prompt='')]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinnacledb.ext.llm.prompter import *\n",
    "from pinnacledb.base.variables import Variable\n",
    "from pinnacledb import Document\n",
    "from pinnacledb.components.model import SequentialModel\n",
    "from pinnacledb.ext.openai import OpenAIChatCompletion\n",
    "\n",
    "q = db['docu'].like(Document({'txt': Variable('prompt')}), vector_index='my-index', n=5).find().limit(10)\n",
    "\n",
    "def get_output(c):\n",
    "    return [r['txt'] for r in c]\n",
    "\n",
    "prompt_template = RetrievalPrompt('my-prompt', select=q, postprocess=Code.from_object(get_output))\n",
    "\n",
    "llm = OpenAIChatCompletion('gpt-3.5-turbo')\n",
    "seq = SequentialModel('rag', models=[prompt_template, llm])\n",
    "\n",
    "db.apply(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75784c5-bfbc-4892-8788-e0f9e576c072",
   "metadata": {},
   "source": [
    "Now we can test the `SequentialModel` with a sample question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "428caeee-5e82-4268-9bd5-1499fc21667b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-Jun-06 14:04:54.06| INFO     | Duncans-MBP.fritz.box| pinnacledb.base.datalayer:1073 | {}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ffa00ed81634a71aa2364e5a01f8449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Vector-indexes in SuperDuperDB allow users to make their data searchable based on vector embeddings generated by models. Users can wrap a `Listener` or a `Model` instance with a `VectorIndex` to enable vector search capabilities. These indexes can be applied to the data layer to make vector-search queries using the `.like` operator. Additionally, the `LanceVectorSearcher` class in the `pinnacledb.vector_search.lance` module provides an implementation of a vector index with specific parameters such as dimensions, seed vectors, index IDs, and similarity measures. By setting up and using vector-indexes, users can enhance the search functionality of their database by enabling searching based on vector similarities.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq.predict('Tell be about vector-indexes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda45127-5cfc-42e9-90cb-3ea987e9281f",
   "metadata": {},
   "source": [
    ":::tip\n",
    "Did you know you can use any tools from the Python ecosystem with `pinnacledb`.\n",
    "That includes `langchain` and `llamaindex` which can be very useful for RAG applications.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "314bbc1a-a189-402d-be37-9f340c25734d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = Stack('rag', components=[vector_index, seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "069ec70c-93f2-41aa-b0f8-4d2a154d15f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack.export('rag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cb33df7-a908-42bb-a825-a00b2a66d1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m{\n",
      "  \u001b[0m\u001b[1;34m\"_base\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"?:component:stack/rag/37e587f3-91e8-4a4f-b286-2d32398dd0b3\"\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[1;34m\"_leaves\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "    \u001b[0m\u001b[1;34m\"pinnacledb/components/vector_index/vector/232a2649119b9619411948dc32785b5addb1549a\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "      \u001b[0m\u001b[1;34m\"_path\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"pinnacledb/components/vector_index/vector\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"shape\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m384\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"identifier\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"my-vec\"\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[1;34m\":component:model/my-embedding/a34389e8-12bf-4bf3-bca7-bbe5c027d859\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "      \u001b[0m\u001b[1;34m\"_path\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"pinnacledb/ext/sentence_transformers/model/SentenceTransformer\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"preferred_devices\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
      "        \u001b[0;32m\"cuda\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0;32m\"mps\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0;32m\"cpu\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"device\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"cpu\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"identifier\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"my-embedding\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"uuid\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"a34389e8-12bf-4bf3-bca7-bbe5c027d859\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"signature\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"*args,**kwargs\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"datatype\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"?pinnacledb/components/vector_index/vector/232a2649119b9619411948dc32785b5addb1549a\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"output_schema\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;90mnull\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"flatten\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mfalse\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"model_update_kwargs\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"predict_kwargs\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[1;34m\"show_progress_bar\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mtrue\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"compute_kwargs\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"validation\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;90mnull\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"metric_values\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"num_workers\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m0\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"all-MiniLM-L6-v2\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"preprocess\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;90mnull\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"postprocess\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[1;34m\"_path\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"pinnacledb/base/code/Code\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[1;34m\"identifier\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[1;34m\"uuid\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"2c9da7eb-8fdf-4fe6-9c0d-d1f1dd056f6f\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[1;34m\"code\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"from pinnacledb import code\\n\\n@code\\ndef postprocess(x):\\n    return x.tolist()\\n\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"type_id\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"model\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"version\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m0\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"hidden\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mfalse\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[1;34m\"query/89c6bbe09d45e024c89b0eb0caaf620a04d608885796fe739fdafadd9ed87ce4\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "      \u001b[0m\u001b[1;34m\"_path\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"pinnacledb/backends/mongodb/query/parse_query\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"documents\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[]\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"query\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"docu.find()\"\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[1;34m\":component:listener/my-listener/f2a5cc60-9308-4146-8370-4c0b787292e3\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "      \u001b[0m\u001b[1;34m\"_path\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"pinnacledb/components/listener/Listener\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"identifier\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"my-listener\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"uuid\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"f2a5cc60-9308-4146-8370-4c0b787292e3\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"key\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"txt\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"?:component:model/my-embedding/a34389e8-12bf-4bf3-bca7-bbe5c027d859\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"select\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"?query/89c6bbe09d45e024c89b0eb0caaf620a04d608885796fe739fdafadd9ed87ce4\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"active\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mtrue\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"predict_kwargs\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[1;34m\"max_chunk_size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m50\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"type_id\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"listener\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"version\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m0\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"hidden\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mfalse\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[1;34m\":component:vector_index/my-index/a32aae9a-465c-4041-aa82-ecbebbb4e0fb\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "      \u001b[0m\u001b[1;34m\"_path\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"pinnacledb/components/vector_index/VectorIndex\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"identifier\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"my-index\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"uuid\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"a32aae9a-465c-4041-aa82-ecbebbb4e0fb\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"indexing_listener\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"?:component:listener/my-listener/f2a5cc60-9308-4146-8370-4c0b787292e3\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"compatible_listener\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;90mnull\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"measure\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"cosine\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"metric_values\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"type_id\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"vector_index\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"version\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m0\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"hidden\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mfalse\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[1;34m\"variable/prompt\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "      \u001b[0m\u001b[1;34m\"_path\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"pinnacledb/base/variables/Variable\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"identifier\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"prompt\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"uuid\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"2cb12f3d-2fb1-4aae-ab0c-a3afb6166923\"\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[1;34m\"query/d2e7bca73884aee93102dba7d578275fbc35d241a8cbbf4b2aad82fd57b7c805\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "      \u001b[0m\u001b[1;34m\"_path\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"pinnacledb/backends/mongodb/query/parse_query\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"documents\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
      "        \u001b[1;39m{\n",
      "          \u001b[0m\u001b[1;34m\"txt\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"?variable/prompt\"\u001b[0m\u001b[1;39m\n",
      "        \u001b[1;39m}\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"query\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"docu.like(documents[0], vector_index=\\\"my-index\\\", n=5).find().limit(10)\"\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[1;34m\":component:model/my-prompt/5e165724-d78f-47b9-b4e0-f782f21eecf7\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "      \u001b[0m\u001b[1;34m\"_path\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"pinnacledb/ext/llm/prompter/RetrievalPrompt\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"identifier\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"my-prompt\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"uuid\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"5e165724-d78f-47b9-b4e0-f782f21eecf7\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"signature\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"**kwargs\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"datatype\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;90mnull\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"output_schema\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;90mnull\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"flatten\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mfalse\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"model_update_kwargs\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"predict_kwargs\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"compute_kwargs\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"validation\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;90mnull\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"metric_values\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"num_workers\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m0\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"preprocess\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;90mnull\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"postprocess\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "        \u001b[0m\u001b[1;34m\"_path\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"pinnacledb/base/code/Code\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[1;34m\"identifier\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[1;34m\"uuid\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"9d1e182d-42bc-4ec2-857f-06fb4008dee2\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0m\u001b[1;34m\"code\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"from pinnacledb import code\\n\\n@code\\ndef get_output(c):\\n    return [r['txt'] for r in c]\\n\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"select\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"?query/d2e7bca73884aee93102dba7d578275fbc35d241a8cbbf4b2aad82fd57b7c805\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"prompt_explanation\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"HERE ARE SOME FACTS SEPARATED BY '---' IN OUR DATA REPOSITORY WHICH WILL HELP YOU ANSWER THE QUESTION.\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"prompt_introduction\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"HERE IS THE QUESTION WHICH YOU SHOULD ANSWER BASED ONLY ON THE PREVIOUS FACTS:\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"join\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"\\n---\\n\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"type_id\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"model\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"version\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m0\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"hidden\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mfalse\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[1;34m\":component:model/gpt-3-5-turbo/eb850e54-e5b3-49a2-806c-77808f520a05\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "      \u001b[0m\u001b[1;34m\"_path\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"pinnacledb/ext/openai/model/OpenAIChatCompletion\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"identifier\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"gpt-3.5-turbo\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"uuid\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"eb850e54-e5b3-49a2-806c-77808f520a05\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"signature\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"singleton\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"datatype\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;90mnull\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"output_schema\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;90mnull\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"flatten\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mfalse\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"model_update_kwargs\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"predict_kwargs\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"compute_kwargs\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"validation\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;90mnull\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"metric_values\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"num_workers\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m0\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"gpt-3.5-turbo\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"max_batch_size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m8\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"openai_api_key\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;90mnull\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"openai_api_base\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;90mnull\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"client_kwargs\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"batch_size\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m1\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"prompt\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"type_id\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"model\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"version\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m0\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"hidden\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mfalse\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[1;34m\":component:model/rag/c95f5400-c9d4-4cf7-99e3-ec86b685e7f1\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "      \u001b[0m\u001b[1;34m\"_path\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"pinnacledb/components/model/SequentialModel\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"identifier\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"rag\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"uuid\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"c95f5400-c9d4-4cf7-99e3-ec86b685e7f1\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"signature\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"**kwargs\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"datatype\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;90mnull\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"output_schema\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;90mnull\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"flatten\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mfalse\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"model_update_kwargs\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"predict_kwargs\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"compute_kwargs\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"validation\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;90mnull\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"metric_values\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"num_workers\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m0\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"models\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
      "        \u001b[0;32m\"?:component:model/my-prompt/5e165724-d78f-47b9-b4e0-f782f21eecf7\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0;32m\"?:component:model/gpt-3-5-turbo/eb850e54-e5b3-49a2-806c-77808f520a05\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"type_id\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"model\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"version\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39m0\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"hidden\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mfalse\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "    \u001b[0m\u001b[1;34m\":component:stack/rag/37e587f3-91e8-4a4f-b286-2d32398dd0b3\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{\n",
      "      \u001b[0m\u001b[1;34m\"_path\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"pinnacledb/components/stack/Stack\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"identifier\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"rag\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"uuid\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"37e587f3-91e8-4a4f-b286-2d32398dd0b3\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"components\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m[\n",
      "        \u001b[0;32m\"?:component:vector_index/my-index/a32aae9a-465c-4041-aa82-ecbebbb4e0fb\"\u001b[0m\u001b[1;39m,\n",
      "        \u001b[0;32m\"?:component:model/rag/c95f5400-c9d4-4cf7-99e3-ec86b685e7f1\"\u001b[0m\u001b[1;39m\n",
      "      \u001b[1;39m]\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"type_id\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;32m\"stack\"\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"version\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;90mnull\u001b[0m\u001b[1;39m,\n",
      "      \u001b[0m\u001b[1;34m\"hidden\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[0;39mfalse\u001b[0m\u001b[1;39m\n",
      "    \u001b[1;39m}\u001b[0m\u001b[1;39m\n",
      "  \u001b[1;39m}\u001b[0m\u001b[1;39m,\n",
      "  \u001b[0m\u001b[1;34m\"_files\"\u001b[0m\u001b[1;39m: \u001b[0m\u001b[1;39m{}\u001b[0m\u001b[1;39m\n",
      "\u001b[1;39m}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!cat rag/component.json | jq ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

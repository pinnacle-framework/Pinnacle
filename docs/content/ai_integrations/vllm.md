# vLLM


`pinnacle` allows users to work with self-hosted LLM models via "[vLLM](https://github.com/vllm-project/vllm)".

| Class | Description | GitHub | API-docs |
| --- | --- | --- | --- |
| `pinnacle.ext.vllm.VllmModel` | Completes a prompt with natural language (LLM) based on a self hosted LLM | [Code](https://github.com/pinnacle/pinnacle/blob/main/pinnacle/ext/vllm/model.py) | [Docs](/docs/api/ext/vllm/model#vllmmodel) |
| `pinnacle.ext.vllm.VllmAPI` | Completes a prompt with natural language (LLM) based on a self hosted LLM behind the vLLM API server | [Code](https://github.com/pinnacle/pinnacle/blob/main/pinnacle/ext/vllm/model.py) | [Docs](/docs/api/ext/vllm/model#vllmapi) |


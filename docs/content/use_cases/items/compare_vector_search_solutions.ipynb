{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6843aed6",
   "metadata": {},
   "source": [
    "# Turn your classical-database into a vector-database with SuperDuperDB\n",
    "\n",
    "In this notebook we show how you can use SuperDuperDB to turn your classical database into a vector-search database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2adf0f-330d-4af7-b782-3e8530a7cc7c",
   "metadata": {},
   "source": [
    "In this example, we'll be using the `sentence_transformers` with `pinnacledb` python package.\n",
    "In addition, we'll be accessing the OpenAI API. In order to get these working you'll need to install the packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b7288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers\n",
    "!pip install pinnacledb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04229106-d340-43ef-b4cf-0a2addcf17b1",
   "metadata": {},
   "source": [
    "And set the `OPEN_AI_KEY` as environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f50639-1c70-4b2e-898b-c08a9cf99f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = '<YOUR-OPENAI-KEY>'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9110906e",
   "metadata": {},
   "source": [
    "In order to access SuperDuperDB, we'll wrap our standard database connector with the `pinnacle` decorator.\n",
    "This will transform the functionality of your database into a **super-duper** database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7047d51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnacledb import pinnacle\n",
    "import pymongo\n",
    "\n",
    "db = pymongo.MongoClient().documents\n",
    "db = pinnacle(db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028abdfb",
   "metadata": {},
   "source": [
    "In this notebook we upload some wikipedia documents from a wikipedia dump. You can find this raw data here https://dumps.wikimedia.org/enwiki/.\n",
    "\n",
    "We've preprocessed the data, extracting titles and abstracts from each document. We can use this as a test bed for search, by simulating a \"typed query\" using the title, and indexing the document based on the abstracts only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84948ce4-bd76-4cd8-96f9-27f03777aaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random \n",
    "\n",
    "with open(f'{os.environ[\"HOME\"]}/data/wikipedia/abstracts.json') as f:\n",
    "    data = json.load(f)\n",
    "data = random.sample(data, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb728b3-6656-40ee-8b81-5a7974beaae5",
   "metadata": {},
   "source": [
    "Here's a snapshot of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58927e41-9073-40c5-9f6e-3ee15cc84420",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6486fd2-35d8-431d-90cc-76f665eb0526",
   "metadata": {},
   "source": [
    "We now insert the data into MongoDB using the SuperDuperDB client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f621da76-42b6-4d6c-8fe4-f68b5d827bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnacledb.db.mongodb.query import Collection\n",
    "\n",
    "collection = Collection(name='wikipedia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b95e652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnacledb.container.document import Document\n",
    "\n",
    "db.execute(collection.insert_many([Document(r) for r in data]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5e94c5-6156-49ea-85a3-288e961fa138",
   "metadata": {},
   "source": [
    "We can verify that the documents are in the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133aad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = db.execute(collection.find_one())\n",
    "r.unpack()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f1c34f",
   "metadata": {},
   "source": [
    "Creating a vector-index in SuperDuperDB involves two things:\n",
    "\n",
    "- Creating a model which is used to compute vectors (in this case `OpenAIEmbedding`)\n",
    "- Daemonizing this model on a key (`Listener`), so that when new data are added, these are vectorized using the key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e64056-aefa-420a-ba81-69f715d18482",
   "metadata": {},
   "source": [
    "Sentence Transformers are supported by SuperDuperDB, with a wrapper that allows the chosen model to \n",
    "communicate directly with SuperDuperDB. The `encoder` argument specifies how the outputs of the models\n",
    "are saved in the `Datalayer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138ed858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentence_transformers\n",
    "from pinnacledb.container.model import Model\n",
    "from pinnacledb.ext.numpy.array import array\n",
    "\n",
    "model = Model(\n",
    "    identifier='all-MiniLM-L6-v2',\n",
    "    object=sentence_transformers.SentenceTransformer('all-MiniLM-L6-v2'),\n",
    "    encoder=array('float32', shape=(384,)),\n",
    "    predict_method='encode',\n",
    "    batch_predict=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff87b136-fd58-43f7-94bc-816484953e9f",
   "metadata": {},
   "source": [
    "SuperDuperDB also has inbuilt support for OpenAI. You can also integrate APIs from clients, such as the CoherAI\n",
    "client using the Model wrapper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e6be7c-8621-4564-823d-6663c91481cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnacledb.ext.openai.model import OpenAIEmbedding\n",
    "\n",
    "model = OpenAIEmbedding(model='text-embedding-ada-002')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a46a85-aa20-4bd7-b7df-9b5d8a45bdf0",
   "metadata": {},
   "source": [
    "We can test our model (whichever we've chosen) like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fcf9d1-baf6-49d7-939d-2a9ba1f428fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict('This is a test', one=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126da2fb-d9db-4c57-a12c-2328ba19fbbd",
   "metadata": {},
   "source": [
    "We've verified our model gives us vectorial outputs, now let's add the search functionality using this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e60606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinnacledb.container.vector_index import VectorIndex\n",
    "from pinnacledb.container.listener import Listener\n",
    "from pinnacledb.ext.numpy.array import array\n",
    "\n",
    "db.add(\n",
    "    VectorIndex(\n",
    "        identifier=f'wiki-index-{model.identifier}',\n",
    "        indexing_listener=Listener(\n",
    "            model=model,\n",
    "            key='abstract',\n",
    "            select=collection.find(),\n",
    "            predict_kwargs={'max_chunk_size': 1000},\n",
    "        ),\n",
    "        compatible_listener=Listener(\n",
    "            model=model,\n",
    "            key='title',\n",
    "            select=collection.find(),\n",
    "            active=False,\n",
    "        ),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5df9561-3fb3-488e-85c3-f10d49c54c57",
   "metadata": {},
   "source": [
    "We can inspect the functionality which was added like this. The above command creates several components in the single call:\n",
    "\n",
    "- *model*\n",
    "- *listener*\n",
    "- *vector_index*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bf29c9-92ab-44ed-a62c-65949f7d2412",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.show('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8ba502-f7ed-4fc1-8423-3b2b0337a6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.show('listener')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da066cf-f0e7-4475-b692-31135e6820fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.show('vector_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bf5c0f-a6c8-46d0-a76d-821cf4fbb6df",
   "metadata": {},
   "source": [
    "We can now test a few vector searches. The way to do this in combination with your classical database\n",
    "(in this case MongoDB) is to pre-pend the standard query, with a similarity comparison via `like`.\n",
    "\n",
    "The item inside `like` is vectorized and compared with the stored vectors. In order for this to work, the keys in the \n",
    "first parameter to `like` must match those configured in the `Listener` instances inside the `VectorIndex`. The results are then filtered\n",
    "using the classical query part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074ed478",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = db.execute(\n",
    "    collection\n",
    "        .like({'title': 'articles about sport'}, n=10, vector_index=f'wiki-index-{model.identifier}')\n",
    "        .find({}, {'title': 1})\n",
    ")\n",
    "\n",
    "for r in cur:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff25aae-49ef-4946-8086-07a0b3531557",
   "metadata": {},
   "source": [
    "The benefit of having this combination is demonstrated in this query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6c185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = db.execute(\n",
    "    collection\n",
    "        .like({'title': 'articles about sport'}, n=100, vector_index=f'wiki-index-{model.identifier}')\n",
    "        .find({'title': {'$regex': '.*Australia'}})\n",
    ")\n",
    "\n",
    "for r in cur:\n",
    "    print(r['title'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

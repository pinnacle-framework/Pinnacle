{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50891727",
   "metadata": {},
   "source": [
    "# Running computations on Dask\n",
    "\n",
    "In this example, we show how to run computations on a Dask cluster, rather than in the same process as \n",
    "data is submitted from. This allows compute to be scaled horizontally, and also submitted to \n",
    "workers, which may utilize specialized hardware, including GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbd6eee",
   "metadata": {},
   "source": [
    "To do this, we need to override the default configuration. To do this, we only need specify the \n",
    "configurations which diverge from the defaults. In particular, to use a Dask cluster, we specify \n",
    "`CFG.distributed = True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8d5a9ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"distributed\": true}\r\n"
     ]
    }
   ],
   "source": [
    "!echo '{\"distributed\": true}' > configs.json\n",
    "!cat configs.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d840df3",
   "metadata": {},
   "source": [
    "We can now confirm, by importing the loaded configuration `CFG`, that `CFG.distribute == True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34229af6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'apis': {'providers': {},\n",
      "          'retry': {'stop_after_attempt': 2,\n",
      "                    'wait_max': 10.0,\n",
      "                    'wait_min': 4.0,\n",
      "                    'wait_multiplier': 1.0}},\n",
      " 'cdc': False,\n",
      " 'dask': {'deserializers': [],\n",
      "          'ip': 'localhost',\n",
      "          'local': True,\n",
      "          'password': '',\n",
      "          'port': 8786,\n",
      "          'serializers': [],\n",
      "          'username': ''},\n",
      " 'data_layers': {'artifact': {'cls': 'mongodb',\n",
      "                              'connection': 'pymongo',\n",
      "                              'kwargs': {'host': 'localhost',\n",
      "                                         'password': 'testmongodbpassword',\n",
      "                                         'port': 27018,\n",
      "                                         'username': 'testmongodbuser'},\n",
      "                              'name': '_filesystem:test_db'},\n",
      "                 'data_backend': {'cls': 'mongodb',\n",
      "                                  'connection': 'pymongo',\n",
      "                                  'kwargs': {'host': 'localhost',\n",
      "                                             'password': 'testmongodbpassword',\n",
      "                                             'port': 27018,\n",
      "                                             'username': 'testmongodbuser'},\n",
      "                                  'name': 'test_db'},\n",
      "                 'metadata': {'cls': 'mongodb',\n",
      "                              'connection': 'pymongo',\n",
      "                              'kwargs': {'host': 'localhost',\n",
      "                                         'password': 'testmongodbpassword',\n",
      "                                         'port': 27018,\n",
      "                                         'username': 'testmongodbuser'},\n",
      "                              'name': 'test_db'}},\n",
      " 'distributed': True,\n",
      " 'logging': {'kwargs': {},\n",
      "             'level': <LogLevel.INFO: 'INFO'>,\n",
      "             'type': <LogType.STDERR: 'STDERR'>},\n",
      " 'model_server': {'host': '127.0.0.1',\n",
      "                  'password': '',\n",
      "                  'port': 5001,\n",
      "                  'username': ''},\n",
      " 'notebook': {'ip': '0.0.0.0', 'password': '', 'port': 8888, 'token': ''},\n",
      " 'ray': {'deployments': [],\n",
      "         'host': '127.0.0.1',\n",
      "         'password': '',\n",
      "         'port': 0,\n",
      "         'username': ''},\n",
      " 'server': {'host': '127.0.0.1', 'port': 3223, 'protocol': 'http'},\n",
      " 'vector_search': {'host': 'localhost',\n",
      "                   'password': '',\n",
      "                   'port': 19530,\n",
      "                   'type': {'backfill_batch_size': 100, 'inmemory': True},\n",
      "                   'username': ''}}\n"
     ]
    }
   ],
   "source": [
    "from pinnacledb import CFG\n",
    "\n",
    "import pprint\n",
    "pprint.pprint(CFG.dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69847fe",
   "metadata": {},
   "source": [
    "Now that we've set up the environment to use a Dask cluster, we can add some data to the `Datalayer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d334809",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dodo/SuperDuperDB/pinnacledb/.venv/lib/python3.11/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 49921 instead\n",
      "  warnings.warn(\n",
      "INFO:distributed.scheduler:State start\n",
      "INFO:distributed.scheduler:  Scheduler at:     tcp://127.0.0.1:49922\n",
      "INFO:distributed.scheduler:  dashboard at:  http://127.0.0.1:49921/status\n",
      "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:49925'\n",
      "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:49926'\n",
      "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:49927'\n",
      "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:49928'\n",
      "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:49935', name: 2, status: init, memory: 0, processing: 0>\n",
      "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:49935\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:49939\n",
      "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:49933', name: 1, status: init, memory: 0, processing: 0>\n",
      "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:49933\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:49940\n",
      "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:49934', name: 0, status: init, memory: 0, processing: 0>\n",
      "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:49934\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:49941\n",
      "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:49942', name: 3, status: init, memory: 0, processing: 0>\n",
      "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:49942\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:49944\n",
      "INFO:distributed.scheduler:Receive client connection: Client-49aacf9a-2c26-11ee-890c-1e00f226d550\n",
      "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:49945\n"
     ]
    }
   ],
   "source": [
    "from pinnacledb.datalayer.base.build import build_datalayer\n",
    "\n",
    "db = build_datalayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b3ae27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.db.client.drop_database('testdb')\n",
    "db.db.client.drop_database('_filesystem:testdb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d364e04",
   "metadata": {},
   "source": [
    "As in the previous tutorials, we can wrap models from a range of AI frameworks to interoperate with the data set, \n",
    "as well as inserting data with, for instances, tensors of a specific data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71a538ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Could not get an identifier from submitted function, creating one!\n",
      "INFO:root:found 0 uris\n"
     ]
    }
   ],
   "source": [
    "import pymongo\n",
    "import torch\n",
    "\n",
    "from pinnacledb import pinnacle\n",
    "from pinnacledb.core.document import Document as D\n",
    "from pinnacledb.encoders.torch.tensor import tensor\n",
    "from pinnacledb.datalayer.mongodb.query import Collection\n",
    "\n",
    "m = pinnacle(\n",
    "    torch.nn.Linear(128, 7),\n",
    "    encoder=tensor(torch.float, shape=(7,))\n",
    ")\n",
    "\n",
    "t32 = tensor(torch.float, shape=(128,))\n",
    "\n",
    "output = db.execute(\n",
    "    Collection('localcluster').insert_many(\n",
    "        [D({'x': t32(torch.randn(128))}) for _ in range(1000)], \n",
    "        encoders=(t32,)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2488d20",
   "metadata": {},
   "source": [
    "Now when we instruct the model to make predictions based on the `Datalayer`, the computations run on the Dask cluster. The `.predict` method returns a `Job` instance, which can be used to monitor the progress of the computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a653d0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = m.predict(\n",
    "    X='x',\n",
    "    db=db,\n",
    "    select=Collection('localcluster').find(),\n",
    ")\n",
    "\n",
    "job.watch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050c0252",
   "metadata": {},
   "source": [
    "To check that the `Datalayer` has been populated with outputs, we can check the `\"_outputs\"` field of a record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d111789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document({'_id': ObjectId('64c1d71719f67e1b48cdf3dd'), 'x': Encodable(x=tensor([-0.1185, -0.0404, -0.1605, -0.1824, -0.3947,  1.8372, -0.0539, -0.4879,\n",
       "         0.8195,  1.5238, -1.4167, -2.0685, -0.9496, -0.1749,  1.2830,  0.8140,\n",
       "         0.9339, -0.4342, -1.1220, -0.3847, -1.9544,  0.1534, -1.2628, -0.3808,\n",
       "        -0.8816, -1.6340, -0.2665,  0.1103, -0.5372, -2.4823, -0.7087,  1.3672,\n",
       "         1.2557, -0.5210,  0.9967, -1.0727,  1.2504,  0.5167,  2.3840, -1.0954,\n",
       "         1.4559, -0.3013,  0.6051,  0.6426,  0.0433, -1.4484,  0.4398, -0.9044,\n",
       "         1.2979, -1.0627,  0.0968, -0.7796,  1.4209, -0.1462, -1.5939, -1.6432,\n",
       "        -0.7866,  1.5465,  0.1046,  1.0507, -0.3342,  0.7803, -0.2175, -1.3123,\n",
       "        -0.7993, -0.3464, -1.0265, -2.1460,  0.1070, -0.9112,  0.3214, -0.0166,\n",
       "         0.9422, -0.6901,  0.5440,  0.0243,  0.8935, -1.1099, -0.9086, -0.1164,\n",
       "        -0.8712, -0.3519,  0.2826, -1.7652,  0.6794, -0.1562, -0.1362,  0.9918,\n",
       "         0.0920,  0.9796,  0.0780, -0.2145, -1.3863, -1.1139, -0.6165, -0.5944,\n",
       "         0.0714, -0.8560, -0.4366, -0.6890, -0.0823,  1.5119, -1.6940, -1.1011,\n",
       "        -1.2935, -0.0069,  0.4241,  0.0410, -0.0433,  0.0461, -0.8076,  1.2476,\n",
       "        -0.7005, -1.0018, -0.1181,  1.5169, -0.2415,  0.2934, -0.8017, -0.0182,\n",
       "        -0.9250, -0.4665,  1.4740,  0.1819,  2.7405,  0.6077, -0.7615, -0.9959]), encoder=Encoder(identifier='torch.float32[128]', decoder=<Artifact artifact=<pinnacledb.encoders.torch.tensor.DecodeTensor object at 0x17cbd0350> serializer=dill>, encoder=<Artifact artifact=<pinnacledb.encoders.torch.tensor.EncodeTensor object at 0x17cbd0410> serializer=dill>, shape=[128], version=1)), '_fold': 'train', '_outputs': {'x': {'linear': Encodable(x=tensor([ 0.5870, -0.2290, -0.3595, -0.0456,  0.7253,  0.7665,  0.7731]), encoder=Encoder(identifier='torch.float32[7]', decoder=<Artifact artifact=<pinnacledb.encoders.torch.tensor.DecodeTensor object at 0x17cb90b50> serializer=dill>, encoder=<Artifact artifact=<pinnacledb.encoders.torch.tensor.EncodeTensor object at 0x17cb64050> serializer=dill>, shape=[7], version=1))}}})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.execute(Collection('localcluster').find_one())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
